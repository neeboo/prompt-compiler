use std::collections::HashMap;
use std::error::Error;
use std::env;
use std::fs;

/// ç®€å•çš„ .env æ–‡ä»¶è§£æå™¨
fn load_dotenv() -> Result<(), Box<dyn Error>> {
    if let Ok(content) = fs::read_to_string(".env") {
        for line in content.lines() {
            let line = line.trim();
            if line.starts_with('#') || line.is_empty() {
                continue;
            }
            if let Some((key, value)) = line.split_once('=') {
                let key = key.trim();
                let value = value.trim().trim_matches('"');
                env::set_var(key, value);
            }
        }
    }
    Ok(())
}

/// OpenAI æ¨¡å‹å¯¹æ¯”æ¼”ç¤º
struct ModelComparison {
    models: Vec<ModelInfo>,
}

struct ModelInfo {
    name: String,
    dimension: usize,
    cost_per_1k_tokens: f32,
    use_cases: Vec<String>,
    performance_score: f32,
}

impl ModelComparison {
    fn new() -> Self {
        Self {
            models: vec![
                ModelInfo {
                    name: "text-embedding-3-small".to_string(),
                    dimension: 1536,
                    cost_per_1k_tokens: 0.00002, // $0.00002 per 1K tokens
                    use_cases: vec![
                        "å¤§è§„æ¨¡æ–‡æ¡£æ£€ç´¢".to_string(),
                        "å®æ—¶è¯­ä¹‰æœç´¢".to_string(),
                        "èŠå¤©æœºå™¨äººçŸ¥è¯†åº“".to_string(),
                        "å†…å®¹æ¨èç³»ç»Ÿ".to_string(),
                    ],
                    performance_score: 85.0,
                },
                ModelInfo {
                    name: "text-embedding-3-large".to_string(),
                    dimension: 3072,
                    cost_per_1k_tokens: 0.00013, // $0.00013 per 1K tokens
                    use_cases: vec![
                        "æ³•å¾‹æ–‡æ¡£åˆ†æ".to_string(),
                        "å­¦æœ¯è®ºæ–‡æ£€ç´¢".to_string(),
                        "åŒ»ç–—çŸ¥è¯†åº“".to_string(),
                        "é«˜ç²¾åº¦è¯­ä¹‰åŒ¹é…".to_string(),
                    ],
                    performance_score: 95.0,
                },
                ModelInfo {
                    name: "text-embedding-ada-002".to_string(),
                    dimension: 1536,
                    cost_per_1k_tokens: 0.0001, // $0.0001 per 1K tokens (Legacy)
                    use_cases: vec![
                        "ä¼ ç»Ÿåº”ç”¨è¿ç§»".to_string(),
                        "é¢„ç®—æœ‰é™é¡¹ç›®".to_string(),
                    ],
                    performance_score: 75.0,
                },
            ],
        }
    }

    fn compare_models(&self) {
        println!("ğŸ“Š OpenAI Embedding æ¨¡å‹æ·±åº¦å¯¹æ¯”");
        println!("{}", "=".repeat(60));

        for (i, model) in self.models.iter().enumerate() {
            println!("\n{}. ğŸ¤– {}", i + 1, model.name);
            println!("   ğŸ“ å‘é‡ç»´åº¦: {} ç»´", model.dimension);
            println!("   ğŸ’° æˆæœ¬: ${:.5} / 1K tokens", model.cost_per_1k_tokens);
            println!("   ğŸ¯ æ€§èƒ½è¯„åˆ†: {}/100", model.performance_score);
            println!("   ğŸ”§ é€‚ç”¨åœºæ™¯:");
            for use_case in &model.use_cases {
                println!("      â€¢ {}", use_case);
            }

            // æˆæœ¬æ•ˆç›Šåˆ†æ
            let cost_efficiency = model.performance_score / (model.cost_per_1k_tokens * 100000.0);
            println!("   ğŸ“ˆ æ€§ä»·æ¯”æŒ‡æ•°: {:.1}", cost_efficiency);
        }
    }

    fn recommend_model(&self, use_case: &str) -> &ModelInfo {
        match use_case {
            "high_precision" => &self.models[1], // text-embedding-3-large
            "cost_effective" => &self.models[0], // text-embedding-3-small
            "legacy" => &self.models[2],         // text-embedding-ada-002
            _ => &self.models[0], // é»˜è®¤æ¨è small
        }
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸš€ OpenAI Embedding æ¨¡å‹å¯¹æ¯”æ¼”ç¤º");
    println!("=====================================");

    // 1. åŠ è½½å½“å‰é…ç½®
    load_dotenv()?;
    let current_model = env::var("OPENAI_MODEL").unwrap_or_else(|_| "text-embedding-3-small".to_string());

    println!("ğŸ“‹ å½“å‰é…ç½®æ¨¡å‹: {}", current_model);

    // 2. æ¨¡å‹å¯¹æ¯”åˆ†æ
    let comparison = ModelComparison::new();
    comparison.compare_models();

    // 3. åœºæ™¯åŒ–æ¨è
    println!("\nğŸ’¡ åœºæ™¯åŒ–æ¨¡å‹æ¨è:");
    println!("{}", "=".repeat(40));

    let scenarios = vec![
        ("é«˜ç²¾åº¦è¯­ä¹‰åˆ†æ", "high_precision"),
        ("æˆæœ¬æ•ˆç›Šä¼˜å…ˆ", "cost_effective"),
        ("ä¼ ç»Ÿç³»ç»Ÿå…¼å®¹", "legacy"),
    ];

    for (scenario, use_case) in scenarios {
        let recommended = comparison.recommend_model(use_case);
        println!("\nğŸ¯ åœºæ™¯: {}", scenario);
        println!("   æ¨èæ¨¡å‹: {}", recommended.name);
        println!("   ç†ç”±: {} ç»´åº¦, æ€§èƒ½ {}/100, æˆæœ¬ ${:.5}/1K",
                 recommended.dimension, recommended.performance_score, recommended.cost_per_1k_tokens);
    }

    // 4. æˆæœ¬è®¡ç®—å™¨
    println!("\nğŸ’° æˆæœ¬ä¼°ç®— (å¤„ç†100ä¸‡tokens):");
    println!("{}", "=".repeat(40));

    let tokens_1m = 1_000_000.0;
    for model in &comparison.models {
        let cost_1m = (tokens_1m / 1000.0) * model.cost_per_1k_tokens;
        println!("   â€¢ {}: ${:.2}", model.name, cost_1m);
    }

    // 5. å½“å‰æ¨¡å‹è¯¦ç»†ä¿¡æ¯
    if let Some(current) = comparison.models.iter().find(|m| m.name == current_model) {
        println!("\nğŸ” å½“å‰ä½¿ç”¨æ¨¡å‹è¯¦æƒ…:");
        println!("{}", "=".repeat(30));
        println!("   ğŸ“± æ¨¡å‹: {}", current.name);
        println!("   ğŸ“ ç»´åº¦: {} ç»´ ({})",
                 current.dimension,
                 if current.dimension >= 3000 { "é«˜ç²¾åº¦" } else { "æ ‡å‡†ç²¾åº¦" });
        println!("   ğŸ’° æˆæœ¬: ${:.5}/1K tokens", current.cost_per_1k_tokens);
        println!("   ğŸ¯ æ€§èƒ½: {}/100", current.performance_score);

        // å­˜å‚¨éœ€æ±‚ä¼°ç®—
        let storage_per_vector_mb = (current.dimension * 4) as f64 / 1_000_000.0; // 4 bytes per float32
        println!("   ğŸ’¾ å­˜å‚¨éœ€æ±‚: {:.3} MB/ç™¾ä¸‡å‘é‡", storage_per_vector_mb * 1_000_000.0);
    }

    // 6. åˆ‡æ¢å»ºè®®
    println!("\nğŸ”„ æ¨¡å‹åˆ‡æ¢æŒ‡å—:");
    println!("{}", "=".repeat(25));
    println!("   ä¿®æ”¹ .env æ–‡ä»¶ä¸­çš„ OPENAI_MODEL é…ç½®:");
    println!("   â€¢ é«˜ç²¾åº¦: OPENAI_MODEL=text-embedding-3-large");
    println!("   â€¢ æ ‡å‡†ç‰ˆ: OPENAI_MODEL=text-embedding-3-small");
    println!("   â€¢ ä¼ ç»Ÿç‰ˆ: OPENAI_MODEL=text-embedding-ada-002");

    println!("\nâœ¨ å½“å‰æ­£åœ¨ä½¿ç”¨: {} ğŸ‰", current_model);
    if current_model == "text-embedding-3-large" {
        println!("ğŸŒŸ æ­å–œï¼ä½ æ­£åœ¨ä½¿ç”¨æœ€é«˜ç²¾åº¦æ¨¡å‹ï¼Œé€‚åˆå¤æ‚è¯­ä¹‰ä»»åŠ¡ï¼");
    }

    Ok(())
}
