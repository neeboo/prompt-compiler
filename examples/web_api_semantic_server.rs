use std::collections::HashMap;
use std::sync::{Arc, Mutex};
use std::error::Error;
use std::time::{SystemTime, UNIX_EPOCH};
use std::net::SocketAddr;

// ç®€åŒ–çš„HTTPæœåŠ¡å™¨æ¨¡æ‹Ÿï¼ˆå®é™…ç¯å¢ƒä¸­ä¼šä½¿ç”¨axum/warpç­‰æ¡†æ¶ï¼‰
use std::io::prelude::*;
use std::net::{TcpListener, TcpStream};
use std::thread;

/// ä¼ä¸šçº§è¯­ä¹‰ç³»ç»ŸWeb APIæœåŠ¡å™¨
struct SemanticAPIServer {
    storage_system: Arc<Mutex<HighPerformanceSemanticStorage>>,
    dynamics_system: Arc<Mutex<WeightDynamicsEngine>>,
    api_stats: Arc<Mutex<APIStats>>,
    config: ServerConfig,
}

/// é«˜æ€§èƒ½è¯­ä¹‰å­˜å‚¨ç³»ç»Ÿï¼ˆé›†æˆç‰ˆï¼‰
struct HighPerformanceSemanticStorage {
    chunks: HashMap<String, SemanticChunk>,
    vector_index: HashMap<String, VectorIndex>,
    cache: HashMap<String, Vec<f32>>,
    stats: StorageStats,
}

/// æƒé‡åŠ¨åŠ›å­¦å¼•æ“ï¼ˆé›†æˆç‰ˆï¼‰
struct WeightDynamicsEngine {
    weight_nodes: HashMap<String, WeightNode>,
    learning_rate: f32,
    convergence_threshold: f32,
    training_stats: TrainingStats,
}

/// è¯­ä¹‰å—
#[derive(Clone, Debug)]
struct SemanticChunk {
    pub id: String,
    pub title: String,
    pub content: String,
    pub embedding: Vec<f32>,
    pub compression_ratio: f32,
    pub created_at: u64,
    pub priority: f32,
}

/// å‘é‡ç´¢å¼•
#[derive(Clone, Debug)]
struct VectorIndex {
    pub chunk_id: String,
    pub compressed_embedding: Vec<f32>,
    pub similarity_score: f32,
}

/// æƒé‡èŠ‚ç‚¹
#[derive(Clone, Debug)]
struct WeightNode {
    pub id: String,
    pub weights: Vec<f32>,
    pub gradient: Vec<f32>,
    pub convergence_score: f32,
    pub update_count: u64,
}

/// APIç»Ÿè®¡
#[derive(Debug)]
struct APIStats {
    total_requests: u64,
    search_requests: u64,
    training_requests: u64,
    storage_requests: u64,
    avg_response_time_ms: f64,
    error_count: u64,
    uptime_seconds: u64,
}

/// å­˜å‚¨ç»Ÿè®¡
#[derive(Debug)]
struct StorageStats {
    total_chunks: usize,
    index_size_kb: f64,
    cache_hit_rate: f32,
}

/// è®­ç»ƒç»Ÿè®¡
#[derive(Debug)]
struct TrainingStats {
    total_updates: u64,
    avg_convergence_rate: f32,
    best_convergence_score: f32,
}

/// æœåŠ¡å™¨é…ç½®
struct ServerConfig {
    host: String,
    port: u16,
    max_connections: usize,
    dimension: usize,
}

/// APIè¯·æ±‚ç±»å‹
#[derive(Debug)]
enum APIRequest {
    Search { query: String, top_k: usize, threshold: f32 },
    Store { title: String, content: String },
    Train { node_id: String, target: Vec<f32> },
    Stats,
    Health,
}

/// APIå“åº”ç±»å‹
#[derive(Debug)]
struct APIResponse {
    success: bool,
    data: String,
    execution_time_ms: u64,
    error: Option<String>,
}

impl SemanticAPIServer {
    /// åˆ›å»ºæ–°çš„APIæœåŠ¡å™¨
    fn new() -> Result<Self, Box<dyn Error>> {
        let config = ServerConfig {
            host: "127.0.0.1".to_string(),
            port: 8080,
            max_connections: 100,
            dimension: 768,
        };

        let storage_system = Arc::new(Mutex::new(HighPerformanceSemanticStorage::new(config.dimension)?));
        let dynamics_system = Arc::new(Mutex::new(WeightDynamicsEngine::new(config.dimension)?));

        let api_stats = Arc::new(Mutex::new(APIStats {
            total_requests: 0,
            search_requests: 0,
            training_requests: 0,
            storage_requests: 0,
            avg_response_time_ms: 0.0,
            error_count: 0,
            uptime_seconds: 0,
        }));

        Ok(Self {
            storage_system,
            dynamics_system,
            api_stats,
            config,
        })
    }

    /// å¯åŠ¨Web APIæœåŠ¡å™¨
    fn start(&mut self) -> Result<(), Box<dyn Error>> {
        let addr = format!("{}:{}", self.config.host, self.config.port);
        println!("ğŸš€ å¯åŠ¨ä¼ä¸šçº§è¯­ä¹‰ç³»ç»ŸAPIæœåŠ¡å™¨");
        println!("   ğŸ“¡ ç›‘å¬åœ°å€: {}", addr);
        println!("   ğŸ”§ æœ€å¤§è¿æ¥æ•°: {}", self.config.max_connections);
        println!("   ğŸ“ å‘é‡ç»´åº¦: {}", self.config.dimension);
        println!("=================================================\n");

        let listener = TcpListener::bind(&addr)?;
        println!("âœ… APIæœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼");
        println!("ğŸ“– APIæ–‡æ¡£:");
        self.print_api_documentation();

        // åˆå§‹åŒ–ä¸€äº›æµ‹è¯•æ•°æ®
        self.initialize_demo_data()?;

        // å¤„ç†ä¼ å…¥è¿æ¥
        for stream in listener.incoming() {
            match stream {
                Ok(stream) => {
                    let storage_clone = Arc::clone(&self.storage_system);
                    let dynamics_clone = Arc::clone(&self.dynamics_system);
                    let stats_clone = Arc::clone(&self.api_stats);

                    thread::spawn(move || {
                        if let Err(e) = Self::handle_client(stream, storage_clone, dynamics_clone, stats_clone) {
                            eprintln!("âŒ å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚é”™è¯¯: {}", e);
                        }
                    });
                }
                Err(e) => {
                    eprintln!("âŒ è¿æ¥é”™è¯¯: {}", e);
                }
            }
        }

        Ok(())
    }

    /// å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚
    fn handle_client(
        mut stream: TcpStream,
        storage: Arc<Mutex<HighPerformanceSemanticStorage>>,
        dynamics: Arc<Mutex<WeightDynamicsEngine>>,
        stats: Arc<Mutex<APIStats>>,
    ) -> Result<(), Box<dyn Error>> {
        let start_time = SystemTime::now();

        let mut buffer = [0; 1024];
        stream.read(&mut buffer)?;

        let request = String::from_utf8_lossy(&buffer[..]);
        let request_line = request.lines().next().unwrap_or("");

        println!("ğŸ“¨ æ”¶åˆ°è¯·æ±‚: {}", request_line);

        // æ›´æ–°ç»Ÿè®¡
        {
            let mut api_stats = stats.lock().unwrap();
            api_stats.total_requests += 1;
        }

        let response = match Self::parse_request(request_line) {
            Ok(api_request) => {
                match api_request {
                    APIRequest::Search { query, top_k, threshold } => {
                        {
                            let mut api_stats = stats.lock().unwrap();
                            api_stats.search_requests += 1;
                        }
                        Self::handle_search_request(&query, top_k, threshold, storage)
                    }
                    APIRequest::Store { title, content } => {
                        {
                            let mut api_stats = stats.lock().unwrap();
                            api_stats.storage_requests += 1;
                        }
                        Self::handle_store_request(&title, &content, storage)
                    }
                    APIRequest::Train { node_id, target } => {
                        {
                            let mut api_stats = stats.lock().unwrap();
                            api_stats.training_requests += 1;
                        }
                        Self::handle_train_request(&node_id, &target, dynamics)
                    }
                    APIRequest::Stats => {
                        Self::handle_stats_request(storage, dynamics, stats.clone())
                    }
                    APIRequest::Health => {
                        APIResponse {
                            success: true,
                            data: "OK".to_string(),
                            execution_time_ms: 0,
                            error: None,
                        }
                    }
                }
            }
            Err(e) => {
                let mut api_stats = stats.lock().unwrap();
                api_stats.error_count += 1;

                APIResponse {
                    success: false,
                    data: "".to_string(),
                    execution_time_ms: 0,
                    error: Some(e.to_string()),
                }
            }
        };

        let execution_time = start_time.elapsed()?.as_millis() as u64;

        // æ›´æ–°å¹³å‡å“åº”æ—¶é—´
        {
            let mut api_stats = stats.lock().unwrap();
            api_stats.avg_response_time_ms = (api_stats.avg_response_time_ms + execution_time as f64) / 2.0;
        }

        let http_response = Self::create_http_response(&response, execution_time);
        stream.write(http_response.as_bytes())?;
        stream.flush()?;

        println!("âœ… è¯·æ±‚å¤„ç†å®Œæˆ ({}ms)", execution_time);

        Ok(())
    }

    /// è§£æAPIè¯·æ±‚
    fn parse_request(request_line: &str) -> Result<APIRequest, Box<dyn Error>> {
        let parts: Vec<&str> = request_line.split_whitespace().collect();
        if parts.len() < 2 {
            return Err("Invalid request format".into());
        }

        let method = parts[0];
        let path = parts[1];

        if method != "GET" && method != "POST" {
            return Err("Unsupported HTTP method".into());
        }

        match path {
            "/health" => Ok(APIRequest::Health),
            "/stats" => Ok(APIRequest::Stats),
            path if path.starts_with("/search") => {
                // è§£ææŸ¥è¯¢å‚æ•° /search?q=query&k=5&t=0.5
                let query_str = path.split('?').nth(1).unwrap_or("");
                let mut query = "".to_string();
                let mut top_k = 5;
                let mut threshold = 0.3;

                for param in query_str.split('&') {
                    let kv: Vec<&str> = param.split('=').collect();
                    if kv.len() == 2 {
                        match kv[0] {
                            "q" => query = kv[1].replace("%20", " "),
                            "k" => top_k = kv[1].parse().unwrap_or(5),
                            "t" => threshold = kv[1].parse().unwrap_or(0.3),
                            _ => {}
                        }
                    }
                }

                Ok(APIRequest::Search { query, top_k, threshold })
            }
            path if path.starts_with("/store") => {
                // ç®€åŒ–çš„å­˜å‚¨è¯·æ±‚è§£æ
                Ok(APIRequest::Store {
                    title: "API Test".to_string(),
                    content: "Test content from API".to_string(),
                })
            }
            path if path.starts_with("/train") => {
                // ç®€åŒ–çš„è®­ç»ƒè¯·æ±‚è§£æ
                Ok(APIRequest::Train {
                    node_id: "test_node".to_string(),
                    target: vec![0.1; 768],
                })
            }
            _ => Err("Unknown endpoint".into()),
        }
    }

    /// å¤„ç†æœç´¢è¯·æ±‚
    fn handle_search_request(
        query: &str,
        top_k: usize,
        threshold: f32,
        storage: Arc<Mutex<HighPerformanceSemanticStorage>>,
    ) -> APIResponse {
        match storage.lock() {
            Ok(mut storage_system) => {
                match storage_system.semantic_search(query, top_k, threshold) {
                    Ok(results) => {
                        let mut response_data = format!("æœç´¢ç»“æœ (æŸ¥è¯¢: '{}'):\n", query);
                        for (i, (chunk_id, score)) in results.iter().enumerate() {
                            response_data.push_str(&format!("{}. {} (ç›¸ä¼¼åº¦: {:.3})\n", i + 1, chunk_id, score));
                        }

                        APIResponse {
                            success: true,
                            data: response_data,
                            execution_time_ms: 0,
                            error: None,
                        }
                    }
                    Err(e) => APIResponse {
                        success: false,
                        data: "".to_string(),
                        execution_time_ms: 0,
                        error: Some(e.to_string()),
                    }
                }
            }
            Err(e) => APIResponse {
                success: false,
                data: "".to_string(),
                execution_time_ms: 0,
                error: Some(e.to_string()),
            }
        }
    }

    /// å¤„ç†å­˜å‚¨è¯·æ±‚
    fn handle_store_request(
        title: &str,
        content: &str,
        storage: Arc<Mutex<HighPerformanceSemanticStorage>>,
    ) -> APIResponse {
        match storage.lock() {
            Ok(mut storage_system) => {
                match storage_system.store_chunk(title, content) {
                    Ok(chunk_id) => APIResponse {
                        success: true,
                        data: format!("è¯­ä¹‰å—å·²å­˜å‚¨: {}", chunk_id),
                        execution_time_ms: 0,
                        error: None,
                    },
                    Err(e) => APIResponse {
                        success: false,
                        data: "".to_string(),
                        execution_time_ms: 0,
                        error: Some(e.to_string()),
                    }
                }
            }
            Err(e) => APIResponse {
                success: false,
                data: "".to_string(),
                execution_time_ms: 0,
                error: Some(e.to_string()),
            }
        }
    }

    /// å¤„ç†è®­ç»ƒè¯·æ±‚
    fn handle_train_request(
        node_id: &str,
        target: &[f32],
        dynamics: Arc<Mutex<WeightDynamicsEngine>>,
    ) -> APIResponse {
        match dynamics.lock() {
            Ok(mut dynamics_system) => {
                match dynamics_system.update_weights(node_id, target) {
                    Ok(convergence) => APIResponse {
                        success: true,
                        data: format!("æƒé‡æ›´æ–°å®Œæˆ: {} (æ”¶æ•›åˆ†æ•°: {:.4})", node_id, convergence),
                        execution_time_ms: 0,
                        error: None,
                    },
                    Err(e) => APIResponse {
                        success: false,
                        data: "".to_string(),
                        execution_time_ms: 0,
                        error: Some(e.to_string()),
                    }
                }
            }
            Err(e) => APIResponse {
                success: false,
                data: "".to_string(),
                execution_time_ms: 0,
                error: Some(e.to_string()),
            }
        }
    }

    /// å¤„ç†ç»Ÿè®¡è¯·æ±‚
    fn handle_stats_request(
        storage: Arc<Mutex<HighPerformanceSemanticStorage>>,
        dynamics: Arc<Mutex<WeightDynamicsEngine>>,
        stats: Arc<Mutex<APIStats>>,
    ) -> APIResponse {
        let api_stats = stats.lock().unwrap();
        let storage_stats = storage.lock().unwrap().get_stats();
        let training_stats = dynamics.lock().unwrap().get_stats();

        let stats_data = format!(
            "ğŸš€ ä¼ä¸šçº§è¯­ä¹‰ç³»ç»ŸAPIç»Ÿè®¡æŠ¥å‘Š\n\
            =====================================\n\
            ğŸ“¡ APIç»Ÿè®¡:\n\
            - æ€»è¯·æ±‚æ•°: {}\n\
            - æœç´¢è¯·æ±‚: {}\n\
            - å­˜å‚¨è¯·æ±‚: {}\n\
            - è®­ç»ƒè¯·æ±‚: {}\n\
            - å¹³å‡å“åº”æ—¶é—´: {:.2}ms\n\
            - é”™è¯¯æ¬¡æ•°: {}\n\n\
            ğŸ’¾ å­˜å‚¨ç»Ÿè®¡:\n\
            - è¯­ä¹‰å—æ€»æ•°: {}\n\
            - ç´¢å¼•å¤§å°: {:.2}KB\n\
            - ç¼“å­˜å‘½ä¸­ç‡: {:.1}%\n\n\
            ğŸ§  è®­ç»ƒç»Ÿè®¡:\n\
            - æƒé‡æ›´æ–°æ¬¡æ•°: {}\n\
            - å¹³å‡æ”¶æ•›ç‡: {:.2}%\n\
            - æœ€ä½³æ”¶æ•›åˆ†æ•°: {:.4}\n",
            api_stats.total_requests,
            api_stats.search_requests,
            api_stats.storage_requests,
            api_stats.training_requests,
            api_stats.avg_response_time_ms,
            api_stats.error_count,
            storage_stats.total_chunks,
            storage_stats.index_size_kb,
            storage_stats.cache_hit_rate * 100.0,
            training_stats.total_updates,
            training_stats.avg_convergence_rate * 100.0,
            training_stats.best_convergence_score
        );

        APIResponse {
            success: true,
            data: stats_data,
            execution_time_ms: 0,
            error: None,
        }
    }

    /// åˆ›å»ºHTTPå“åº”
    fn create_http_response(api_response: &APIResponse, execution_time: u64) -> String {
        let status = if api_response.success { "200 OK" } else { "500 Internal Server Error" };

        let body = if api_response.success {
            format!("æ‰§è¡Œæ—¶é—´: {}ms\n\n{}", execution_time, api_response.data)
        } else {
            format!("é”™è¯¯: {}", api_response.error.as_ref().unwrap_or(&"Unknown error".to_string()))
        };

        format!(
            "HTTP/1.1 {}\r\n\
            Content-Type: text/plain; charset=utf-8\r\n\
            Content-Length: {}\r\n\
            Access-Control-Allow-Origin: *\r\n\
            \r\n\
            {}",
            status,
            body.len(),
            body
        )
    }

    /// æ‰“å°APIæ–‡æ¡£
    fn print_api_documentation(&self) {
        println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
        println!("â”‚                    APIç«¯ç‚¹æ–‡æ¡£                           â”‚");
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚ GET  /health                           - å¥åº·æ£€æŸ¥        â”‚");
        println!("â”‚ GET  /stats                            - ç³»ç»Ÿç»Ÿè®¡        â”‚");
        println!("â”‚ GET  /search?q=query&k=5&t=0.3         - è¯­ä¹‰æœç´¢        â”‚");
        println!("â”‚ POST /store                            - å­˜å‚¨è¯­ä¹‰å—      â”‚");
        println!("â”‚ POST /train                            - è®­ç»ƒæƒé‡        â”‚");
        println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n");
    }

    /// åˆå§‹åŒ–æ¼”ç¤ºæ•°æ®
    fn initialize_demo_data(&mut self) -> Result<(), Box<dyn Error>> {
        println!("ğŸ”§ åˆå§‹åŒ–æ¼”ç¤ºæ•°æ®...");

        let demo_data = vec![
            ("ä¼ä¸šçº§AIæ¶æ„", "ç°ä»£ä¼ä¸šçº§äººå·¥æ™ºèƒ½æ¶æ„éœ€è¦æ”¯æŒé«˜å¹¶å‘ã€å¯æ‰©å±•æ€§å’Œå®æ—¶å“åº”èƒ½åŠ›ã€‚"),
            ("è¯­ä¹‰æœç´¢å¼•æ“", "åŸºäºæ·±åº¦å­¦ä¹ çš„è¯­ä¹‰æœç´¢å¼•æ“èƒ½å¤Ÿç†è§£ç”¨æˆ·æ„å›¾å¹¶æä¾›ç²¾ç¡®çš„æœç´¢ç»“æœã€‚"),
            ("æƒé‡åŠ¨åŠ›å­¦ä¼˜åŒ–", "é€šè¿‡æ¢¯åº¦ä¸‹é™å’ŒåŠ¨é‡ä¼˜åŒ–å®ç°ç¥ç»ç½‘ç»œæƒé‡çš„æ™ºèƒ½æ›´æ–°å’Œæ”¶æ•›ã€‚"),
            ("é«˜æ€§èƒ½å­˜å‚¨", "RocksDBæä¾›ä¼ä¸šçº§çš„é«˜æ€§èƒ½é”®å€¼å­˜å‚¨ï¼Œæ”¯æŒå¿«é€Ÿè¯»å†™å’Œæ•°æ®å‹ç¼©ã€‚"),
            ("APIæœåŠ¡æ¶æ„", "RESTful APIè®¾è®¡æä¾›æ ‡å‡†åŒ–çš„æ¥å£ï¼Œæ”¯æŒå¤šç§å®¢æˆ·ç«¯å’Œé›†æˆæ–¹å¼ã€‚"),
        ];

        let mut storage = self.storage_system.lock().unwrap();
        for (title, content) in demo_data {
            storage.store_chunk(title, content)?;
        }

        println!("âœ… æ¼”ç¤ºæ•°æ®åˆå§‹åŒ–å®Œæˆ ({} ä¸ªè¯­ä¹‰å—)", 5);
        Ok(())
    }
}

// ç®€åŒ–çš„å­˜å‚¨ç³»ç»Ÿå®ç°
impl HighPerformanceSemanticStorage {
    fn new(dimension: usize) -> Result<Self, Box<dyn Error>> {
        Ok(Self {
            chunks: HashMap::new(),
            vector_index: HashMap::new(),
            cache: HashMap::new(),
            stats: StorageStats {
                total_chunks: 0,
                index_size_kb: 0.0,
                cache_hit_rate: 0.0,
            },
        })
    }

    fn store_chunk(&mut self, title: &str, content: &str) -> Result<String, Box<dyn Error>> {
        let chunk_id = format!("api_chunk_{:08}", self.chunks.len() + 1);
        let embedding = self.generate_embedding(content)?;

        let chunk = SemanticChunk {
            id: chunk_id.clone(),
            title: title.to_string(),
            content: content.to_string(),
            embedding: embedding.clone(),
            compression_ratio: 0.75,
            created_at: SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs(),
            priority: 1.0,
        };

        self.chunks.insert(chunk_id.clone(), chunk);

        // æ›´æ–°å‘é‡ç´¢å¼•
        let compressed_embedding = embedding[..192].to_vec(); // å‹ç¼©åˆ°192ç»´
        let index = VectorIndex {
            chunk_id: chunk_id.clone(),
            compressed_embedding,
            similarity_score: 1.0,
        };
        self.vector_index.insert(chunk_id.clone(), index);

        self.stats.total_chunks = self.chunks.len();
        self.stats.index_size_kb = (self.vector_index.len() * 192 * 4) as f64 / 1024.0;

        Ok(chunk_id)
    }

    fn semantic_search(&mut self, query: &str, top_k: usize, threshold: f32) -> Result<Vec<(String, f32)>, Box<dyn Error>> {
        let query_embedding = self.generate_embedding(query)?;
        let compressed_query = query_embedding[..192].to_vec();

        let mut results = Vec::new();

        for (chunk_id, index) in &self.vector_index {
            let similarity = Self::cosine_similarity(&compressed_query, &index.compressed_embedding);
            if similarity >= threshold {
                results.push((chunk_id.clone(), similarity));
            }
        }

        results.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        results.truncate(top_k);

        Ok(results)
    }

    fn generate_embedding(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        // æ£€æŸ¥ç¼“å­˜
        if let Some(cached) = self.cache.get(text) {
            self.stats.cache_hit_rate = (self.stats.cache_hit_rate + 1.0) / 2.0;
            return Ok(cached.clone());
        }

        // ç”Ÿæˆæ–°çš„embedding
        let mut embedding = vec![0.0; 768];
        let bytes = text.as_bytes();

        for (i, &byte) in bytes.iter().enumerate() {
            let idx1 = (i * 7 + byte as usize) % 768;
            let idx2 = (i * 13 + (byte as usize).pow(2)) % 768;

            embedding[idx1] += (byte as f32 / 255.0) * 0.8;
            embedding[idx2] += ((byte as f32 * 0.1).sin() + 1.0) * 0.3;
        }

        // å½’ä¸€åŒ–
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for x in embedding.iter_mut() {
                *x /= norm;
            }
        }

        self.cache.insert(text.to_string(), embedding.clone());
        Ok(embedding)
    }

    fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
        let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
        let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
        let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();

        if norm_a > 0.0 && norm_b > 0.0 {
            dot_product / (norm_a * norm_b)
        } else {
            0.0
        }
    }

    fn get_stats(&self) -> StorageStats {
        StorageStats {
            total_chunks: self.stats.total_chunks,
            index_size_kb: self.stats.index_size_kb,
            cache_hit_rate: self.stats.cache_hit_rate,
        }
    }
}

// ç®€åŒ–çš„æƒé‡åŠ¨åŠ›å­¦å¼•æ“å®ç°
impl WeightDynamicsEngine {
    fn new(dimension: usize) -> Result<Self, Box<dyn Error>> {
        Ok(Self {
            weight_nodes: HashMap::new(),
            learning_rate: 0.01,
            convergence_threshold: 0.001,
            training_stats: TrainingStats {
                total_updates: 0,
                avg_convergence_rate: 0.0,
                best_convergence_score: 0.0,
            },
        })
    }

    fn update_weights(&mut self, node_id: &str, target: &[f32]) -> Result<f32, Box<dyn Error>> {
        // å¦‚æœèŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°èŠ‚ç‚¹
        if !self.weight_nodes.contains_key(node_id) {
            let node = WeightNode {
                id: node_id.to_string(),
                weights: vec![0.1; target.len()],
                gradient: vec![0.0; target.len()],
                convergence_score: 0.0,
                update_count: 0,
            };
            self.weight_nodes.insert(node_id.to_string(), node);
        }

        if let Some(node) = self.weight_nodes.get_mut(node_id) {
            // ç®€åŒ–çš„æƒé‡æ›´æ–°
            for i in 0..node.weights.len().min(target.len()) {
                let error = target[i] - node.weights[i];
                node.gradient[i] = error;
                node.weights[i] += self.learning_rate * error;
            }

            let gradient_norm = node.gradient.iter().map(|x| x * x).sum::<f32>().sqrt();
            node.convergence_score = (-gradient_norm).exp();
            node.update_count += 1;

            self.training_stats.total_updates += 1;
            self.training_stats.avg_convergence_rate = (self.training_stats.avg_convergence_rate + node.convergence_score) / 2.0;

            if node.convergence_score > self.training_stats.best_convergence_score {
                self.training_stats.best_convergence_score = node.convergence_score;
            }

            Ok(node.convergence_score)
        } else {
            Err("Failed to create or access weight node".into())
        }
    }

    fn get_stats(&self) -> TrainingStats {
        TrainingStats {
            total_updates: self.training_stats.total_updates,
            avg_convergence_rate: self.training_stats.avg_convergence_rate,
            best_convergence_score: self.training_stats.best_convergence_score,
        }
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸŒ ä¼ä¸šçº§è¯­ä¹‰ç³»ç»ŸWeb APIæœåŠ¡å™¨");
    println!("=================================================");

    let mut server = SemanticAPIServer::new()?;
    server.start()?;

    Ok(())
}
