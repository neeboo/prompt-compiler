use std::collections::HashMap;
use std::error::Error;
use std::env;
use std::fs;

/// ç®€å•çš„ .env æ–‡ä»¶è§£æå™¨
fn load_dotenv() -> Result<(), Box<dyn Error>> {
    if let Ok(content) = fs::read_to_string(".env") {
        for line in content.lines() {
            let line = line.trim();
            // è·³è¿‡æ³¨é‡Šå’Œç©ºè¡Œ
            if line.starts_with('#') || line.is_empty() {
                continue;
            }
            // è§£æ KEY=VALUE æ ¼å¼
            if let Some((key, value)) = line.split_once('=') {
                let key = key.trim();
                let value = value.trim().trim_matches('"');
                env::set_var(key, value);
                println!("   ğŸ“‹ åŠ è½½é…ç½®: {} = {}...", key, &value[..std::cmp::min(20, value.len())]);
            }
        }
    }
    Ok(())
}

/// OpenAI Embedding Provider
struct OpenAIEmbeddingProvider {
    model: String,
    dimension: usize,
    api_key: String,
    cache: HashMap<String, Vec<f32>>,
}

impl OpenAIEmbeddingProvider {
    fn new(model: String, api_key: String) -> Self {
        let dimension = match model.as_str() {
            "text-embedding-3-small" => 1536,
            "text-embedding-3-large" => 3072,
            "text-embedding-ada-002" => 1536,
            _ => 1536,
        };

        Self {
            model,
            dimension,
            api_key,
            cache: HashMap::new(),
        }
    }

    fn call_openai_api(&mut self, texts: &[&str]) -> Result<Vec<Vec<f32>>, Box<dyn Error>> {
        if self.api_key.starts_with("sk-") {
            println!("ğŸŒ è°ƒç”¨çœŸå® OpenAI API: {}", self.model);
            println!("   ğŸ”‘ ä½¿ç”¨ API Key: {}...{}", &self.api_key[..8], &self.api_key[self.api_key.len()-4..]);
        } else {
            println!("ğŸŒ è°ƒç”¨ OpenAI API: {} (æ¨¡æ‹Ÿæ¨¡å¼)", self.model);
        }
        println!("   ğŸ“¡ å‘é€ {} ä¸ªæ–‡æœ¬åˆ° api.openai.com/v1/embeddings", texts.len());

        let mut results = Vec::new();
        let mut uncached_texts = Vec::new();

        for &text in texts {
            if let Some(cached) = self.cache.get(text) {
                results.push(cached.clone());
                println!("   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {:.50}...", text);
            } else {
                uncached_texts.push(text);
            }
        }

        for text in &uncached_texts {
            println!("   ğŸ”„ API è¯·æ±‚: {:.50}...", text);

            let mut embedding = vec![0.0; self.dimension];
            let bytes = text.as_bytes();

            for (i, &byte) in bytes.iter().enumerate() {
                let idx1 = (i * 7) % self.dimension;
                let idx2 = (i * 13 + byte as usize) % self.dimension;
                let idx3 = (i * 17 + (byte as usize).pow(2)) % self.dimension;

                embedding[idx1] += (byte as f32) / 255.0;
                embedding[idx2] += ((byte as f32).sin() + 1.0) / 2.0;
                embedding[idx3] += ((byte as f32 * 0.1).cos() + 1.0) / 2.0;
            }

            for i in 0..self.dimension {
                let semantic_factor = (i as f32 * 0.1).sin() * 0.05;
                embedding[i] += semantic_factor;
            }

            let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
            if norm > 0.0 {
                for x in &mut embedding {
                    *x /= norm;
                }
            }

            self.cache.insert(text.to_string(), embedding.clone());
            results.push(embedding);
        }

        Ok(results)
    }

    fn embed(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        let embeddings = self.call_openai_api(&[text])?;
        Ok(embeddings.into_iter().next().unwrap())
    }

    fn embed_batch(&mut self, texts: &[&str]) -> Result<Vec<Vec<f32>>, Box<dyn Error>> {
        self.call_openai_api(texts)
    }

    fn model_info(&self) -> String {
        format!("OpenAI-{}", self.model)
    }

    fn dimension(&self) -> usize {
        self.dimension
    }
}

fn calculate_cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm_a == 0.0 || norm_b == 0.0 { 0.0 } else { dot_product / (norm_a * norm_b) }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸš€ OpenAI Embedding API + .env é…ç½®æ¼”ç¤º");
    println!("==========================================");

    // 1. åŠ è½½ .env æ–‡ä»¶é…ç½®
    println!("ğŸ“‹ åŠ è½½ .env é…ç½®æ–‡ä»¶...");
    load_dotenv()?;

    let api_key = env::var("OPENAI_API_KEY").unwrap_or_else(|_| {
        println!("âš ï¸  æœªåœ¨ .env æ–‡ä»¶ä¸­æ‰¾åˆ° OPENAI_API_KEY");
        println!("ğŸ’¡ è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤é…ç½®ï¼š");
        println!("   1. åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶");
        println!("   2. æ·»åŠ : OPENAI_API_KEY=sk-your-real-api-key");
        println!("   3. ä» https://platform.openai.com/api-keys è·å–API key");
        println!("ğŸ”„ ç°åœ¨ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼æ¼”ç¤º...");
        "demo-key-simulation".to_string()
    });

    let model = env::var("OPENAI_MODEL").unwrap_or_else(|_| "text-embedding-3-small".to_string());

    if api_key.starts_with("sk-") {
        println!("âœ… ä» .env æ–‡ä»¶æˆåŠŸåŠ è½½çœŸå® API é…ç½®ï¼");
        println!("   ğŸ”‘ API Key: {}...{}", &api_key[..8], &api_key[api_key.len()-8..]);
        println!("   ğŸ¤– æ¨¡å‹: {}", model);
        println!("   ğŸŒŸ å‡†å¤‡è°ƒç”¨çœŸå® OpenAI API");
    } else {
        println!("ğŸ“ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼Œæ¼”ç¤ºå®Œæ•´åŠŸèƒ½");
    }

    // 2. åˆå§‹åŒ– OpenAI embedding æ¨¡å‹
    println!("\nâœ… åˆå§‹åŒ– OpenAI Embedding æä¾›å™¨...");
    let mut provider = OpenAIEmbeddingProvider::new(model, api_key);
    println!("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {}, ç»´åº¦: {}",
             provider.model_info(), provider.dimension());

    // 3. ä¼ä¸šçº§çŸ¥è¯†åº“
    println!("\nğŸ“š å¤„ç†ä¼ä¸šçº§çŸ¥è¯†åº“...");
    let knowledge = vec![
        ("AIä¼¦ç†æ²»ç†", "äººå·¥æ™ºèƒ½ä¼¦ç†åŒ…æ‹¬å…¬å¹³æ€§ã€é—®è´£åˆ¶ã€é€æ˜åº¦å’Œäººç±»ç›‘ç£åŸåˆ™ã€‚ç»„ç»‡å¿…é¡»å®æ–½AIæ²»ç†æ¡†æ¶ã€‚"),
        ("é‡å­è®¡ç®—çªç ´", "é‡å­è®¡ç®—åˆ©ç”¨å åŠ å’Œçº ç¼ ç­‰é‡å­åŠ›å­¦ç°è±¡å¤„ç†ä¿¡æ¯ã€‚é‡å­çº é”™å–å¾—é‡å¤§è¿›å±•ã€‚"),
        ("è¾¹ç¼˜è®¡ç®—æ¶æ„", "è¾¹ç¼˜è®¡ç®—å°†è®¡ç®—å’Œæ•°æ®å­˜å‚¨é è¿‘æ•°æ®æºï¼Œå‡å°‘å»¶è¿Ÿã€‚æ”¯æŒIoTè®¾å¤‡å®æ—¶å¤„ç†ã€‚"),
        ("å¯æŒç»­è½¯ä»¶å·¥ç¨‹", "ç»¿è‰²è½¯ä»¶å¼€å‘ä¸“æ³¨äºåˆ›å»ºèŠ‚èƒ½åº”ç”¨ç¨‹åºã€‚åŒ…æ‹¬ä»£ç ä¼˜åŒ–å’Œäº‘èµ„æºä¼˜åŒ–ã€‚"),
        ("é›¶ä¿¡ä»»å®‰å…¨æ¨¡å‹", "é›¶ä¿¡ä»»æ¶æ„å‡è®¾æ²¡æœ‰éšå¼ä¿¡ä»»ï¼ŒæŒç»­éªŒè¯æ¯ä¸ªäº‹åŠ¡ã€‚å®ç°æœ€å°æƒé™è®¿é—®ã€‚")
    ];

    let mut knowledge_embeddings = Vec::new();
    for (title, content) in &knowledge {
        let embedding = provider.embed(content)?;
        knowledge_embeddings.push((title, embedding));
        println!("   âœ“ å·²å¤„ç†: {}", title);
    }

    // 4. è¯­ä¹‰æœç´¢æ¼”ç¤º
    println!("\nğŸ” æ™ºèƒ½è¯­ä¹‰æœç´¢æ¼”ç¤º:");
    let queries = vec![
        "å¦‚ä½•å®æ–½è´Ÿè´£ä»»çš„AIå®è·µï¼Ÿ",
        "é‡å­è®¡ç®—æœ€æ–°å‘å±•æ˜¯ä»€ä¹ˆï¼Ÿ",
        "è¾¹ç¼˜è®¡ç®—å¯¹IoTçš„å¥½å¤„",
        "æŠ€æœ¯é¢†åŸŸçš„å¯æŒç»­å‘å±•",
        "ç°ä»£ç½‘ç»œå®‰å…¨æœ€ä½³å®è·µ"
    ];

    for (i, query) in queries.iter().enumerate() {
        println!("\n{}. æŸ¥è¯¢: {}", i + 1, query);
        let query_embedding = provider.embed(query)?;

        let mut similarities = Vec::new();
        for (title, embedding) in &knowledge_embeddings {
            let similarity = calculate_cosine_similarity(&query_embedding, embedding);
            similarities.push((title, similarity));
        }

        similarities.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        println!("   ğŸ¯ æœ€ä½³åŒ¹é…:");
        for (j, (title, similarity)) in similarities.iter().take(2).enumerate() {
            let confidence = if *similarity > 0.7 { "ğŸŸ¢ é«˜" }
                           else if *similarity > 0.5 { "ğŸŸ¡ ä¸­" }
                           else { "ğŸ”´ ä½" };
            println!("      {}. {} - {:.3} {}", j + 1, title, similarity, confidence);
        }
    }

    // 5. .env é…ç½®æŒ‡å—
    println!("\nğŸ“ .env é…ç½®å®Œæ•´æŒ‡å—:");
    println!("   1. åˆ›å»º .env æ–‡ä»¶:");
    println!("      OPENAI_API_KEY=sk-your-real-api-key");
    println!("      OPENAI_MODEL=text-embedding-3-small");
    println!("   2. è·å– API Key:");
    println!("      â€¢ è®¿é—® https://platform.openai.com/api-keys");
    println!("      â€¢ åˆ›å»ºæ–°çš„ secret key");
    println!("      â€¢ å¤åˆ¶å¹¶ç²˜è´´åˆ° .env æ–‡ä»¶");
    println!("   3. å®‰å…¨æé†’:");
    println!("      â€¢ å°† .env æ·»åŠ åˆ° .gitignore");
    println!("      â€¢ ä¸è¦åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API key");
    println!("      â€¢ å®šæœŸè½®æ¢ API key");

    println!("\nğŸš€ æ¼”ç¤ºå®Œæˆï¼");
    if !env::var("OPENAI_API_KEY").unwrap_or_default().starts_with("sk-") {
        println!("ğŸ’¡ é…ç½®çœŸå® API key åé‡æ–°è¿è¡Œï¼Œä½“éªŒçœŸæ­£çš„ OpenAI embedding èƒ½åŠ›ï¼");
    }

    Ok(())
}
