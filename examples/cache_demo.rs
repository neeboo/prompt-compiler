use std::collections::HashMap;
use std::error::Error;
use std::env;
use std::fs;
use std::io::{Write, BufReader, BufRead};

// ç®€åŒ–çš„ .env åŠ è½½
fn load_dotenv() -> Result<(), Box<dyn Error>> {
    if let Ok(content) = fs::read_to_string(".env") {
        for line in content.lines() {
            let line = line.trim();
            if line.starts_with('#') || line.is_empty() { continue; }
            if let Some((key, value)) = line.split_once('=') {
                env::set_var(key.trim(), value.trim().trim_matches('"'));
            }
        }
    }
    Ok(())
}

/// è¯­ä¹‰å—æ•°æ®ç»“æ„
#[derive(Clone, Debug)]
struct SemanticChunk {
    pub id: String,
    pub title: String,
    pub content: String,
    pub embedding: Vec<f32>,
    pub created_at: u64,
    pub access_count: u64,
    pub semantic_tags: Vec<String>,
}

/// æŒä¹…åŒ–è¯­ä¹‰å‹ç¼©ç³»ç»Ÿ
struct PersistentSemanticSystem {
    model: String,
    dimension: usize,
    db_path: String,
    chunks: HashMap<String, SemanticChunk>,
    embedding_cache: HashMap<String, Vec<f32>>,
    stats: SystemStats,
}

#[derive(Debug)]
struct SystemStats {
    total_chunks: usize,
    cache_hits: usize,
    api_calls: usize,
    total_queries: usize,
}

impl PersistentSemanticSystem {
    fn new(db_path: &str) -> Result<Self, Box<dyn Error>> {
        load_dotenv()?;

        let model = env::var("OPENAI_MODEL")
            .unwrap_or_else(|_| "text-embedding-3-large".to_string());

        let dimension = match model.as_str() {
            "text-embedding-3-small" => 1536,
            "text-embedding-3-large" => 3072,
            "text-embedding-ada-002" => 1536,
            _ => 3072,
        };

        let mut system = Self {
            model,
            dimension,
            db_path: db_path.to_string(),
            chunks: HashMap::new(),
            embedding_cache: HashMap::new(),
            stats: SystemStats {
                total_chunks: 0,
                cache_hits: 0,
                api_calls: 0,
                total_queries: 0,
            },
        };

        // å°è¯•ä»ç£ç›˜åŠ è½½ç°æœ‰æ•°æ®
        system.load_from_disk()?;

        Ok(system)
    }

    /// ä»ç£ç›˜åŠ è½½ç°æœ‰æ•°æ® (ç®€åŒ–çš„æ–‡æœ¬æ ¼å¼)
    fn load_from_disk(&mut self) -> Result<(), Box<dyn Error>> {
        let chunks_file = format!("{}/chunks.txt", self.db_path);

        if fs::metadata(&chunks_file).is_ok() {
            println!("ğŸ“‚ ä»ç£ç›˜åŠ è½½ç°æœ‰è¯­ä¹‰åº“...");

            let file = fs::File::open(&chunks_file)?;
            let reader = BufReader::new(file);
            let lines: Vec<String> = reader.lines().collect::<Result<Vec<_>, _>>()?;

            let mut i = 0;
            while i < lines.len() {
                if lines[i].starts_with("CHUNK:") {
                    let id = lines[i].strip_prefix("CHUNK:").unwrap().to_string();
                    let title = lines.get(i+1).unwrap_or(&"".to_string()).clone();
                    let content = lines.get(i+2).unwrap_or(&"".to_string()).clone();

                    // ä½¿ç”¨ get_embedding è€Œä¸æ˜¯ generate_embeddingï¼Œè¿™æ ·ä¼šåˆ©ç”¨ç¼“å­˜
                    let embedding = self.get_embedding(&content)?;

                    let chunk = SemanticChunk {
                        id: id.clone(),
                        title,
                        content,
                        embedding,
                        created_at: 0,
                        access_count: 0,
                        semantic_tags: vec![],
                    };

                    self.chunks.insert(id, chunk);
                    i += 4; // è·³è¿‡åˆ†éš”ç¬¦
                } else {
                    i += 1;
                }
            }

            self.stats.total_chunks = self.chunks.len();
            println!("âœ… æˆåŠŸåŠ è½½ {} ä¸ªè¯­ä¹‰å—", self.chunks.len());
        } else {
            println!("ğŸ“ é¦–æ¬¡è¿è¡Œï¼Œåˆ›å»ºæ–°çš„è¯­ä¹‰åº“");
            fs::create_dir_all(&self.db_path)?;
        }

        Ok(())
    }

    /// ä¿å­˜åˆ°ç£ç›˜ (ç®€åŒ–çš„æ–‡æœ¬æ ¼å¼)
    fn save_to_disk(&self) -> Result<(), Box<dyn Error>> {
        let chunks_file = format!("{}/chunks.txt", self.db_path);
        let mut file = fs::File::create(&chunks_file)?;

        for chunk in self.chunks.values() {
            writeln!(file, "CHUNK:{}", chunk.id)?;
            writeln!(file, "{}", chunk.title)?;
            writeln!(file, "{}", chunk.content)?;
            writeln!(file, "---")?;
        }

        // ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        let stats_file = format!("{}/stats.txt", self.db_path);
        let mut stats_file = fs::File::create(&stats_file)?;
        writeln!(stats_file, "total_chunks:{}", self.stats.total_chunks)?;
        writeln!(stats_file, "cache_hits:{}", self.stats.cache_hits)?;
        writeln!(stats_file, "api_calls:{}", self.stats.api_calls)?;
        writeln!(stats_file, "total_queries:{}", self.stats.total_queries)?;

        println!("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°ç£ç›˜ ({} ä¸ªè¯­ä¹‰å—)", self.chunks.len());
        Ok(())
    }

    /// ç”Ÿæˆembedding
    fn generate_embedding(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        // é«˜è´¨é‡æ¨¡æ‹Ÿembeddingç”Ÿæˆ
        let mut embedding = vec![0.0; self.dimension];
        let bytes = text.as_bytes();

        for (i, &byte) in bytes.iter().enumerate() {
            let idx1 = (i * 7 + byte as usize) % self.dimension;
            let idx2 = (i * 13 + (byte as usize).pow(2)) % self.dimension;
            let idx3 = (i * 19 + (byte as usize).pow(3)) % self.dimension;

            embedding[idx1] += (byte as f32 / 255.0) * 0.8;
            embedding[idx2] += ((byte as f32 * 0.1).sin() + 1.0) * 0.3;
            embedding[idx3] += ((byte as f32 * 0.01).cos() + 1.0) * 0.2;
        }

        // æ·»åŠ è¯­ä¹‰å¢å¼º
        for i in 0..self.dimension {
            let pos_encoding = ((i as f32 / self.dimension as f32) * 2.0 * std::f32::consts::PI).sin() * 0.1;
            embedding[i] += pos_encoding;
        }

        // L2å½’ä¸€åŒ–
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for x in &mut embedding {
                *x /= norm;
            }
        }

        Ok(embedding)
    }

    /// è·å–æˆ–ç”Ÿæˆembedding
    fn get_embedding(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        // æ£€æŸ¥å†…å­˜ç¼“å­˜
        if let Some(cached) = self.embedding_cache.get(text) {
            self.stats.cache_hits += 1;
            println!("   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {:.50}...", text);
            return Ok(cached.clone());
        }

        // ç”Ÿæˆæ–°çš„embedding
        self.stats.api_calls += 1;
        println!("   ğŸŒ ç”Ÿæˆembedding ({})...", self.model);

        let embedding = self.generate_embedding(text)?;
        self.embedding_cache.insert(text.to_string(), embedding.clone());
        Ok(embedding)
    }

    /// æ·»åŠ çŸ¥è¯†å—åˆ°æŒä¹…åŒ–å­˜å‚¨
    fn add_knowledge(&mut self, title: &str, content: &str, tags: Vec<String>) -> Result<(), Box<dyn Error>> {
        let chunk_id = format!("chunk_{:04}", self.chunks.len() + 1);

        // æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if self.chunks.values().any(|c| c.content == content) {
            println!("âš ï¸  å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡: {}", title);
            return Ok(());
        }

        let embedding = self.get_embedding(content)?;
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_secs();

        let chunk = SemanticChunk {
            id: chunk_id.clone(),
            title: title.to_string(),
            content: content.to_string(),
            embedding,
            created_at: timestamp,
            access_count: 0,
            semantic_tags: tags,
        };

        self.chunks.insert(chunk_id.clone(), chunk);
        self.stats.total_chunks = self.chunks.len();

        println!("âœ… å·²æ·»åŠ çŸ¥è¯†: {} (ID: {})", title, chunk_id);

        // è‡ªåŠ¨ä¿å­˜åˆ°ç£ç›˜
        self.save_to_disk()?;
        Ok(())
    }

    /// è¯­ä¹‰æœç´¢
    fn semantic_search(&mut self, query: &str, top_k: usize) -> Result<Vec<(String, String, f32)>, Box<dyn Error>> {
        self.stats.total_queries += 1;
        println!("\nğŸ” è¯­ä¹‰æœç´¢: {}", query);

        let query_embedding = self.get_embedding(query)?;
        let mut similarities = Vec::new();

        for chunk in self.chunks.values() {
            let similarity = cosine_similarity(&query_embedding, &chunk.embedding);
            similarities.push((chunk.id.clone(), chunk.title.clone(), similarity));
        }

        // æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort_by(|a, b| b.2.partial_cmp(&a.2).unwrap());
        similarities.truncate(top_k);

        println!("ğŸ“Š æœç´¢ç»“æœ:");
        for (i, (_, title, similarity)) in similarities.iter().enumerate() {
            let confidence = if *similarity > 0.7 { "ğŸŸ¢ é«˜" }
                           else if *similarity > 0.5 { "ğŸŸ¡ ä¸­" }
                           else { "ğŸ”´ ä½" };
            println!("   {}. {} - ç›¸ä¼¼åº¦: {:.3} {}",
                     i + 1, title, similarity, confidence);
        }

        Ok(similarities)
    }

    /// ç”Ÿæˆå¢å¼ºprompt
    fn generate_enhanced_prompt(&mut self, query: &str, context_results: &[(String, String, f32)]) -> Result<String, Box<dyn Error>> {
        let mut prompt = format!("æŸ¥è¯¢: {}\n\nç›¸å…³ä¸Šä¸‹æ–‡:\n", query);

        for (chunk_id, title, similarity) in context_results {
            if *similarity > 0.3 {
                if let Some(chunk) = self.chunks.get_mut(chunk_id) {
                    chunk.access_count += 1; // æ›´æ–°è®¿é—®è®¡æ•°
                    prompt.push_str(&format!("\n## {} (ç›¸ä¼¼åº¦: {:.3})\n{}\n",
                                           title, similarity, chunk.content));
                }
            }
        }

        prompt.push_str("\nåŸºäºä»¥ä¸Šä¸Šä¸‹æ–‡ï¼Œè¯·æä¾›å‡†ç¡®çš„å›ç­”ã€‚");
        Ok(prompt)
    }

    /// è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    fn get_stats(&self) -> &SystemStats {
        &self.stats
    }

    /// æ¼”ç¤ºç¼“å­˜æ•ˆæœ
    fn demo_cache_effect(&mut self) -> Result<(), Box<dyn Error>> {
        println!("\nğŸ§ª ç¼“å­˜æ•ˆæœæ¼”ç¤º:");

        let test_queries = vec![
            "è¾¹ç¼˜è®¡ç®—åœ¨IoTä¸­çš„åº”ç”¨ï¼Ÿ",
            "é‡å­è®¡ç®—çš„å•†ä¸šå‰æ™¯å¦‚ä½•ï¼Ÿ",
            "è¾¹ç¼˜è®¡ç®—åœ¨IoTä¸­çš„åº”ç”¨ï¼Ÿ", // é‡å¤æŸ¥è¯¢
            "é‡å­è®¡ç®—çš„å•†ä¸šå‰æ™¯å¦‚ä½•ï¼Ÿ", // é‡å¤æŸ¥è¯¢
        ];

        for (i, query) in test_queries.iter().enumerate() {
            println!("\n--- æµ‹è¯•æŸ¥è¯¢ {} ---", i + 1);
            let _embedding = self.get_embedding(query)?;
        }

        Ok(())
    }
}

fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm_a == 0.0 || norm_b == 0.0 { 0.0 } else { dot_product / (norm_a * norm_b) }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸš€ ç¼“å­˜æ•ˆæœéªŒè¯æ¼”ç¤º");
    println!("=====================================");

    // 1. åˆå§‹åŒ–æŒä¹…åŒ–ç³»ç»Ÿ
    let mut system = PersistentSemanticSystem::new("./cache_test_db")?;
    println!("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ - æ¨¡å‹: {}, ç»´åº¦: {}", system.model, system.dimension);

    // 2. æ·»åŠ å°‘é‡æµ‹è¯•æ•°æ®
    println!("\nğŸ“š æ·»åŠ æµ‹è¯•æ•°æ®...");

    let knowledge_entries = vec![
        ("è¾¹ç¼˜è®¡ç®—",
         "è¾¹ç¼˜è®¡ç®—å°†æ•°æ®å¤„ç†èƒ½åŠ›éƒ¨ç½²åˆ°ç½‘ç»œè¾¹ç¼˜ï¼Œå‡å°‘å»¶è¿Ÿå¹¶æé«˜å“åº”é€Ÿåº¦ã€‚",
         vec!["è¾¹ç¼˜è®¡ç®—".to_string()]),

        ("é‡å­è®¡ç®—",
         "é‡å­è®¡ç®—æ­£ä»å®éªŒå®¤èµ°å‘å•†ä¸šåº”ç”¨ï¼Œå…·æœ‰å·¨å¤§çš„å•†ä¸šæ½œåŠ›ã€‚",
         vec!["é‡å­è®¡ç®—".to_string()]),
    ];

    for (title, content, tags) in knowledge_entries {
        system.add_knowledge(title, content, tags)?;
    }

    // 3. ç¼“å­˜æ•ˆæœæ¼”ç¤º
    system.demo_cache_effect()?;

    // 4. æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    println!("\nğŸ“Š ç¼“å­˜æ•ˆæœåˆ†æ:");
    let stats = system.get_stats();

    println!("   ğŸ“š æ€»è¯­ä¹‰å—æ•°: {}", stats.total_chunks);
    println!("   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {} æ¬¡", stats.cache_hits);
    println!("   ğŸŒ APIè°ƒç”¨: {} æ¬¡", stats.api_calls);

    let cache_hit_rate = if stats.api_calls + stats.cache_hits > 0 {
        (stats.cache_hits as f32 / (stats.api_calls + stats.cache_hits) as f32) * 100.0
    } else { 0.0 };
    println!("   ğŸ“ˆ ç¼“å­˜å‘½ä¸­ç‡: {:.1}%", cache_hit_rate);

    // 5. è¯´æ˜ç¼“å­˜é€»è¾‘
    println!("\nğŸ’¡ ç¼“å­˜æœºåˆ¶è¯´æ˜:");
    println!("   âœ… ç›¸åŒæ–‡æœ¬å†…å®¹ â†’ ç¼“å­˜å‘½ä¸­");
    println!("   âŒ ä¸åŒæ–‡æœ¬å†…å®¹ â†’ éœ€è¦ç”Ÿæˆæ–°embedding");
    println!("   ğŸ”„ è¿™æ˜¯æ­£å¸¸çš„ç¼“å­˜è¡Œä¸ºï¼Œé¿å…äº†é‡å¤è®¡ç®—ç›¸åŒå†…å®¹");

    Ok(())
}
