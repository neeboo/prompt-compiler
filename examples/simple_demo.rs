use prompt_compiler_storage::{
    SemanticChunk, ContextInjectionStrategy, StateDB, CompilationStats
};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§  è¯­ä¹‰å‹ç¼©ä¸ä¸Šä¸‹æ–‡æ³¨å…¥ç³»ç»Ÿæ¼”ç¤º");
    println!("==========================================");

    // åˆå§‹åŒ–å­˜å‚¨ç³»ç»Ÿ
    println!("âœ… æ­£åœ¨åˆå§‹åŒ–å­˜å‚¨ç³»ç»Ÿ...");
    let db = StateDB::new("./demo_semantic_db")?;
    println!("âœ… å­˜å‚¨ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ");

    // æ¨¡æ‹Ÿå‹ç¼©ä¸€äº›çŸ¥è¯†ç‰‡æ®µ
    println!("\nğŸ“¦ å‹ç¼©å¹¶å­˜å‚¨çŸ¥è¯†ç‰‡æ®µ...");

    let knowledge = [
        ("æœºå™¨å­¦ä¹ ", "æœºå™¨å­¦ä¹ æ˜¯AIçš„æ ¸å¿ƒåˆ†æ”¯ï¼Œé€šè¿‡ç®—æ³•è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼"),
        ("åŒºå—é“¾", "åŒºå—é“¾æ˜¯åˆ†å¸ƒå¼è´¦æœ¬æŠ€æœ¯ï¼Œé€šè¿‡å¯†ç å­¦ç¡®ä¿æ•°æ®ä¸å¯ç¯¡æ”¹"),
        ("é‡å­è®¡ç®—", "é‡å­è®¡ç®—åˆ©ç”¨é‡å­åŠ›å­¦åŸç†ï¼Œé‡å­æ¯”ç‰¹å¯åŒæ—¶å¤„äº0å’Œ1çŠ¶æ€"),
    ];

    for (title, content) in knowledge.iter() {
        // ç”Ÿæˆç®€å•çš„æ¨¡æ‹Ÿembedding
        let embedding: Vec<f32> = (0..128).map(|i| (i as f32 * 0.1).sin()).collect();

        let chunk = db.compress_and_store_context(
            &format!("æ ‡é¢˜: {}\nå†…å®¹: {}", title, content),
            embedding
        )?;

        println!("   âœ“ {}: {}å­—èŠ‚ â†’ {}å­—èŠ‚ (å‹ç¼©æ¯”: {:.1}%)",
                title, chunk.original_size, chunk.compressed_size,
                chunk.compression_ratio * 100.0);
    }

    // æ¼”ç¤ºä¸Šä¸‹æ–‡æ³¨å…¥
    println!("\nğŸ” æ¼”ç¤ºä¸Šä¸‹æ–‡æ³¨å…¥ç­–ç•¥...");
    let user_query = "æˆ‘æƒ³äº†è§£äººå·¥æ™ºèƒ½ç›¸å…³æŠ€æœ¯";
    let query_embedding: Vec<f32> = (0..128).map(|i| (i as f32 * 0.05).sin()).collect();

    println!("ç”¨æˆ·æŸ¥è¯¢: {}", user_query);

    // ç›´æ¥å‘é€ç­–ç•¥
    println!("\nğŸ“¤ ç­–ç•¥1: ç›´æ¥å‘é€");
    let strategy = ContextInjectionStrategy::DirectSend { max_tokens: 200 };
    let result = db.inject_context(user_query, &strategy, &query_embedding)?;
    println!("ç»“æœ: {}", &result[..result.len().min(150)]);

    // è¯­ä¹‰æ³¨å…¥ç­–ç•¥
    println!("\nâš¡ ç­–ç•¥2: è¯­ä¹‰æ³¨å…¥");
    let strategy = ContextInjectionStrategy::SemanticInject { similarity_threshold: 0.5 };
    let result = db.inject_context(user_query, &strategy, &query_embedding)?;
    println!("ç»“æœ: {}", result);

    // æ£€ç´¢æµ‹è¯•
    println!("\nğŸ¯ è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢æµ‹è¯•...");
    let chunks = db.retrieve_by_semantic_similarity(&query_embedding, 0.3, 2)?;
    println!("æ‰¾åˆ° {} ä¸ªç›¸å…³è¯­ä¹‰å—", chunks.len());

    // ç»Ÿè®¡ä¿¡æ¯
    println!("\nğŸ“Š æ›´æ–°ç³»ç»Ÿç»Ÿè®¡...");
    let stats = CompilationStats {
        total_compilations: 50,
        avg_compilation_time_ms: 125.0,
        avg_weight_updates_per_prompt: 6.5,
        most_common_targets: vec!["GPT-4".to_string()],
        convergence_rate: 0.82,
        semantic_compression_ratio: 0.25, // 25%å‹ç¼©æ¯”
        avg_chunk_reuse_rate: 0.68,
        context_injection_success_rate: 0.89,
    };

    db.update_compilation_stats(&stats)?;

    println!("\nğŸ‰ ç³»ç»Ÿä¼˜åŠ¿æ€»ç»“:");
    println!("   â€¢ è¯­ä¹‰å‹ç¼©: {:.1}% å‹ç¼©æ¯”", stats.semantic_compression_ratio * 100.0);
    println!("   â€¢ æ”¶æ•›ç‡: {:.1}%", stats.convergence_rate * 100.0);
    println!("   â€¢ æ³¨å…¥æˆåŠŸç‡: {:.1}%", stats.context_injection_success_rate * 100.0);

    println!("\nâœ¨ æ¼”ç¤ºå®Œæˆï¼è¯­ä¹‰å‹ç¼©ç³»ç»ŸæˆåŠŸå±•ç¤ºäº†æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†èƒ½åŠ›ã€‚");
    Ok(())
}
