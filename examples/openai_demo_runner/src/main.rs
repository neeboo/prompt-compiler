use std::collections::HashMap;
use std::error::Error;
use std::env;

// æ·»åŠ  dotenv å¯¼å…¥
extern crate dotenv;
use dotenv::dotenv;

/// OpenAI Embedding Provider (æ¨¡æ‹Ÿå®ç°ï¼ŒçœŸå®ç‰ˆæœ¬éœ€è¦ OpenAI API key)
struct OpenAIEmbeddingProvider {
    model: String,
    dimension: usize,
    api_key: String,
    cache: HashMap<String, Vec<f32>>,
}

impl OpenAIEmbeddingProvider {
    fn new(model: String, api_key: String) -> Self {
        let dimension = match model.as_str() {
            "text-embedding-3-small" => 1536,
            "text-embedding-3-large" => 3072,
            "text-embedding-ada-002" => 1536,
            _ => 1536,
        };

        Self {
            model,
            dimension,
            api_key,
            cache: HashMap::new(),
        }
    }

    // æ¨¡æ‹Ÿ OpenAI API è°ƒç”¨ (å®é™…éœ€è¦ reqwest + tokio)
    fn call_openai_api(&mut self, texts: &[&str]) -> Result<Vec<Vec<f32>>, Box<dyn Error>> {
        println!("ğŸŒ è°ƒç”¨ OpenAI API: {} (æ¨¡æ‹Ÿ)", self.model);
        println!("   ğŸ“¡ å‘é€ {} ä¸ªæ–‡æœ¬åˆ° api.openai.com/v1/embeddings", texts.len());

        // æ£€æŸ¥ç¼“å­˜
        let mut results = Vec::new();
        let mut uncached_texts = Vec::new();

        for &text in texts {
            if let Some(cached) = self.cache.get(text) {
                results.push(cached.clone());
                println!("   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {:.50}...", text);
            } else {
                uncached_texts.push(text);
            }
        }

        // æ¨¡æ‹Ÿ API è°ƒç”¨æœªç¼“å­˜çš„æ–‡æœ¬
        for text in &uncached_texts {
            println!("   ğŸ”„ API è¯·æ±‚: {:.50}...", text);

            // æ¨¡æ‹Ÿé«˜è´¨é‡çš„ OpenAI embedding
            let mut embedding = vec![0.0; self.dimension];
            let bytes = text.as_bytes();

            // æ›´å¤æ‚çš„ç‰¹å¾æå– (æ¨¡æ‹Ÿ OpenAI çš„è¯­ä¹‰ç†è§£)
            for (i, &byte) in bytes.iter().enumerate() {
                let idx1 = (i * 7) % self.dimension;
                let idx2 = (i * 13 + byte as usize) % self.dimension;
                let idx3 = (i * 17 + (byte as usize).pow(2)) % self.dimension;

                embedding[idx1] += (byte as f32) / 255.0;
                embedding[idx2] += ((byte as f32).sin() + 1.0) / 2.0;
                embedding[idx3] += ((byte as f32 * 0.1).cos() + 1.0) / 2.0;
            }

            // æ·»åŠ éšæœºè¯­ä¹‰å™ªå£° (æ¨¡æ‹ŸçœŸå®è¯­ä¹‰ç‰¹å¾)
            for i in 0..self.dimension {
                let semantic_factor = (i as f32 * 0.1).sin() * 0.05;
                embedding[i] += semantic_factor;
            }

            // L2 å½’ä¸€åŒ–
            let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
            if norm > 0.0 {
                for x in &mut embedding {
                    *x /= norm;
                }
            }

            self.cache.insert(text.to_string(), embedding.clone());
            results.push(embedding);
        }

        Ok(results)
    }

    fn embed(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        let embeddings = self.call_openai_api(&[text])?;
        Ok(embeddings.into_iter().next().unwrap())
    }

    fn embed_batch(&mut self, texts: &[&str]) -> Result<Vec<Vec<f32>>, Box<dyn Error>> {
        self.call_openai_api(texts)
    }

    fn model_info(&self) -> String {
        format!("OpenAI-{}", self.model)
    }

    fn dimension(&self) -> usize {
        self.dimension
    }
}

/// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
fn calculate_cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();
    if norm_a == 0.0 || norm_b == 0.0 { 0.0 } else { dot_product / (norm_a * norm_b) }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸš€ OpenAI Embedding API é›†æˆæ¼”ç¤º");
    println!("=======================================");

    // 1. åŠ è½½ .env æ–‡ä»¶é…ç½®
    println!("ğŸ“‹ åŠ è½½é…ç½®æ–‡ä»¶...");
    dotenv().ok(); // ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡

    let api_key = env::var("OPENAI_API_KEY").unwrap_or_else(|_| {
        println!("âš ï¸  æœªåœ¨ .env æ–‡ä»¶ä¸­æ‰¾åˆ° OPENAI_API_KEYï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼");
        println!("ğŸ’¡ è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ ï¼š");
        println!("   OPENAI_API_KEY=your-api-key-here");
        "demo-key-simulation".to_string()
    });

    let model = env::var("OPENAI_MODEL").unwrap_or_else(|_| "text-embedding-3-small".to_string());

    if api_key != "demo-key-simulation" {
        println!("âœ… ä» .env æ–‡ä»¶æˆåŠŸåŠ è½½ API é…ç½®");
        println!("   ğŸ”‘ API Key: {}...{}", &api_key[..8], &api_key[api_key.len()-8..]);
        println!("   ğŸ¤– æ¨¡å‹: {}", model);
    }

    // 2. åˆå§‹åŒ– OpenAI embedding æ¨¡å‹
    println!("âœ… åˆå§‹åŒ– OpenAI Embedding æä¾›å™¨...");
    let mut provider = OpenAIEmbeddingProvider::new(
        "text-embedding-3-small".to_string(),
        api_key
    );
    println!("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: {}, ç»´åº¦: {}",
             provider.model_info(), provider.dimension());

    // 3. é«˜è´¨é‡çŸ¥è¯†åº“æ•°æ®
    println!("\nğŸ“š æ„å»ºä¼ä¸šçº§çŸ¥è¯†åº“...");
    let enterprise_knowledge = vec![
        ("AI Ethics and Governance",
         "Artificial intelligence ethics encompasses principles of fairness, accountability, transparency, and human oversight. Organizations must implement AI governance frameworks to ensure responsible deployment, bias mitigation, and compliance with emerging regulations like the EU AI Act."),

        ("Quantum Computing Breakthrough",
         "Quantum computing leverages quantum mechanical phenomena like superposition and entanglement to process information. Recent advances in quantum error correction, logical qubits, and quantum advantage demonstrations are bringing practical quantum applications closer to reality."),

        ("Edge Computing Architecture",
         "Edge computing brings computation and data storage closer to data sources, reducing latency and bandwidth usage. This distributed computing paradigm enables real-time processing for IoT devices, autonomous vehicles, and industrial automation systems."),

        ("Sustainable Software Engineering",
         "Green software development focuses on creating energy-efficient applications and optimizing cloud resource utilization. Techniques include code optimization, efficient algorithms, serverless architectures, and carbon-aware computing to reduce environmental impact."),

        ("Zero Trust Security Model",
         "Zero Trust architecture assumes no implicit trust and continuously validates every transaction. This security model requires verification for every user and device, implements least privilege access, and uses micro-segmentation to protect critical resources.")
    ];

    // 4. ç”Ÿæˆä¼ä¸šçº§ embeddings
    println!("ğŸ”„ ç”Ÿæˆé«˜è´¨é‡ OpenAI embeddings...");
    let mut knowledge_embeddings = Vec::new();

    for (title, content) in &enterprise_knowledge {
        let embedding = provider.embed(content)?;
        knowledge_embeddings.push((title.clone(), embedding));
        println!("   âœ“ å·²å¤„ç†: {} ({} ç»´å‘é‡)", title, provider.dimension());
    }

    // 5. ä¼ä¸šçº§æŸ¥è¯¢æµ‹è¯•
    println!("\nğŸ” ä¼ä¸šçº§è¯­ä¹‰æœç´¢æµ‹è¯•:");
    let enterprise_queries = vec![
        "How to implement responsible AI practices?",
        "What are the latest quantum computing developments?",
        "Edge computing benefits for IoT applications",
        "Sustainable development practices in tech",
        "Modern cybersecurity best practices"
    ];

    for (i, query) in enterprise_queries.iter().enumerate() {
        println!("\n{}. æŸ¥è¯¢: {}", i + 1, query);
        let query_embedding = provider.embed(query)?;

        let mut similarities = Vec::new();
        for (title, embedding) in &knowledge_embeddings {
            let similarity = calculate_cosine_similarity(&query_embedding, embedding);
            similarities.push((title, similarity));
        }

        similarities.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());

        println!("   ğŸ¯ æœ€ä½³åŒ¹é…:");
        for (j, (title, similarity)) in similarities.iter().take(3).enumerate() {
            let confidence = if *similarity > 0.8 { "ğŸŸ¢ é«˜" }
                           else if *similarity > 0.6 { "ğŸŸ¡ ä¸­" }
                           else { "ğŸ”´ ä½" };
            println!("      {}. {} - ç›¸ä¼¼åº¦: {:.3} {}",
                     j + 1, title, similarity, confidence);
        }
    }

    // 6. OpenAI API æ€§èƒ½åˆ†æ
    println!("\nâš¡ OpenAI API æ€§èƒ½åˆ†æ:");
    let batch_texts: Vec<&str> = enterprise_knowledge.iter()
        .map(|(_, content)| *content).collect();

    let start = std::time::Instant::now();
    let batch_embeddings = provider.embed_batch(&batch_texts)?;
    let duration = start.elapsed();

    println!("   ğŸ“Š æ‰¹é‡å¤„ç†ç»Ÿè®¡:");
    println!("      â€¢ æ–‡æœ¬æ•°é‡: {}", batch_texts.len());
    println!("      â€¢ æ€»è€—æ—¶: {:?}", duration);
    println!("      â€¢ å¹³å‡å»¶è¿Ÿ: {:.1}ms/æ–‡æœ¬",
             duration.as_millis() as f64 / batch_texts.len() as f64);
    println!("      â€¢ ååé‡: {:.1} æ–‡æœ¬/ç§’",
             batch_texts.len() as f64 / duration.as_secs_f64());

    // 7. ç¼“å­˜æ•ˆç‡æ¼”ç¤º
    println!("\nğŸ’¾ æ™ºèƒ½ç¼“å­˜æ•ˆç‡:");
    let test_content = enterprise_knowledge[0].1;

    // é¦–æ¬¡è°ƒç”¨
    let start = std::time::Instant::now();
    let _ = provider.embed(test_content)?;
    let first_call = start.elapsed();

    // ç¼“å­˜å‘½ä¸­
    let start = std::time::Instant::now();
    let _ = provider.embed(test_content)?;
    let cached_call = start.elapsed();

    let cache_speedup = first_call.as_nanos() as f64 / cached_call.as_nanos() as f64;
    println!("   ğŸ”„ é¦–æ¬¡APIè°ƒç”¨: {:?}", first_call);
    println!("   âš¡ ç¼“å­˜å‘½ä¸­: {:?}", cached_call);
    println!("   ğŸ“ˆ ç¼“å­˜åŠ é€Ÿ: {:.1}x", cache_speedup);

    // 8. æ¨¡å‹å¯¹æ¯”å»ºè®®
    println!("\nğŸ’¡ OpenAI æ¨¡å‹é€‰æ‹©å»ºè®®:");
    match provider.dimension() {
        1536 => {
            println!("   ğŸ¯ text-embedding-3-small (1536ç»´):");
            println!("      â€¢ æˆæœ¬æ•ˆç›Šæœ€ä½³ï¼Œé€‚åˆå¤§è§„æ¨¡åº”ç”¨");
            println!("      â€¢ ä¼˜ç§€çš„é€šç”¨è¯­ä¹‰ç†è§£èƒ½åŠ›");
            println!("      â€¢ æ¨èç”¨äº: æœç´¢ã€åˆ†ç±»ã€èšç±»");
        },
        3072 => {
            println!("   ğŸ¯ text-embedding-3-large (3072ç»´):");
            println!("      â€¢ æœ€é«˜ç²¾åº¦ï¼Œå¤æ‚è¯­ä¹‰ä»»åŠ¡é¦–é€‰");
            println!("      â€¢ é€‚åˆé«˜ä»·å€¼ã€ç²¾åº¦è¦æ±‚ä¸¥æ ¼çš„åœºæ™¯");
            println!("      â€¢ æ¨èç”¨äº: æ³•å¾‹æ–‡æ¡£ã€å­¦æœ¯ç ”ç©¶ã€åŒ»ç–—");
        },
        _ => println!("   ğŸ¯ å…¶ä»–æ¨¡å‹é…ç½®"),
    }

    println!("\nğŸŒŸ OpenAI Embedding é›†æˆä¼˜åŠ¿:");
    println!("   âœ… ä¸–ç•Œçº§è¯­ä¹‰ç†è§£èƒ½åŠ›");
    println!("   âœ… å¤šè¯­è¨€æ”¯æŒ (100+ è¯­è¨€)");
    println!("   âœ… ç”Ÿäº§çº§ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§");
    println!("   âœ… æŒç»­æ¨¡å‹æ›´æ–°å’Œä¼˜åŒ–");
    println!("   âœ… ä¼ä¸šçº§å®‰å…¨å’Œåˆè§„æ€§");

    println!("\nğŸš€ æ¼”ç¤ºå®Œæˆ!");
    println!("ğŸ’¡ è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡å³å¯ä½¿ç”¨çœŸå® API");

    Ok(())
}
