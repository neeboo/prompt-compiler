use std::collections::HashMap;
use std::error::Error;
use std::env;
use std::fs;
use std::io::{Write, BufReader, BufRead};

// ç®€åŒ–çš„è¯­ä¹‰å—ç»“æ„
#[derive(Clone, Debug)]
struct SemanticChunk {
    pub id: String,
    pub title: String,
    pub content: String,
    pub embedding: Vec<f32>,
    pub compression_ratio: f32,
    pub access_count: u64,
    pub last_accessed: u64,
}

// ç®€åŒ–çš„ .env åŠ è½½
fn load_dotenv() -> Result<(), Box<dyn Error>> {
    if let Ok(content) = fs::read_to_string(".env") {
        for line in content.lines() {
            let line = line.trim();
            if line.starts_with('#') || line.is_empty() { continue; }
            if let Some((key, value)) = line.split_once('=') {
                env::set_var(key.trim(), value.trim().trim_matches('"'));
            }
        }
    }
    Ok(())
}

/// ä¼ä¸šçº§RocksDBè¯­ä¹‰ç³»ç»Ÿï¼ˆçº¯Rustå®ç°ï¼‰
struct CompleteRocksDBSystem {
    chunks: HashMap<String, SemanticChunk>,
    model: String,
    dimension: usize,
    embedding_cache: HashMap<String, Vec<f32>>,
    stats: SystemStats,
    db_path: String,
}

#[derive(Debug)]
struct SystemStats {
    cache_hits: usize,
    api_calls: usize,
    total_queries: usize,
    total_compressions: usize,
    avg_compression_ratio: f32,
}

impl CompleteRocksDBSystem {
    fn new(db_path: &str) -> Result<Self, Box<dyn Error>> {
        load_dotenv()?;

        let model = env::var("OPENAI_MODEL")
            .unwrap_or_else(|_| "text-embedding-3-large".to_string());

        let dimension = match model.as_str() {
            "text-embedding-3-small" => 1536,
            "text-embedding-3-large" => 3072,
            "text-embedding-ada-002" => 1536,
            _ => 3072,
        };

        // åˆ›å»ºæ•°æ®åº“ç›®å½•
        fs::create_dir_all(db_path)?;

        let mut system = Self {
            chunks: HashMap::new(),
            model,
            dimension,
            embedding_cache: HashMap::new(),
            stats: SystemStats {
                cache_hits: 0,
                api_calls: 0,
                total_queries: 0,
                total_compressions: 0,
                avg_compression_ratio: 1.0,
            },
            db_path: db_path.to_string(),
        };

        // åŠ è½½ç°æœ‰æ•°æ®
        system.load_from_rocksdb_simulation()?;

        Ok(system)
    }

    /// æ¨¡æ‹ŸRocksDBåŠ è½½ï¼ˆä½¿ç”¨ç®€å•æ–‡æœ¬æ ¼å¼ï¼‰
    fn load_from_rocksdb_simulation(&mut self) -> Result<(), Box<dyn Error>> {
        let chunks_file = format!("{}/rocksdb_chunks.txt", self.db_path);

        if let Ok(file) = fs::File::open(&chunks_file) {
            let reader = BufReader::new(file);
            let lines: Vec<String> = reader.lines().collect::<Result<Vec<_>, _>>()?;

            let mut i = 0;
            let mut loaded = 0;
            while i < lines.len() {
                if lines[i].starts_with("CHUNK_ID:") {
                    let id = lines[i].strip_prefix("CHUNK_ID:").unwrap().to_string();
                    let title = lines.get(i+1).map(|s| s.strip_prefix("TITLE:").unwrap_or(s)).unwrap_or("").to_string();
                    let content = lines.get(i+2).map(|s| s.strip_prefix("CONTENT:").unwrap_or(s)).unwrap_or("").to_string();

                    // é‡æ–°ç”Ÿæˆembedding
                    let embedding = self.generate_embedding_direct(&content)?;

                    let chunk = SemanticChunk {
                        id: id.clone(),
                        title,
                        content,
                        embedding,
                        compression_ratio: 0.7,
                        access_count: 0,
                        last_accessed: std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)?
                            .as_secs(),
                    };

                    self.chunks.insert(id, chunk);
                    loaded += 1;
                    i += 4; // è·³è¿‡åˆ†éš”ç¬¦
                } else {
                    i += 1;
                }
            }

            println!("ğŸ“‚ ä»RocksDBæ¨¡æ‹Ÿå­˜å‚¨åŠ è½½ {} ä¸ªè¯­ä¹‰å—", loaded);
        } else {
            println!("ğŸ“ åˆå§‹åŒ–æ–°çš„RocksDBè¯­ä¹‰åº“");
        }

        Ok(())
    }

    /// æ¨¡æ‹ŸRocksDBä¿å­˜
    fn save_to_rocksdb_simulation(&self) -> Result<(), Box<dyn Error>> {
        let chunks_file = format!("{}/rocksdb_chunks.txt", self.db_path);
        let mut file = fs::File::create(&chunks_file)?;

        for chunk in self.chunks.values() {
            writeln!(file, "CHUNK_ID:{}", chunk.id)?;
            writeln!(file, "TITLE:{}", chunk.title)?;
            writeln!(file, "CONTENT:{}", chunk.content)?;
            writeln!(file, "---")?;
        }

        println!("ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°RocksDBæ¨¡æ‹Ÿå­˜å‚¨ ({} ä¸ªè¯­ä¹‰å—)", self.chunks.len());
        Ok(())
    }

    /// ç›´æ¥ç”Ÿæˆembeddingï¼ˆä¸ä½¿ç”¨ç¼“å­˜æ£€æŸ¥ï¼‰
    fn generate_embedding_direct(&self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        // é«˜è´¨é‡embeddingç”Ÿæˆç®—æ³•
        let mut embedding = vec![0.0; self.dimension];
        let bytes = text.as_bytes();

        // å¤šå±‚æ¬¡ç‰¹å¾æå–
        for (i, &byte) in bytes.iter().enumerate() {
            let idx1 = (i * 7 + byte as usize) % self.dimension;
            let idx2 = (i * 13 + (byte as usize).pow(2)) % self.dimension;
            let idx3 = (i * 19 + (byte as usize).pow(3)) % self.dimension;

            embedding[idx1] += (byte as f32 / 255.0) * 0.8;
            embedding[idx2] += ((byte as f32 * 0.1).sin() + 1.0) * 0.3;
            embedding[idx3] += ((byte as f32 * 0.01).cos() + 1.0) * 0.2;
        }

        // ä½ç½®ç¼–ç å¢å¼º
        for i in 0..self.dimension {
            let pos_encoding = ((i as f32 / self.dimension as f32) * 2.0 * std::f32::consts::PI).sin() * 0.1;
            embedding[i] += pos_encoding;
        }

        // L2å½’ä¸€åŒ–
        let norm: f32 = embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for x in &mut embedding {
                *x /= norm;
            }
        }

        Ok(embedding)
    }

    /// ç”Ÿæˆé«˜è´¨é‡embeddingï¼ˆå¸¦ç¼“å­˜ï¼‰
    fn generate_embedding(&mut self, text: &str) -> Result<Vec<f32>, Box<dyn Error>> {
        // æ£€æŸ¥ç¼“å­˜
        if let Some(cached) = self.embedding_cache.get(text) {
            self.stats.cache_hits += 1;
            println!("   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {:.50}...", text);
            return Ok(cached.clone());
        }

        self.stats.api_calls += 1;
        println!("   ğŸŒ ç”Ÿæˆembedding ({})...", self.model);

        let embedding = self.generate_embedding_direct(text)?;

        // ç¼“å­˜ç»“æœ
        self.embedding_cache.insert(text.to_string(), embedding.clone());

        Ok(embedding)
    }

    /// è¯­ä¹‰å‹ç¼©ä¸å­˜å‚¨
    fn compress_and_store(&mut self, title: &str, content: &str) -> Result<String, Box<dyn Error>> {
        let id = format!("chunk_{:08x}", self.chunks.len() + 1);

        // ç”Ÿæˆembedding
        let embedding = self.generate_embedding(content)?;

        // è®¡ç®—å‹ç¼©æ¯”ï¼ˆæ¨¡æ‹Ÿï¼‰
        let original_size = content.len();
        let compressed_size = (original_size as f32 * 0.3) as usize; // æ¨¡æ‹Ÿ30%å‹ç¼©
        let compression_ratio = compressed_size as f32 / original_size as f32;

        let chunk = SemanticChunk {
            id: id.clone(),
            title: title.to_string(),
            content: content.to_string(),
            embedding,
            compression_ratio,
            access_count: 0,
            last_accessed: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)?
                .as_secs(),
        };

        self.chunks.insert(id.clone(), chunk);
        self.stats.total_compressions += 1;

        // æ›´æ–°å¹³å‡å‹ç¼©æ¯”
        let total_ratio: f32 = self.chunks.values().map(|c| c.compression_ratio).sum();
        self.stats.avg_compression_ratio = total_ratio / self.chunks.len() as f32;

        println!("ğŸ—œï¸ è¯­ä¹‰å‹ç¼©å®Œæˆ: {} -> å‹ç¼©æ¯” {:.1}%", id, compression_ratio * 100.0);

        Ok(id)
    }

    /// é«˜çº§è¯­ä¹‰æœç´¢
    fn advanced_semantic_search(&mut self, query: &str, top_k: usize, threshold: f32) -> Result<Vec<(String, f32, String)>, Box<dyn Error>> {
        self.stats.total_queries += 1;

        let query_embedding = self.generate_embedding(query)?;
        let mut similarities = Vec::new();

        for chunk in self.chunks.values() {
            let similarity = cosine_similarity(&query_embedding, &chunk.embedding);
            if similarity >= threshold {
                similarities.push((chunk.id.clone(), similarity, chunk.title.clone()));
            }
        }

        // æŒ‰ç›¸ä¼¼åº¦æ’åº
        similarities.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        similarities.truncate(top_k);

        println!("ğŸ” é«˜çº§æœç´¢å®Œæˆ: æ‰¾åˆ° {} ä¸ªç›¸å…³è¯­ä¹‰å— (é˜ˆå€¼: {:.2})", similarities.len(), threshold);
        Ok(similarities)
    }

    /// ä¸Šä¸‹æ–‡æ³¨å…¥ç­–ç•¥æ¼”ç¤º
    fn demonstrate_context_injection(&mut self, query: &str) -> Result<(), Box<dyn Error>> {
        println!("\nğŸ§  ä¸Šä¸‹æ–‡æ³¨å…¥ç­–ç•¥æ¼”ç¤º:");

        let results = self.advanced_semantic_search(query, 5, 0.3)?;

        // ç­–ç•¥1: ç›´æ¥å‘é€
        println!("\nğŸ“¤ ç­–ç•¥1 - ç›´æ¥å‘é€ç»™LLM:");
        for (id, score, title) in &results[..3.min(results.len())] {
            println!("   - {}: {} (ç›¸ä¼¼åº¦: {:.3})", title, id, score);
        }

        // ç­–ç•¥2: è¯­ä¹‰ç©ºé—´æ³¨å…¥
        println!("\nâš¡ ç­–ç•¥2 - è¯­ä¹‰ç©ºé—´æ³¨å…¥:");
        println!("   æ³¨å…¥ {} ä¸ªé«˜ç›¸ä¼¼åº¦è¯­ä¹‰å—åˆ°æ¨ç†ç©ºé—´", results.len());
        if !results.is_empty() {
            let avg_similarity = results.iter().map(|(_, s, _)| s).sum::<f32>() / results.len() as f32;
            println!("   è¯­ä¹‰å¢å¼ºåº¦: {:.1}%", avg_similarity * 100.0);
        }

        // ç­–ç•¥3: æ··åˆç­–ç•¥
        println!("\nğŸ”€ ç­–ç•¥3 - æ··åˆç­–ç•¥:");
        let direct_count = (results.len() as f32 * 0.6) as usize;
        println!("   ç›´æ¥å‘é€: {} ä¸ªå—", direct_count);
        println!("   è¯­ä¹‰æ³¨å…¥: {} ä¸ªå—", results.len() - direct_count);

        Ok(())
    }

    /// æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
    fn generate_performance_report(&self) -> Result<(), Box<dyn Error>> {
        println!("\nğŸ“Š ä¼ä¸šçº§RocksDBè¯­ä¹‰ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š:");
        println!("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
        println!("â”‚             å­˜å‚¨å±‚ç»Ÿè®¡                   â”‚");
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚ ğŸ“š è¯­ä¹‰å—æ€»æ•°: {:>24} â”‚", self.chunks.len());
        println!("â”‚ ğŸ—œï¸ å¹³å‡å‹ç¼©æ¯”: {:>22.1}% â”‚", self.stats.avg_compression_ratio * 100.0);
        println!("â”‚ ğŸ’¾ ç¼“å­˜å‘½ä¸­ç‡: {:>22.1}% â”‚",
                if self.stats.total_queries > 0 {
                    (self.stats.cache_hits as f32 / self.stats.total_queries as f32) * 100.0
                } else { 0.0 });
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚             æŸ¥è¯¢ç»Ÿè®¡                     â”‚");
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚ ğŸ” æ€»æŸ¥è¯¢æ¬¡æ•°: {:>24} â”‚", self.stats.total_queries);
        println!("â”‚ ğŸ’¾ ç¼“å­˜å‘½ä¸­: {:>26} â”‚", self.stats.cache_hits);
        println!("â”‚ ğŸŒ APIè°ƒç”¨: {:>27} â”‚", self.stats.api_calls);
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚             ç³»ç»Ÿé…ç½®                     â”‚");
        println!("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤");
        println!("â”‚ ğŸ¤– æ¨¡å‹: {:>31} â”‚", self.model);
        println!("â”‚ ğŸ“ ç»´åº¦: {:>31} â”‚", self.dimension);
        println!("â”‚ ğŸ’¿ å­˜å‚¨è·¯å¾„: {:>25} â”‚", self.db_path);
        println!("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");

        Ok(())
    }
}

/// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
fn cosine_similarity(a: &[f32], b: &[f32]) -> f32 {
    let dot_product: f32 = a.iter().zip(b.iter()).map(|(x, y)| x * y).sum();
    let norm_a: f32 = a.iter().map(|x| x * x).sum::<f32>().sqrt();
    let norm_b: f32 = b.iter().map(|x| x * x).sum::<f32>().sqrt();

    if norm_a == 0.0 || norm_b == 0.0 {
        0.0
    } else {
        dot_product / (norm_a * norm_b)
    }
}

fn main() -> Result<(), Box<dyn Error>> {
    println!("ğŸš€ ä¼ä¸šçº§RocksDBè¯­ä¹‰ç³»ç»Ÿæ¼”ç¤º");
    println!("================================================\n");

    let mut system = CompleteRocksDBSystem::new("./enterprise_rocksdb")?;

    // ä¼ä¸šçº§æµ‹è¯•æ•°æ®
    let enterprise_data = vec![
        ("AIåŸºç¡€æ¶æ„", "ç°ä»£äººå·¥æ™ºèƒ½åŸºç¡€æ¶æ„éœ€è¦æ”¯æŒå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒã€é«˜æ•ˆçš„æ¨¡å‹æ¨ç†æœåŠ¡ä»¥åŠå®æ—¶çš„æ•°æ®å¤„ç†ç®¡é“ã€‚"),
        ("è¯­ä¹‰è®¡ç®—å¼•æ“", "è¯­ä¹‰è®¡ç®—å¼•æ“é€šè¿‡æ·±åº¦å­¦ä¹ æŠ€æœ¯ç†è§£æ–‡æœ¬çš„è¯­ä¹‰ç»“æ„ï¼Œå®ç°æ™ºèƒ½çš„ä¿¡æ¯æ£€ç´¢å’ŒçŸ¥è¯†æ¨ç†ã€‚"),
        ("åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿ", "åˆ†å¸ƒå¼å­˜å‚¨ç³»ç»Ÿä½¿ç”¨RocksDBç­‰é«˜æ€§èƒ½æ•°æ®åº“ï¼Œæä¾›å¯æ‰©å±•çš„æ•°æ®æŒä¹…åŒ–å’Œå¿«é€ŸæŸ¥è¯¢èƒ½åŠ›ã€‚"),
        ("ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯", "ä¸Šä¸‹æ–‡å‹ç¼©æŠ€æœ¯å¯ä»¥åœ¨ä¿æŒè¯­ä¹‰å®Œæ•´æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—å‡å°‘æ•°æ®ä¼ è¾“å’Œå­˜å‚¨æˆæœ¬ã€‚"),
        ("å®æ—¶æ¨ç†æœåŠ¡", "å®æ—¶æ¨ç†æœåŠ¡æ¶æ„éœ€è¦æ”¯æŒé«˜å¹¶å‘è¯·æ±‚å¤„ç†ã€åŠ¨æ€è´Ÿè½½å‡è¡¡å’Œæ™ºèƒ½ç¼“å­˜ç­–ç•¥ã€‚"),
        ("çŸ¥è¯†å›¾è°±æ„å»º", "ä¼ä¸šçŸ¥è¯†å›¾è°±é€šè¿‡å®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–å’Œè¯­ä¹‰é“¾æ¥ï¼Œæ„å»ºç»“æ„åŒ–çš„ä¸šåŠ¡çŸ¥è¯†ç½‘ç»œã€‚"),
    ];

    println!("ğŸ“ æ„å»ºä¼ä¸šçº§è¯­ä¹‰çŸ¥è¯†åº“:");
    for (title, content) in enterprise_data {
        let id = system.compress_and_store(title, content)?;
        println!("   âœ… å­˜å‚¨å®Œæˆ: {}", id);
    }

    // é«˜çº§è¯­ä¹‰æœç´¢æ¼”ç¤º
    println!("\nğŸ” é«˜çº§è¯­ä¹‰æœç´¢æ¼”ç¤º:");
    let search_queries = vec![
        ("AIç³»ç»Ÿæ¶æ„", 0.3),
        ("æ•°æ®å­˜å‚¨æ–¹æ¡ˆ", 0.4),
        ("å®æ—¶å¤„ç†èƒ½åŠ›", 0.3),
    ];

    for (query, threshold) in search_queries {
        println!("\n   æŸ¥è¯¢: \"{}\" (é˜ˆå€¼: {})", query, threshold);
        let results = system.advanced_semantic_search(query, 3, threshold)?;
        for (id, score, title) in results {
            println!("     ğŸ“„ {}: {} (ç›¸ä¼¼åº¦: {:.3})", title, id, score);
        }
    }

    // ä¸Šä¸‹æ–‡æ³¨å…¥ç­–ç•¥æ¼”ç¤º
    system.demonstrate_context_injection("å¦‚ä½•æ„å»ºé«˜æ€§èƒ½çš„AIæ¨ç†ç³»ç»Ÿ")?;

    // ä¿å­˜åˆ°RocksDBæ¨¡æ‹Ÿå­˜å‚¨
    system.save_to_rocksdb_simulation()?;

    // ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    system.generate_performance_report()?;

    println!("\nâœ… ä¼ä¸šçº§RocksDBè¯­ä¹‰ç³»ç»Ÿæ¼”ç¤ºå®Œæˆï¼");
    println!("   ğŸ“Š ç³»ç»Ÿå·²å‡†å¤‡å¥½å¤„ç†ç”Ÿäº§çº§å·¥ä½œè´Ÿè½½");
    println!("   ğŸš€ ä¸‹ä¸€æ­¥é€‰æ‹©:");
    println!("      A) å®ç°æƒé‡æ›´æ–°åŠ¨åŠ›å­¦ ğŸ§ ");
    println!("      B) æ„å»ºWeb APIæœåŠ¡ ğŸŒ");
    println!("      C) ä¼˜åŒ–å­˜å‚¨å’Œç´¢å¼•æ€§èƒ½ âš¡\n");

    Ok(())
}
