// PCä¸LLMäº¤äº’è¾¹ç•Œè¯¦è§£
// å±•ç¤ºContextåœ¨PCå’ŒLLMä¹‹é—´çš„åˆ†å¸ƒå’Œä¼ é€’æœºåˆ¶

use std::collections::HashMap;

/// ğŸ¯ Contextåˆ†å±‚æ¶æ„
///
/// ```
/// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
/// â”‚                    PC (Complete Context)                        â”‚
/// â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
/// â”‚  â”‚ Full User   â”‚ â”‚ Full Agent  â”‚ â”‚ Cross-Agent â”‚ â”‚ Historical  â”‚â”‚
/// â”‚  â”‚ Profile     â”‚ â”‚ History     â”‚ â”‚ Knowledge   â”‚ â”‚ Patterns    â”‚â”‚
/// â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
/// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
///                                â”‚
///                                â”‚ Context Compression & Filtering
///                                â–¼
/// â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
/// â”‚                LLM (Minimal Context)                            â”‚
/// â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
/// â”‚  â”‚ Key User    â”‚ â”‚ Relevant    â”‚ â”‚ Task-Specificâ”‚               â”‚
/// â”‚  â”‚ Info        â”‚ â”‚ History     â”‚ â”‚ Knowledge    â”‚               â”‚
/// â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
/// â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/// ```

/// å®Œæ•´Contextï¼ˆPCå†…éƒ¨ï¼‰
#[derive(Debug, Clone)]
pub struct CompleteContext {
    pub user_profile: CompleteUserProfile,
    pub agent_history: CompleteAgentHistory,
    pub cross_agent_knowledge: CrossAgentKnowledge,
    pub domain_expertise: DomainExpertise,
    pub relationship_graph: RelationshipGraph,
    pub metadata: ContextMetadata,
}

/// LLM Contextï¼ˆå‘é€ç»™LLMçš„å‹ç¼©ç‰ˆæœ¬ï¼‰
#[derive(Debug, Clone)]
pub struct LLMContext {
    pub essential_user_info: String,    // å‹ç¼©çš„ç”¨æˆ·å…³é”®ä¿¡æ¯
    pub relevant_history: String,       // ç›¸å…³å†å²æ‘˜è¦
    pub task_knowledge: String,         // ä»»åŠ¡ç›¸å…³çŸ¥è¯†
    pub personalization_hints: String,  // ä¸ªæ€§åŒ–æç¤º
}

/// å®Œæ•´ç”¨æˆ·æ¡£æ¡ˆï¼ˆPCå†…éƒ¨ï¼‰
#[derive(Debug, Clone)]
pub struct CompleteUserProfile {
    pub user_id: String,
    pub demographics: HashMap<String, String>,
    pub interaction_history: Vec<InteractionRecord>,
    pub preference_analysis: PreferenceAnalysis,
    pub satisfaction_trends: Vec<SatisfactionPoint>,
    pub behavioral_patterns: BehavioralPatterns,
    pub relationship_network: Vec<String>, // å…³è”çš„å…¶ä»–ç”¨æˆ·
    pub privacy_settings: PrivacySettings,
}

/// å®Œæ•´Agentå†å²ï¼ˆPCå†…éƒ¨ï¼‰
#[derive(Debug, Clone)]
pub struct CompleteAgentHistory {
    pub agent_id: String,
    pub all_conversations: Vec<ConversationFull>,
    pub performance_metrics: PerformanceHistory,
    pub learning_trajectory: LearningTrajectory,
    pub collaboration_patterns: CollaborationPatterns,
    pub specialization_areas: Vec<SpecializationArea>,
}

/// Contextå‹ç¼©å¼•æ“
pub struct ContextCompressionEngine {
    compression_rules: CompressionRules,
    relevance_scorer: RelevanceScorer,
    privacy_filter: PrivacyFilter,
    token_budget_manager: TokenBudgetManager,
}

impl ContextCompressionEngine {
    /// ğŸ”¥ æ ¸å¿ƒæ–¹æ³•ï¼šå°†å®Œæ•´Contextå‹ç¼©ä¸ºLLM Context
    pub fn compress_context_for_llm(
        &self,
        complete_context: &CompleteContext,
        current_query: &str,
        llm_constraints: &LLMConstraints,
    ) -> Result<LLMContext, Box<dyn std::error::Error>> {

        println!("ğŸ”„ Compressing complete context for LLM...");

        // Step 1: åˆ†æå½“å‰æŸ¥è¯¢çš„éœ€æ±‚
        let query_analysis = self.analyze_query_requirements(current_query);
        println!("   ğŸ“‹ Query type: {} | Complexity: {:.1}",
                query_analysis.query_type, query_analysis.complexity);

        // Step 2: è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
        let relevance_scores = self.calculate_relevance_scores(
            complete_context,
            &query_analysis
        );

        // Step 3: åº”ç”¨éšç§è¿‡æ»¤
        let filtered_context = self.apply_privacy_filter(
            complete_context,
            &relevance_scores
        );

        // Step 4: Tokené¢„ç®—åˆ†é…
        let budget_allocation = self.allocate_token_budget(
            &filtered_context,
            llm_constraints.max_context_tokens
        );

        // Step 5: ç”Ÿæˆå‹ç¼©çš„ç”¨æˆ·ä¿¡æ¯
        let essential_user_info = self.compress_user_profile(
            &complete_context.user_profile,
            &query_analysis,
            budget_allocation.user_info_tokens
        );

        // Step 6: ç”Ÿæˆç›¸å…³å†å²æ‘˜è¦
        let relevant_history = self.compress_history(
            &complete_context.agent_history,
            &query_analysis,
            budget_allocation.history_tokens
        );

        // Step 7: æå–ä»»åŠ¡ç›¸å…³çŸ¥è¯†
        let task_knowledge = self.extract_task_knowledge(
            &complete_context.cross_agent_knowledge,
            &complete_context.domain_expertise,
            &query_analysis,
            budget_allocation.knowledge_tokens
        );

        // Step 8: ç”Ÿæˆä¸ªæ€§åŒ–æç¤º
        let personalization_hints = self.generate_personalization_hints(
            &complete_context.user_profile,
            &query_analysis,
            budget_allocation.personalization_tokens
        );

        let llm_context = LLMContext {
            essential_user_info,
            relevant_history,
            task_knowledge,
            personalization_hints,
        };

        // éªŒè¯å‹ç¼©ç»“æœ
        let estimated_tokens = self.estimate_llm_context_tokens(&llm_context);
        println!("   âœ… Context compressed: {} â†’ {} tokens ({:.1}% reduction)",
                self.estimate_complete_context_tokens(complete_context),
                estimated_tokens,
                (1.0 - estimated_tokens as f64 / self.estimate_complete_context_tokens(complete_context) as f64) * 100.0
        );

        Ok(llm_context)
    }

    /// å‹ç¼©ç”¨æˆ·æ¡£æ¡ˆ
    fn compress_user_profile(
        &self,
        profile: &CompleteUserProfile,
        query_analysis: &QueryAnalysis,
        token_budget: u32,
    ) -> String {
        let mut compressed = String::new();

        // æ ¹æ®æŸ¥è¯¢ç±»å‹é€‰æ‹©å…³é”®ä¿¡æ¯
        match query_analysis.query_type.as_str() {
            "technical_support" => {
                compressed.push_str(&format!("User: {} ({}), technical level: {}",
                    profile.user_id,
                    profile.demographics.get("education").unwrap_or(&"unknown".to_string()),
                    self.assess_technical_level(profile)
                ));
            },
            "customer_service" => {
                compressed.push_str(&format!("Customer: {} ({}), communication style: {}, satisfaction: {:.1}",
                    profile.user_id,
                    profile.demographics.get("age").unwrap_or(&"unknown".to_string()),
                    self.determine_communication_style(profile),
                    self.calculate_average_satisfaction(profile)
                ));
            },
            "sales" => {
                compressed.push_str(&format!("Prospect: {} ({}), budget level: {}, decision style: {}",
                    profile.user_id,
                    profile.demographics.get("income").unwrap_or(&"unknown".to_string()),
                    self.assess_budget_level(profile),
                    self.determine_decision_style(profile)
                ));
            },
            _ => {
                compressed.push_str(&format!("User: {}", profile.user_id));
            }
        }

        // æ·»åŠ æœ€é‡è¦çš„åå¥½ä¿¡æ¯
        if let Some(key_preferences) = self.extract_key_preferences(profile, query_analysis) {
            compressed.push_str(&format!(". Preferences: {}", key_preferences));
        }

        // ç¡®ä¿ä¸è¶…è¿‡tokené¢„ç®—
        self.truncate_to_budget(&compressed, token_budget)
    }

    /// å‹ç¼©å†å²è®°å½•
    fn compress_history(
        &self,
        history: &CompleteAgentHistory,
        query_analysis: &QueryAnalysis,
        token_budget: u32,
    ) -> String {
        // æ‰¾åˆ°æœ€ç›¸å…³çš„å†å²å¯¹è¯
        let relevant_conversations = self.find_relevant_conversations(
            &history.all_conversations,
            query_analysis
        );

        let mut compressed = String::new();

        if !relevant_conversations.is_empty() {
            compressed.push_str("Recent relevant interactions: ");

            for (i, conv) in relevant_conversations.iter().take(3).enumerate() {
                if i > 0 { compressed.push_str("; "); }
                compressed.push_str(&format!("{}. {} â†’ {}",
                    i + 1,
                    self.summarize_user_message(&conv.user_message),
                    self.summarize_agent_response(&conv.agent_response)
                ));
            }
        }

        self.truncate_to_budget(&compressed, token_budget)
    }

    /// æå–ä»»åŠ¡ç›¸å…³çŸ¥è¯†
    fn extract_task_knowledge(
        &self,
        cross_agent_knowledge: &CrossAgentKnowledge,
        domain_expertise: &DomainExpertise,
        query_analysis: &QueryAnalysis,
        token_budget: u32,
    ) -> String {
        let mut knowledge = String::new();

        // è·å–ç›¸å…³çš„è·¨Agentç»éªŒ
        if let Some(relevant_experience) = self.find_relevant_cross_agent_experience(
            cross_agent_knowledge,
            query_analysis
        ) {
            knowledge.push_str(&format!("Similar cases: {}", relevant_experience));
        }

        // è·å–é¢†åŸŸä¸“ä¸šçŸ¥è¯†
        if let Some(domain_info) = self.find_relevant_domain_knowledge(
            domain_expertise,
            query_analysis
        ) {
            if !knowledge.is_empty() { knowledge.push_str(". "); }
            knowledge.push_str(&format!("Domain context: {}", domain_info));
        }

        self.truncate_to_budget(&knowledge, token_budget)
    }

    /// ç”Ÿæˆä¸ªæ€§åŒ–æç¤º
    fn generate_personalization_hints(
        &self,
        profile: &CompleteUserProfile,
        query_analysis: &QueryAnalysis,
        token_budget: u32,
    ) -> String {
        let mut hints = String::new();

        // åŸºäºç”¨æˆ·è¡Œä¸ºæ¨¡å¼çš„æç¤º
        let communication_style = self.determine_communication_style(profile);
        hints.push_str(&format!("Adjust tone for {} communication", communication_style));

        // åŸºäºå†å²æ»¡æ„åº¦çš„æç¤º
        let satisfaction_level = self.calculate_average_satisfaction(profile);
        if satisfaction_level < 0.7 {
            hints.push_str(". Extra care needed - previous dissatisfaction");
        }

        self.truncate_to_budget(&hints, token_budget)
    }

    /// æ„å»ºå‘é€ç»™LLMçš„æœ€ç»ˆPrompt
    pub fn build_llm_prompt(
        &self,
        llm_context: &LLMContext,
        agent_type: &str,
        user_query: &str,
    ) -> String {
        format!(
            "You are a {} agent.\n\n\
            Context: {}\n\n\
            History: {}\n\n\
            Knowledge: {}\n\n\
            Instructions: {}\n\n\
            User Query: {}\n\n\
            Please provide a helpful response:",
            agent_type,
            llm_context.essential_user_info,
            llm_context.relevant_history,
            llm_context.task_knowledge,
            llm_context.personalization_hints,
            user_query
        )
    }
}

/// ğŸ¯ å®é™…ç¤ºä¾‹ï¼šå±•ç¤ºContextåˆ†å¸ƒ
pub struct ContextDistributionDemo;

impl ContextDistributionDemo {
    pub fn demonstrate_context_flow(&self) {
        println!("ğŸ”„ Context Distribution Demo");
        println!("{}", "=".repeat(50));

        // 1. PCå†…éƒ¨çš„å®Œæ•´Context
        self.show_complete_context();

        // 2. å‹ç¼©è¿‡ç¨‹
        self.show_compression_process();

        // 3. å‘é€ç»™LLMçš„Context
        self.show_llm_context();

        // 4. LLMå“åº”å¤„ç†
        self.show_response_processing();
    }

    fn show_complete_context(&self) {
        println!("\nğŸ“š PCå†…éƒ¨å®Œæ•´Context (çº¦2000 tokens):");
        println!("   ğŸ‘¤ Complete User Profile:");
        println!("      - åŸºæœ¬ä¿¡æ¯: å¼ å…ˆç”Ÿ, 35å², æœ¬ç§‘, å·¥ç¨‹å¸ˆ, ä¸­ç­‰æ”¶å…¥");
        println!("      - äº¤äº’å†å²: 23æ¬¡å¯¹è¯, å¹³å‡æ»¡æ„åº¦8.5/10");
        println!("      - è¡Œä¸ºæ¨¡å¼: åå¥½æŠ€æœ¯ç»†èŠ‚, ç®€æ´æ²Ÿé€š, å‘¨äºŒä¸Šåˆæœ€æ´»è·ƒ");
        println!("      - å…³è”ç½‘ç»œ: ä¸æå·¥ç¨‹å¸ˆæœ‰åä½œå…³ç³»");
        println!("      - éšç§è®¾ç½®: å…è®¸åŸºæœ¬ä¿¡æ¯å…±äº«, æ•æ„Ÿä¿¡æ¯é™åˆ¶");

        println!("   ğŸ¤– Complete Agent History:");
        println!("      - æ‰€æœ‰å¯¹è¯: 156æ¬¡äº¤äº’è®°å½•");
        println!("      - æ€§èƒ½æŒ‡æ ‡: è§£å†³ç‡94%, é¦–æ¬¡è§£å†³ç‡78%");
        println!("      - å­¦ä¹ è½¨è¿¹: åœ¨ç™»å½•é—®é¢˜ä¸Šä»60%æå‡åˆ°95%æˆåŠŸç‡");
        println!("      - åä½œæ¨¡å¼: ä¸æŠ€æœ¯æ”¯æŒAgentåä½œåº¦0.8");

        println!("   ğŸ”„ Cross-Agent Knowledge:");
        println!("      - ç›¸ä¼¼æ¡ˆä¾‹: æŠ€æœ¯æ”¯æŒAgentè§£å†³çš„3ä¸ªç±»ä¼¼ç™»å½•é—®é¢˜");
        println!("      - æœ€ä½³å®è·µ: ç™»å½•é—®é¢˜çš„æ ‡å‡†å¤„ç†æµç¨‹");
        println!("      - å¤±è´¥æ¡ˆä¾‹: 2ä¸ªæœªæˆåŠŸè§£å†³çš„å¤æ‚æ¡ˆä¾‹");
    }

    fn show_compression_process(&self) {
        println!("\nğŸ”„ Contextå‹ç¼©è¿‡ç¨‹:");
        println!("   ğŸ“Š ç›¸å…³æ€§åˆ†æ:");
        println!("      - ç”¨æˆ·åŸºæœ¬ä¿¡æ¯: ç›¸å…³æ€§ 0.9 (é«˜)");
        println!("      - æœ€è¿‘3æ¬¡äº¤äº’: ç›¸å…³æ€§ 0.8 (é«˜)");
        println!("      - æŠ€æœ¯èƒŒæ™¯: ç›¸å…³æ€§ 0.9 (é«˜)");
        println!("      - å…³è”ç½‘ç»œ: ç›¸å…³æ€§ 0.3 (ä½) â†’ è¿‡æ»¤æ‰");

        println!("   ğŸ”’ éšç§è¿‡æ»¤:");
        println!("      - ä¿ç•™: æŠ€æœ¯æ°´å¹³, æ²Ÿé€šåå¥½");
        println!("      - è¿‡æ»¤: å…·ä½“æ”¶å…¥æ•°å­—, è¯¦ç»†ä¸ªäººä¿¡æ¯");

        println!("   ğŸ’° Tokené¢„ç®—åˆ†é… (æ€»é¢„ç®—: 300 tokens):");
        println!("      - ç”¨æˆ·ä¿¡æ¯: 80 tokens");
        println!("      - ç›¸å…³å†å²: 120 tokens");
        println!("      - ä»»åŠ¡çŸ¥è¯†: 80 tokens");
        println!("      - ä¸ªæ€§åŒ–æç¤º: 20 tokens");
    }

    fn show_llm_context(&self) {
        println!("\nğŸ“¤ å‘é€ç»™LLMçš„å‹ç¼©Context (300 tokens):");
        println!("   ğŸ‘¤ Essential User Info:");
        println!("      \"User: å¼ å…ˆç”Ÿ (æœ¬ç§‘), technical level: high, communication style: concise, satisfaction: 8.5\"");

        println!("   ğŸ“š Relevant History:");
        println!("      \"Recent relevant interactions: 1. login issue â†’ cache clear resolved; 2. password reset â†’ guided successfully\"");

        println!("   ğŸ§  Task Knowledge:");
        println!("      \"Similar cases: 3 successful login resolutions via cache clearing. Domain context: login issues typically browser-related\"");

        println!("   ğŸ¯ Personalization Hints:");
        println!("      \"Adjust tone for concise communication\"");
    }

    fn show_response_processing(&self) {
        println!("\nğŸ”„ LLMå“åº”å¤„ç†:");
        println!("   ğŸ“¥ LLMåŸå§‹å“åº” (150 tokens):");
        println!("      \"Based on your technical background and previous successful resolution, I recommend clearing your browser cache...\"");

        println!("   ğŸ”„ PCåå¤„ç†:");
        println!("      - è´¨é‡è¯„ä¼°: 8.7/10");
        println!("      - ä¸ªæ€§åŒ–å¢å¼º: æ·»åŠ æŠ€æœ¯ç»†èŠ‚é“¾æ¥");
        println!("      - ä¸Šä¸‹æ–‡æ›´æ–°: è®°å½•æœ¬æ¬¡æˆåŠŸè§£å†³æ–¹æ¡ˆ");
        println!("      - è·¨Agentå…±äº«: æ·»åŠ åˆ°ç™»å½•é—®é¢˜çŸ¥è¯†åº“");

        println!("   ğŸ“¤ è¿”å›ç»™Agentçš„æœ€ç»ˆå“åº”:");
        println!("      \"æ ¹æ®æ‚¨çš„æŠ€æœ¯èƒŒæ™¯å’Œä¹‹å‰çš„æˆåŠŸç»éªŒï¼Œå»ºè®®æ¸…é™¤æµè§ˆå™¨ç¼“å­˜ã€‚å…·ä½“æ­¥éª¤ï¼š...\"");
    }
}

/// ğŸ”§ æ”¯æŒç»“æ„å®šä¹‰
#[derive(Debug)]
struct QueryAnalysis {
    query_type: String,
    complexity: f64,
    required_context_types: Vec<String>,
    urgency: f64,
}

#[derive(Debug)]
struct LLMConstraints {
    max_context_tokens: u32,
    max_total_tokens: u32,
    response_time_limit: u32,
}

#[derive(Debug)]
struct TokenBudgetAllocation {
    user_info_tokens: u32,
    history_tokens: u32,
    knowledge_tokens: u32,
    personalization_tokens: u32,
}

// ç®€åŒ–çš„æ”¯æŒç»“æ„
#[derive(Debug, Clone)]
struct InteractionRecord { user_message: String, agent_response: String, timestamp: u64 }
#[derive(Debug, Clone)]
struct PreferenceAnalysis { communication_style: String, technical_level: f64 }
#[derive(Debug, Clone)]
struct SatisfactionPoint { score: f64, timestamp: u64 }
#[derive(Debug, Clone)]
struct BehavioralPatterns { active_hours: Vec<u8>, response_time_preference: u32 }
#[derive(Debug, Clone)]
struct PrivacySettings { allow_basic_sharing: bool, sensitive_data_restricted: bool }
#[derive(Debug, Clone)]
struct ConversationFull { user_message: String, agent_response: String, quality_score: f64 }
#[derive(Debug, Clone)]
struct PerformanceHistory { resolution_rate: f64, first_contact_resolution: f64 }
#[derive(Debug, Clone)]
struct LearningTrajectory { skill_improvements: HashMap<String, f64> }
#[derive(Debug, Clone)]
struct CollaborationPatterns { partner_agents: HashMap<String, f64> }
#[derive(Debug, Clone)]
struct SpecializationArea { domain: String, proficiency: f64 }
#[derive(Debug, Clone)]
struct CrossAgentKnowledge { shared_experiences: Vec<String> }
#[derive(Debug, Clone)]
struct DomainExpertise { knowledge_base: HashMap<String, String> }
#[derive(Debug, Clone)]
struct RelationshipGraph { connections: HashMap<String, f64> }
#[derive(Debug, Clone)]
struct ContextMetadata { last_updated: u64, version: String }

// ç®€åŒ–çš„å¼•æ“ç»„ä»¶
struct CompressionRules;
struct RelevanceScorer;
struct PrivacyFilter;
struct TokenBudgetManager;

// ç®€åŒ–çš„å®ç°
impl ContextCompressionEngine {
    fn analyze_query_requirements(&self, _query: &str) -> QueryAnalysis {
        QueryAnalysis {
            query_type: "technical_support".to_string(),
            complexity: 0.7,
            required_context_types: vec!["user_profile".to_string(), "history".to_string()],
            urgency: 0.8,
        }
    }

    fn calculate_relevance_scores(&self, _context: &CompleteContext, _analysis: &QueryAnalysis) -> HashMap<String, f64> {
        [("user_profile".to_string(), 0.9), ("history".to_string(), 0.8)].iter().cloned().collect()
    }

    fn apply_privacy_filter(&self, context: &CompleteContext, _scores: &HashMap<String, f64>) -> CompleteContext {
        context.clone()
    }

    fn allocate_token_budget(&self, _context: &CompleteContext, max_tokens: u32) -> TokenBudgetAllocation {
        TokenBudgetAllocation {
            user_info_tokens: max_tokens / 4,
            history_tokens: max_tokens / 2,
            knowledge_tokens: max_tokens / 4,
            personalization_tokens: max_tokens / 10,
        }
    }

    fn estimate_complete_context_tokens(&self, _context: &CompleteContext) -> u32 { 2000 }
    fn estimate_llm_context_tokens(&self, _context: &LLMContext) -> u32 { 300 }
    fn assess_technical_level(&self, _profile: &CompleteUserProfile) -> String { "high".to_string() }
    fn determine_communication_style(&self, _profile: &CompleteUserProfile) -> String { "concise".to_string() }
    fn calculate_average_satisfaction(&self, _profile: &CompleteUserProfile) -> f64 { 8.5 }
    fn assess_budget_level(&self, _profile: &CompleteUserProfile) -> String { "medium".to_string() }
    fn determine_decision_style(&self, _profile: &CompleteUserProfile) -> String { "analytical".to_string() }
    fn extract_key_preferences(&self, _profile: &CompleteUserProfile, _analysis: &QueryAnalysis) -> Option<String> {
        Some("technical details, quick resolution".to_string())
    }
    fn truncate_to_budget(&self, text: &str, _budget: u32) -> String { text.to_string() }
    fn find_relevant_conversations(&self, _conversations: &[ConversationFull], _analysis: &QueryAnalysis) -> Vec<ConversationFull> {
        vec![]
    }
    fn summarize_user_message(&self, message: &str) -> String { message.chars().take(20).collect::<String>() + "..." }
    fn summarize_agent_response(&self, response: &str) -> String { response.chars().take(20).collect::<String>() + "..." }
    fn find_relevant_cross_agent_experience(&self, _knowledge: &CrossAgentKnowledge, _analysis: &QueryAnalysis) -> Option<String> {
        Some("3 successful login resolutions".to_string())
    }
    fn find_relevant_domain_knowledge(&self, _expertise: &DomainExpertise, _analysis: &QueryAnalysis) -> Option<String> {
        Some("login issues typically browser-related".to_string())
    }
}

fn main() {
    println!("ğŸ”„ PC-LLM Context Boundary Demonstration");
    println!("{}", "=".repeat(60));

    let demo = ContextDistributionDemo;
    demo.demonstrate_context_flow();

    println!("\nğŸ¯ Key Insights:");
    println!("   ğŸ’¾ PC maintains complete context (2000+ tokens)");
    println!("   ğŸ“¤ LLM receives compressed context (300 tokens)");
    println!("   ğŸ”„ 86% context compression without losing effectiveness");
    println!("   ğŸ”’ Privacy-aware filtering protects sensitive data");
    println!("   ğŸ¯ Task-specific optimization for relevance");

    println!("\nâœ¨ This demonstrates how PC acts as an intelligent context gateway!");
}
