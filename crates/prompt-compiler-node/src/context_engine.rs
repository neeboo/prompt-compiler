use anyhow::Result;
use std::sync::{Arc, Mutex}; // æ·»åŠ Mutexæ”¯æŒ
use tracing::{info, debug, warn}; // æ·»åŠ warnå¯¼å…¥
use prompt_compiler_embeddings::EmbeddingProvider;
use prompt_compiler_weights::{ImplicitDynamics, DynamicsConfig}; // æ·»åŠ DynamicsConfigå¯¼å…¥
use regex; // æ·»åŠ regexä¾èµ–

use crate::{ChatCompletionRequest, ChatCompletionResponse, ChatMessage, ProcessedRequest};
use crate::storage::NodeStorage;

pub struct ContextEngine {
    embedding_provider: Mutex<EmbeddingProvider>, // ç”¨MutexåŒ…è£…
    dynamics: ImplicitDynamics,
    storage: Arc<NodeStorage>,
}

impl ContextEngine {
    pub async fn new(storage: Arc<NodeStorage>) -> Result<Self> {
        info!("Initializing Context Engine with weight dynamics...");

        // Initialize weight dynamics with paper-compliant configuration
        let config = DynamicsConfig {
            learning_rate: 0.1,
            use_skip_connections: false,
            regularization_strength: 0.001,
        };
        let dynamics = ImplicitDynamics::new(384, 256, config)?;

        // Initialize embedding provider
        let embedding_provider = Mutex::new(EmbeddingProvider::new(
            prompt_compiler_embeddings::EmbeddingConfig::default()
        )?);

        info!("âœ… Context Engine initialized successfully");

        Ok(Self {
            storage,
            dynamics,
            embedding_provider,
        })
    }

    pub async fn process_request_with_group(
        &self,
        request: &ChatCompletionRequest,
        agent_id: Option<&str>,
        shared_context_group: Option<&str>,
    ) -> Result<ProcessedRequest> {
        debug!("Processing request with context sharing for agent: {:?}, group: {:?}", agent_id, shared_context_group);

        // Extract context from messages
        let conversation_context = self.extract_conversation_context(&request.messages).await?;
        debug!("Current conversation context: {}", &conversation_context[..std::cmp::min(100, conversation_context.len())]);

        // ğŸ”§ è·¨Agentä¸Šä¸‹æ–‡å…±äº«é€»è¾‘ - è¿›ä¸€æ­¥ä¼˜åŒ–è¿‡æ»¤ç­–ç•¥
        let similar_contexts = if let Some(group) = shared_context_group {
            // ä½¿ç”¨ä¸Šä¸‹æ–‡ç»„æŸ¥æ‰¾ç›¸å…³ä¸Šä¸‹æ–‡ï¼ˆè·¨Agentå…±äº«ï¼‰
            let context_embedding = {
                let mut provider = self.embedding_provider.lock()
                    .map_err(|e| anyhow::anyhow!("Lock error: {}", e))?;
                provider.encode(&conversation_context)?
            };

            let contexts = self.storage.find_similar_contexts_in_group(group, &context_embedding, 15).await?; // ğŸ”§ å¢åŠ åˆ°15ä¸ªå€™é€‰
            debug!("Found {} similar contexts in group {}", contexts.len(), group);

            // ğŸ”§ æ™ºèƒ½ä¸Šä¸‹æ–‡è¿‡æ»¤ï¼šç¡®ä¿å®¢æˆ·èº«ä»½ä¿¡æ¯å’Œå…³é”®ä¸šåŠ¡ä¿¡æ¯ä¼˜å…ˆä¿ç•™
            let mut filtered_contexts = Vec::new();

            // ğŸ”§ æ”¹è¿›ï¼šé¦–å…ˆæ— æ¡ä»¶æ·»åŠ æ‰€æœ‰åŒ…å«å®¢æˆ·èº«ä»½çš„ä¸Šä¸‹æ–‡
            for ctx in &contexts {
                if self.contains_client_identity(&ctx.content) {
                    filtered_contexts.push(ctx.clone());
                    if filtered_contexts.len() >= 5 { // æœ€å¤š5ä¸ªå®¢æˆ·ç›¸å…³ä¸Šä¸‹æ–‡
                        break;
                    }
                }
            }

            // ç¬¬äºŒè½®ï¼šæ·»åŠ ä¸šåŠ¡å…³é”®ä¿¡æ¯ï¼Œä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
            for ctx in &contexts {
                if !self.contains_client_identity(&ctx.content) &&
                   self.contains_business_info(&ctx.content) &&
                   filtered_contexts.len() < 10 {
                    filtered_contexts.push(ctx.clone());
                }
            }

            // ç¬¬ä¸‰è½®ï¼šæ·»åŠ å…¶ä»–é«˜ç›¸ä¼¼åº¦ä¸Šä¸‹æ–‡
            for ctx in contexts.into_iter() {
                if !self.contains_client_identity(&ctx.content) &&
                   !self.contains_business_info(&ctx.content) &&
                   filtered_contexts.len() < 12 &&
                   ctx.similarity > 0.05 { // ğŸ”§ é™ä½é˜ˆå€¼åˆ°0.05
                    filtered_contexts.push(ctx);
                }
            }

            debug!("Filtered contexts: {} with relaxed criteria", filtered_contexts.len());
            filtered_contexts
        } else if let Some(agent_id) = agent_id {
            // ğŸ”§ å•Agentä¸Šä¸‹æ–‡æŸ¥æ‰¾ - åº”ç”¨å¤šAgentæˆåŠŸç»éªŒ
            let context_embedding = {
                let mut provider = self.embedding_provider.lock()
                    .map_err(|e| anyhow::anyhow!("Lock error: {}", e))?;
                provider.encode(&conversation_context)?
            };

            let contexts = self.storage.find_similar_contexts(agent_id, &context_embedding, 10).await?; // ğŸ”§ å¢åŠ å€™é€‰æ•°é‡
            debug!("Found {} similar contexts for agent {}", contexts.len(), agent_id);

            // ğŸ”§ åº”ç”¨ä¸å¤šAgentç›¸åŒçš„æ™ºèƒ½è¿‡æ»¤ç­–ç•¥
            let mut filtered_contexts = Vec::new();

            // ç¬¬ä¸€è½®ï¼šä¼˜å…ˆæ·»åŠ åŒ…å«ç”¨æˆ·èº«ä»½çš„ä¸Šä¸‹æ–‡ï¼ˆé™ä½é˜ˆå€¼ï¼‰
            for ctx in &contexts {
                if self.contains_user_identity(&ctx.content) && ctx.similarity > 0.05 { // ğŸ”§ é™ä½é˜ˆå€¼
                    filtered_contexts.push(ctx.clone());
                    if filtered_contexts.len() >= 3 {
                        break;
                    }
                }
            }

            // ç¬¬äºŒè½®ï¼šæ·»åŠ å…¶ä»–ç›¸å…³ä¸Šä¸‹æ–‡
            for ctx in contexts.into_iter() {
                if !self.contains_user_identity(&ctx.content) &&
                   filtered_contexts.len() < 8 &&
                   ctx.similarity > 0.05 { // ğŸ”§ ç»Ÿä¸€ä½¿ç”¨æ›´å®½æ¾çš„é˜ˆå€¼
                    filtered_contexts.push(ctx);
                }
            }

            debug!("Single-agent filtered contexts: {} with relaxed criteria", filtered_contexts.len());
            filtered_contexts
        } else {
            debug!("No agent ID or context group provided, skipping context lookup");
            Vec::new()
        };

        // ğŸ”§ å¢å¼ºçš„ä¸Šä¸‹æ–‡å¤„ç† - ä¼˜å…ˆä¿ç•™å…³é”®ä¿¡æ¯
        let processed_messages = if !similar_contexts.is_empty() {
            debug!("Applying context sharing with {} relevant contexts", similar_contexts.len());

            // ğŸ”§ æ”¹è¿›ï¼šç”Ÿæˆæ›´è¯¦ç»†çš„å…³é”®ä¿¡æ¯æ‘˜è¦
            let key_info = self.extract_comprehensive_key_information(&similar_contexts);

            // ğŸ”§ å…³é”®ä¿®å¤ï¼šç¡®ä¿ç”¨æˆ·èº«ä»½ä¿¡æ¯å§‹ç»ˆè¢«ä¿ç•™
            let user_identity_info = self.extract_persistent_user_identity(&similar_contexts);

            let enhanced_context = if !key_info.is_empty() {
                let mut context_parts = Vec::new();

                // ğŸ”§ ä¼˜å…ˆæ·»åŠ ç”¨æˆ·èº«ä»½ä¿¡æ¯ï¼ˆç¡®ä¿ä¸ä¸¢å¤±ï¼‰
                if !user_identity_info.is_empty() {
                    context_parts.push(format!("User Identity: {}", user_identity_info));
                }

                // æ·»åŠ å…¶ä»–å…³é”®ä¿¡æ¯
                if !key_info.is_empty() {
                    context_parts.push(format!("Previous Context: {}", key_info.join("; ")));
                }

                format!("IMPORTANT CONTEXT - {}", context_parts.join(" | "))
            } else {
                format!("Previous context: {}",
                       similar_contexts.first()
                           .map(|c| &c.content[..std::cmp::min(300, c.content.len())])  // å¢åŠ åˆ°300å­—ç¬¦
                           .unwrap_or("No context available"))
            };

            // ğŸ”§ ä¿®å¤ï¼šä¼˜åŒ–å‹ç¼©ç­–ç•¥ï¼Œåœ¨å‹ç¼©æ—¶å¼ºåˆ¶ä¿ç•™ç”¨æˆ·èº«ä»½ä¿¡æ¯
            let base_messages = if request.messages.len() > 5 {  // ä¿æŒé˜ˆå€¼ä¸º5
                debug!("Long conversation detected ({} messages), applying identity-preserving compression", request.messages.len());
                self.apply_identity_preserving_compression(&request.messages, &user_identity_info).await?
            } else {
                request.messages.clone()
            };

            let mut enhanced = vec![
                ChatMessage {
                    role: "system".to_string(),
                    content: enhanced_context,
                }
            ];
            enhanced.extend(base_messages);

            debug!("Added enhanced context ({} chars) with user identity: {}",
                   enhanced[0].content.len(), user_identity_info);
            enhanced
        } else if request.messages.len() > 5 {
            // å¤šè½®å¯¹è¯åœºæ™¯ï¼šæ™ºèƒ½å‹ç¼©
            debug!("Multi-turn conversation detected ({} messages), applying smart compression", request.messages.len());
            self.apply_smart_compression(&request.messages).await?
        } else {
            debug!("No compression needed");
            request.messages.clone()
        };

        // è®¡ç®—å‹ç¼©æ•ˆæœ
        let original_content_length: usize = request.messages.iter().map(|m| m.content.len()).sum();
        let processed_content_length: usize = processed_messages.iter().map(|m| m.content.len()).sum();

        let compression_ratio = if processed_content_length > original_content_length {
            -((processed_content_length - original_content_length) as f32 / original_content_length as f32)
        } else {
            ((original_content_length - processed_content_length) as f32 / original_content_length as f32)
        };

        Ok(ProcessedRequest {
            messages: processed_messages,
            compression_ratio,
            context_used: !similar_contexts.is_empty(),
        })
    }

    // ä¿æŒåŸæœ‰æ–¹æ³•çš„å‘åå…¼å®¹æ€§
    pub async fn process_request(
        &self,
        request: &ChatCompletionRequest,
        agent_id: Option<&str>,
    ) -> Result<ProcessedRequest> {
        self.process_request_with_group(request, agent_id, None).await
    }

    // ğŸ”§ æ–°å¢ï¼šå®ç°çœŸæ­£çš„è¯­ä¹‰å‹ç¼©
    fn compress_historical_context(&self, contexts: &[SimilarContext]) -> String {
        if contexts.is_empty() {
            return String::new();
        }

        // æå–å…³é”®ä¿¡æ¯ï¼Œè€Œä¸æ˜¯å®Œæ•´å¯¹è¯
        let mut key_facts = Vec::new();

        for context in contexts.iter().take(2) { // åªå–æœ€ç›¸å…³çš„2ä¸ªä¸Šä¸‹æ–‡
            // ä»å†å²å¯¹è¯ä¸­æå–å…³é”®äº‹å®
            let content = &context.content;

            // ç®€å•çš„å…³é”®ä¿¡æ¯æå–é€»è¾‘
            if content.contains("name") || content.contains("åå­—") {
                if let Some(name_info) = self.extract_name_info(content) {
                    key_facts.push(name_info);
                }
            }

            if content.contains("work") || content.contains("job") || content.contains("å·¥ä½œ") {
                if let Some(work_info) = self.extract_work_info(content) {
                    key_facts.push(work_info);
                }
            }

            if content.contains("project") || content.contains("é¡¹ç›®") {
                if let Some(project_info) = self.extract_project_info(content) {
                    key_facts.push(project_info);
                }
            }
        }

        // å»é‡å¹¶ç”Ÿæˆç®€æ´çš„ä¸Šä¸‹æ–‡æ‘˜è¦
        key_facts.dedup();
        if key_facts.is_empty() {
            return String::new();
        }

        format!("Context: {}", key_facts.join(", "))
    }

    // ğŸ”§ è¾…åŠ©æ–¹æ³•ï¼šæå–å…³é”®ä¿¡æ¯
    fn extract_name_info(&self, content: &str) -> Option<String> {
        // ç®€å•çš„åå­—æå–é€»è¾‘
        if let Some(start) = content.find("name is ") {
            let after_name = &content[start + 8..];
            if let Some(end) = after_name.find(" ") {
                let name = &after_name[..end];
                if name.len() > 0 && name.len() < 20 {
                    return Some(format!("name: {}", name));
                }
            }
        }
        None
    }

    fn extract_work_info(&self, content: &str) -> Option<String> {
        if content.contains("work at") || content.contains("job") {
            // æå–å·¥ä½œç›¸å…³çš„ç®€çŸ­ä¿¡æ¯
            if content.contains("tech") || content.contains("startup") {
                return Some("work: tech".to_string());
            }
            if content.contains("engineer") {
                return Some("work: engineer".to_string());
            }
        }
        None
    }

    fn extract_project_info(&self, content: &str) -> Option<String> {
        if content.contains("Python") && content.contains("machine learning") {
            return Some("project: Python ML".to_string());
        }
        if content.contains("project") {
            return Some("project: development".to_string());
        }
        None
    }

    // ğŸ”§ æ”¹è¿›ï¼šæ›´æ™ºèƒ½çš„å¯¹è¯å†å²å‹ç¼©ï¼ˆå‡å°‘ç¡¬ç¼–ç ï¼‰
    fn compress_conversation_history(&self, messages: &[ChatMessage]) -> String {
        if messages.is_empty() {
            return String::new();
        }

        // ğŸ”§ ä½¿ç”¨æ›´æ™ºèƒ½çš„è¯­ä¹‰æå–ï¼Œå‡å°‘ç¡¬ç¼–ç 
        let mut key_entities = Vec::new();
        let mut topics = std::collections::HashSet::new();
        let mut user_attributes = Vec::new();

        for message in messages {
            let content = &message.content;

            // ğŸ”§ æ™ºèƒ½å®ä½“æå–ï¼ˆä½¿ç”¨æ›´çµæ´»çš„æ¨¡å¼ï¼‰
            if message.role == "user" {
                // æå–å¯èƒ½çš„ç”¨æˆ·æ ‡è¯†ç¬¦ï¼ˆå§“åã€è§’è‰²ã€å…¬å¸ç­‰ï¼‰
                if let Some(identity) = self.extract_user_identity_smart(content) {
                    if !user_attributes.iter().any(|attr: &String| attr.contains(&identity)) {
                        user_attributes.push(identity);
                    }
                }

                // ğŸ”§ å…³é”®æ”¹è¿›ï¼šæå–ä¸šåŠ¡å…³é”®ä¿¡æ¯
                if let Some(business_info) = self.extract_business_context(content) {
                    if !key_entities.contains(&business_info) && key_entities.len() < 8 {
                        key_entities.push(business_info);
                    }
                }

                // æå–å…³é”®å®ä½“ï¼ˆä½¿ç”¨NER-likeæ–¹æ³•ï¼‰
                let entities = self.extract_entities_smart(content);
                for entity in entities {
                    if !key_entities.contains(&entity) && key_entities.len() < 8 {
                        key_entities.push(entity);
                    }
                }
            }

            // ğŸ”§ ä¸»é¢˜æå–ï¼ˆåŸºäºå…³é”®è¯èšç±»è€Œéç¡¬ç¼–ç ï¼‰
            let detected_topics = self.extract_topics_smart(content);
            for topic in detected_topics {
                topics.insert(topic);
            }
        }

        // ğŸ”§ æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ - ä¼˜å…ˆä¿ç•™ä¸šåŠ¡å…³é”®ä¿¡æ¯
        let mut summary_parts = Vec::new();

        if !user_attributes.is_empty() {
            summary_parts.push(format!("User: {}", user_attributes.join(", ")));
        }

        if !key_entities.is_empty() {
            summary_parts.push(format!("Context: {}", key_entities.join(", ")));
        }

        if !topics.is_empty() && topics.len() <= 3 {
            let topic_list: Vec<String> = topics.into_iter().take(3).collect();
            summary_parts.push(format!("Topics: {}", topic_list.join(", ")));
        }

        if summary_parts.is_empty() {
            // ğŸ”§ fallback: ä½¿ç”¨ç»Ÿè®¡æ‘˜è¦è€Œéç®€å•è®¡æ•°
            let total_chars: usize = messages.iter().map(|m| m.content.len()).sum();
            let avg_message_len = total_chars / messages.len().max(1);
            format!("Session: {} exchanges, avg {} chars/msg",
                   messages.len() / 2, avg_message_len)
        } else {
            summary_parts.join("; ")
        }
    }

    // ğŸ”§ æ–°å¢ï¼šæå–ä¸šåŠ¡ä¸Šä¸‹æ–‡ä¿¡æ¯
    fn extract_business_context(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // å…¬å¸åç§°æ£€æµ‹
        if let Some(company) = self.extract_company_name(&content_lower) {
            return Some(format!("company: {}", company));
        }

        // æ•°é‡å’Œè§„æ¨¡ä¿¡æ¯
        if let Some(scale_info) = self.extract_scale_info(&content_lower) {
            return Some(format!("scale: {}", scale_info));
        }

        // ä¸šåŠ¡éœ€æ±‚
        if let Some(requirement) = self.extract_business_requirement(&content_lower) {
            return Some(format!("need: {}", requirement));
        }

        None
    }

    // ğŸ”§ æå–å…¬å¸åç§°
    fn extract_company_name(&self, content: &str) -> Option<String> {
        // åŒ¹é… "from [Company]" æ¨¡å¼
        if content.contains("from ") {
            if let Some(start) = content.find("from ") {
                let after_from = &content[start + 5..];
                if let Some(end) = after_from.find('.').or_else(|| after_from.find(',')) {
                    let company = after_from[..end].trim();
                    if company.len() > 2 && company.len() < 30 &&
                       (company.contains("corp") || company.contains("inc") || company.contains(" ")) {
                        return Some(company.to_string());
                    }
                }
            }
        }
        None
    }

    // ğŸ”§ æå–è§„æ¨¡ä¿¡æ¯
    fn extract_scale_info(&self, content: &str) -> Option<String> {
        // æ•°å­— + å•ä½æ¨¡å¼
        let patterns = [
            (r"(\d+[,\d]*)\s*(thousand|k)", "scale"),
            (r"(\d+[,\d]*)\s*(million|m)", "scale"),
            (r"(\d+[,\d]*)\s*(inquiries|users|customers)", "volume"),
            (r"(\d+[,\d]*)\s*(per month|monthly)", "monthly"),
        ];

        for (pattern, category) in patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(content) {
                    if let Some(number) = captures.get(1) {
                        return Some(format!("{}: {}", category, number.as_str()));
                    }
                }
            }
        }
        None
    }

    // ğŸ”§ æå–ä¸šåŠ¡éœ€æ±‚
    fn extract_business_requirement(&self, content: &str) -> Option<String> {
        let requirements = [
            ("customer service", "cs-solution"),
            ("ai-powered", "ai-solution"),
            ("reduce response time", "performance"),
            ("auto-scaling", "scalability"),
            ("security", "security"),
            ("compliance", "compliance"),
            ("crm integration", "integration"),
        ];

        for (keyword, category) in requirements {
            if content.contains(keyword) {
                return Some(category.to_string());
            }
        }
        None
    }

    pub async fn store_interaction(
        &self, // æ”¹å›ä¸å¯å˜å¼•ç”¨
        request: &ChatCompletionRequest,
        response: &ChatCompletionResponse,
        agent_id: Option<&str>,
    ) -> Result<()> {
        if let Some(agent_id) = agent_id {
            debug!("Storing interaction context for agent: {}", agent_id);

            // Create conversation summary
            let mut full_conversation = request.messages.clone();
            if let Some(choice) = response.choices.first() {
                full_conversation.push(choice.message.clone());
            }

            let conversation_text = self.extract_conversation_context(&full_conversation).await?;
            let embedding = {
                let mut provider = self.embedding_provider.lock()
                    .map_err(|e| anyhow::anyhow!("Lock error: {}", e))?;
                provider.encode(&conversation_text)?
            };

            // Store in persistent storage
            self.storage.store_context(agent_id, &conversation_text, &embedding).await?;

            debug!("âœ… Interaction context stored successfully");
        }

        Ok(())
    }

    pub async fn store_interaction_with_group(
        &self,
        request: &ChatCompletionRequest,
        response: &ChatCompletionResponse,
        agent_id: Option<&str>,
        shared_context_group: Option<&str>,
    ) -> Result<()> {
        if let Some(agent_id) = agent_id {
            debug!("Storing interaction context for agent: {} in group: {:?}", agent_id, shared_context_group);

            // Create conversation summary
            let mut full_conversation = request.messages.clone();
            if let Some(choice) = response.choices.first() {
                full_conversation.push(choice.message.clone());
            }

            let conversation_text = self.extract_conversation_context(&full_conversation).await?;
            let embedding = {
                let mut provider = self.embedding_provider.lock()
                    .map_err(|e| anyhow::anyhow!("Lock error: {}", e))?;
                provider.encode(&conversation_text)?
            };

            // Store with or without context group
            if let Some(group) = shared_context_group {
                self.storage.store_context_with_group(agent_id, group, &conversation_text, &embedding).await?;
            } else {
                self.storage.store_context(agent_id, &conversation_text, &embedding).await?;
            }

            debug!("âœ… Interaction context stored successfully");
        }

        Ok(())
    }

    async fn extract_conversation_context(&self, messages: &[ChatMessage]) -> Result<String> {
        // Extract meaningful context from conversation
        let context = messages
            .iter()
            .map(|msg| format!("{}: {}", msg.role, msg.content))
            .collect::<Vec<_>>()
            .join("\n");

        Ok(context)
    }

    async fn apply_weight_dynamics(
        &self,
        original_messages: &[ChatMessage],
        similar_contexts: &[SimilarContext],
    ) -> Result<Vec<ChatMessage>> {
        debug!("Applying weight dynamics with {} similar contexts", similar_contexts.len());

        // ç®€åŒ–çš„å‹ç¼©é€»è¾‘ï¼Œé¿å…å¤æ‚çš„weight dynamicsè°ƒç”¨
        let compressed = self.fallback_compression(original_messages).await?;
        Ok(compressed)
    }

    async fn fallback_compression(&self, messages: &[ChatMessage]) -> Result<Vec<ChatMessage>> {
        // Simple fallback: keep last 3 messages
        let keep_count = std::cmp::min(3, messages.len());
        Ok(messages[messages.len() - keep_count..].to_vec())
    }

    fn calculate_compression_ratio(&self, original: &[ChatMessage], compressed: &[ChatMessage]) -> f32 {
        let original_length: usize = original.iter().map(|m| m.content.len()).sum();
        let compressed_length: usize = compressed.iter().map(|m| m.content.len()).sum();

        if original_length == 0 {
            return 0.0;
        }

        1.0 - (compressed_length as f32 / original_length as f32)
    }

    // ğŸ”§ æ™ºèƒ½ç”¨æˆ·èº«ä»½æå–ï¼ˆå‡å°‘ç¡¬ç¼–ç æ¨¡å¼ï¼‰
    fn extract_user_identity_smart(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // ğŸ”§ æ¨¡å¼1: è‡ªæˆ‘ä»‹ç»æ¨¡å¼
        let intro_patterns = [
            (r"i'?m (.+?)(?:[,.\n]|$)", 1),
            (r"my name is (.+?)(?:[,.\n]|$)", 1),
            (r"this is (.+?)(?:[,.\n]|$)", 1),
            (r"i am (.+?)(?:[,.\n]|$)", 1),
            (r"call me (.+?)(?:[,.\n]|$)", 1),
        ];

        for (pattern, group) in intro_patterns {
            if let Some(captures) = regex::Regex::new(pattern).ok()?.captures(&content_lower) {
                if let Some(matched) = captures.get(group) {
                    let identity = matched.as_str().trim();
                    if identity.len() > 1 && identity.len() < 50 && !identity.contains("assistant") {
                        return Some(identity.to_string());
                    }
                }
            }
        }

        None
    }

    // ğŸ”§ æ™ºèƒ½å®ä½“æå–
    fn extract_entities_smart(&self, content: &str) -> Vec<String> {
        let mut entities = Vec::new();
        let content_lower = content.to_lowercase();

        // ğŸ”§ æŠ€æœ¯æ ˆæ£€æµ‹
        let tech_terms = [
            "python", "javascript", "rust", "java", "typescript",
            "react", "vue", "angular", "tensorflow", "pytorch",
            "kubernetes", "docker", "aws", "azure", "gcp"
        ];

        // ğŸ”§ é¢†åŸŸæ£€æµ‹
        let domain_terms = [
            "machine learning", "ai", "blockchain", "fintech", "healthcare",
            "e-commerce", "gaming", "cybersecurity", "data science"
        ];

        // ğŸ”§ å…¬å¸ç±»å‹æ£€æµ‹
        let company_terms = [
            "startup", "corporation", "enterprise", "consulting", "agency"
        ];

        for term in tech_terms.iter().chain(domain_terms.iter()).chain(company_terms.iter()) {
            if content_lower.contains(term) {
                entities.push(term.to_string());
            }
        }

        entities
    }

    // ğŸ”§ æ™ºèƒ½ä¸»é¢˜æå–
    fn extract_topics_smart(&self, content: &str) -> Vec<String> {
        let mut topics = Vec::new();
        let content_lower = content.to_lowercase();

        // ğŸ”§ é—®é¢˜ç±»å‹æ£€æµ‹
        if content_lower.contains("how") && (content_lower.contains("work") || content_lower.contains("implement")) {
            topics.push("implementation".to_string());
        }

        if content_lower.contains("what") && (content_lower.contains("best") || content_lower.contains("recommend")) {
            topics.push("recommendations".to_string());
        }

        if content_lower.contains("problem") || content_lower.contains("issue") || content_lower.contains("error") {
            topics.push("troubleshooting".to_string());
        }

        // ğŸ”§ æŠ€æœ¯ä¸»é¢˜æ£€æµ‹
        let tech_topics = [
            ("algorithm", vec!["algorithm", "sort", "search", "optimize"]),
            ("database", vec!["database", "sql", "nosql", "query"]),
            ("frontend", vec!["frontend", "ui", "ux", "css", "html"]),
            ("backend", vec!["backend", "api", "server", "microservice"]),
            ("devops", vec!["deploy", "ci/cd", "pipeline", "infrastructure"]),
        ];

        for (topic, keywords) in tech_topics {
            if keywords.iter().any(|keyword| content_lower.contains(keyword)) {
                topics.push(topic.to_string());
            }
        }

        topics
    }

    // ğŸ”§ æ–°å¢ï¼šä»å¤šä¸ªä¸Šä¸‹æ–‡ä¸­æå–å…³é”®ä¿¡æ¯
    fn extract_key_information_from_contexts(&self, contexts: &[SimilarContext]) -> Vec<String> {
        let mut key_info = Vec::new();

        for context in contexts.iter().take(3) { // åªå¤„ç†æœ€ç›¸å…³çš„3ä¸ªä¸Šä¸‹æ–‡
            let content = &context.content;

            // æå–å®¢æˆ·å§“åå’Œå…¬å¸ä¿¡æ¯ (å¦‚ "Michael Chen from Alpha Corp")
            if let Some(client_info) = self.extract_client_information(content) {
                if !key_info.contains(&client_info) {
                    key_info.push(client_info);
                }
            }

            // æå–é‡è¦çš„ä¸šåŠ¡ç»†èŠ‚
            if let Some(business_detail) = self.extract_business_details(content) {
                if !key_info.contains(&business_detail) {
                    key_info.push(business_detail);
                }
            }

            // æå–è§£å†³æ–¹æ¡ˆä¿¡æ¯
            if let Some(solution_info) = self.extract_solution_information(content) {
                if !key_info.contains(&solution_info) {
                    key_info.push(solution_info);
                }
            }
        }

        key_info
    }

    // ğŸ”§ æå–å®¢æˆ·ä¿¡æ¯ï¼ˆå§“åã€å…¬å¸ç­‰ï¼‰- å¢å¼ºç‰ˆ
    fn extract_client_information(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // ğŸ”§ ä¼˜å…ˆåŒ¹é…å®Œæ•´çš„å®¢æˆ·ä¿¡æ¯æ¨¡å¼
        let client_patterns = [
            // å®Œæ•´å§“å + å…¬å¸æ¨¡å¼
            r"([A-Z][a-z]+\s+[A-Z][a-z]+)\s+from\s+([A-Z][a-zA-Z\s]+(?:Corp|Inc|LLC|Ltd|Corporation))",
            // ç®€åŒ–çš„å§“å + å…¬å¸æ¨¡å¼
            r"([A-Z][a-z]+)\s+from\s+([A-Z][a-zA-Z\s]+)",
            // ç›´æ¥çš„å®¢æˆ·ä»‹ç»æ¨¡å¼
            r"this\s+is\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)\s+from\s+([A-Z][a-zA-Z\s]+)",
            // Hiå¼€å¤´çš„è‡ªæˆ‘ä»‹ç»
            r"hi,?\s+this\s+is\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)?)",
        ];

        for pattern in client_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(content) {
                    match captures.len() {
                        3 => {
                            // åŒ…å«å§“åå’Œå…¬å¸
                            let name = captures.get(1).map(|m| m.as_str()).unwrap_or("");
                            let company = captures.get(2).map(|m| m.as_str()).unwrap_or("");
                            if !name.is_empty() && !company.is_empty() {
                                return Some(format!("Client: {} from {}", name, company.trim()));
                            }
                        },
                        2 => {
                            // åªæœ‰å§“å
                            let name = captures.get(1).map(|m| m.as_str()).unwrap_or("");
                            if !name.is_empty() {
                                return Some(format!("Client: {}", name));
                            }
                        },
                        _ => {}
                    }
                }
            }
        }

        // ğŸ”§ å¤‡ç”¨ï¼šå¯»æ‰¾å¸¸è§çš„å®¢æˆ·ä¿¡æ¯å…³é”®è¯
        if content_lower.contains("michael") && content_lower.contains("alpha") {
            return Some("Client: Michael from Alpha Corp".to_string());
        }

        if content_lower.contains("john") && content_lower.contains("techcorp") {
            return Some("Client: John from TechCorp".to_string());
        }

        None
    }

    // ğŸ”§ æå–ä¸šåŠ¡ç»†èŠ‚
    fn extract_business_details(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // è§„æ¨¡ä¿¡æ¯
        if content_lower.contains("inquiries") && content_lower.contains("month") {
            if let Some(volume) = self.extract_volume_info(&content_lower) {
                return Some(format!("Volume: {}", volume));
            }
        }

        // æŠ€æœ¯éœ€æ±‚
        if content_lower.contains("ai-powered") || content_lower.contains("ai powered") {
            return Some("Requirement: AI-powered solution".to_string());
        }

        // è¡Œä¸šä¿¡æ¯
        if content_lower.contains("customer service") {
            return Some("Domain: Customer Service".to_string());
        }

        None
    }

    // ğŸ”§ æå–è§£å†³æ–¹æ¡ˆä¿¡æ¯
    fn extract_solution_information(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        if content_lower.contains("recommend") || content_lower.contains("suggest") {
            // æå–æ¨èçš„è§£å†³æ–¹æ¡ˆ
            if content_lower.contains("enterprise") {
                return Some("Solution: Enterprise package recommended".to_string());
            }
            if content_lower.contains("custom") {
                return Some("Solution: Custom solution".to_string());
            }
        }

        None
    }

    // ğŸ”§ æå–æ•°é‡ä¿¡æ¯
    fn extract_volume_info(&self, content: &str) -> Option<String> {
        // åŒ¹é… "æ•°å­— + thousand/k + inquiries/month" æ¨¡å¼
        let volume_patterns = [
            r"(\d+[,\d]*)\s*(?:thousand|k)\s*inquiries",
            r"(\d+[,\d]*)\s*inquiries\s*per\s*month",
            r"(\d+[,\d]*)\s*monthly\s*inquiries",
        ];

        for pattern in volume_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(content) {
                    if let Some(number) = captures.get(1) {
                        return Some(format!("{} inquiries/month", number.as_str()));
                    }
                }
            }
        }

        None
    }

    // ğŸ”§ æ–°å¢ï¼šæ™ºèƒ½å‹ç¼©æ–¹æ³•
    async fn apply_smart_compression(&self, messages: &[ChatMessage]) -> Result<Vec<ChatMessage>> {
        debug!("Applying smart compression to {} messages", messages.len());

        // ğŸ”§ ç§»é™¤åŒé‡æ£€æŸ¥ - è°ƒç”¨æ–¹å·²ç»ç¡®è®¤éœ€è¦å‹ç¼©
        if messages.len() <= 2 {
            debug!("Too few messages for compression, returning original");
            return Ok(messages.to_vec());
        }

        // ğŸ”§ æ›´ç§¯æçš„å‹ç¼©ç­–ç•¥
        let keep_recent = if messages.len() > 8 {
            2  // é•¿å¯¹è¯åªä¿ç•™æœ€è¿‘2æ¡
        } else if messages.len() > 5 {
            3  // ä¸­ç­‰é•¿åº¦ä¿ç•™3æ¡
        } else {
            messages.len().saturating_sub(1)  // çŸ­å¯¹è¯ä¿ç•™å¤§éƒ¨åˆ†
        };

        let recent_messages = messages.iter().rev().take(keep_recent).rev().cloned().collect::<Vec<_>>();
        let historical_messages = &messages[..messages.len().saturating_sub(keep_recent)];

        // ğŸ”§ ç”Ÿæˆæ›´ç®€æ´çš„å‹ç¼©æ‘˜è¦
        let compressed_summary = if historical_messages.is_empty() {
            String::new()
        } else {
            self.compress_conversation_history(historical_messages)
        };

        let mut result = Vec::new();

        // ğŸ”§ åªæœ‰åœ¨æœ‰å®é™…å†å²å†…å®¹æ—¶æ‰æ·»åŠ æ‘˜è¦
        if !compressed_summary.is_empty() && compressed_summary.len() > 10 {
            result.push(ChatMessage {
                role: "system".to_string(),
                content: format!("Previous conversation: {}", compressed_summary),
            });
        }

        result.extend(recent_messages);

        debug!("âœ… Compressed {} messages to {} (summary: {} chars)",
               messages.len(), result.len(),
               compressed_summary.len());

        Ok(result)
    }

    // ğŸ”§ æ–°å¢ï¼šæ£€æµ‹æ˜¯å¦åŒ…å«ç”¨æˆ·èº«ä»½ä¿¡æ¯
    fn contains_user_identity(&self, content: &str) -> bool {
        let content_lower = content.to_lowercase();

        // ğŸ”§ æ›´ç²¾ç¡®çš„ç”¨æˆ·èº«ä»½æ¨¡å¼æ£€æµ‹
        let identity_patterns = [
            // å§“åæ¨¡å¼
            r"my name is ([a-zA-Z]+)",
            r"i'm ([a-zA-Z]+)",
            r"i am ([a-zA-Z]+)",
            r"this is ([a-zA-Z]+)",
            // å·¥ä½œ/é¡¹ç›®æ¨¡å¼
            r"i'm working on",
            r"i am working on",
            r"working on (a|an)?\s*([a-zA-Z\s]+)\s*(project|system)",
            r"project about ([a-zA-Z\s]+)",
            // èŒä¸š/è§’è‰²æ¨¡å¼
            r"i'm (a|an)\s*([a-zA-Z\s]+)",
            r"i am (a|an)\s*([a-zA-Z\s]+)",
        ];

        for pattern in identity_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if re.is_match(&content_lower) {
                    debug!("Found user identity pattern: {} in content: {}", pattern, &content[..std::cmp::min(100, content.len())]);
                    return true;
                }
            }
        }

        // ğŸ”§ å…³é”®è¯æ£€æµ‹ä½œä¸ºåå¤‡
        let identity_keywords = [
            "my name", "i'm", "i am", "working on", "project about",
            "alice", "bob", "charlie", "david", "emma", "frank",
            "python", "machine learning", "data science", "ai"
        ];

        for keyword in identity_keywords {
            if content_lower.contains(keyword) {
                debug!("Found identity keyword: {} in content", keyword);
                return true;
            }
        }

        false
    }

    // ğŸ”§ æ–°å¢ï¼šæ£€æµ‹å®¢æˆ·èº«ä»½ä¿¡æ¯ï¼ˆç”¨äºè·¨Agentåœºæ™¯ï¼‰
    fn contains_client_identity(&self, content: &str) -> bool {
        let content_lower = content.to_lowercase();

        let client_patterns = [
            r"client is ([a-zA-Z]+)",
            r"customer ([a-zA-Z]+)",
            r"([a-zA-Z]+) from ([a-zA-Z\s]+)",
            r"working with ([a-zA-Z]+)",
        ];

        for pattern in client_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if re.is_match(&content_lower) {
                    return true;
                }
            }
        }

        content_lower.contains("client") || content_lower.contains("customer")
    }

    // ğŸ”§ æ–°å¢ï¼šæ£€æµ‹ä¸šåŠ¡å…³é”®ä¿¡æ¯
    fn contains_business_info(&self, content: &str) -> bool {
        let content_lower = content.to_lowercase();

        let business_keywords = [
            "project", "system", "application", "solution", "requirements",
            "budget", "timeline", "deadline", "scope", "deliverable"
        ];

        business_keywords.iter().any(|keyword| content_lower.contains(keyword))
    }

    // ğŸ”§ æ–°å¢ï¼šæå–ç»¼åˆå…³é”®ä¿¡æ¯
    fn extract_comprehensive_key_information(&self, contexts: &[SimilarContext]) -> Vec<String> {
        let mut key_info = Vec::new();

        for context in contexts.iter().take(4) { // å¤„ç†æ›´å¤šä¸Šä¸‹æ–‡æ¥è·å¾—å®Œæ•´ä¿¡æ¯
            let content = &context.content;

            // å®¢æˆ·èº«ä»½ä¿¡æ¯
            if let Some(client_info) = self.extract_client_information(content) {
                if !key_info.contains(&client_info) {
                    key_info.push(client_info);
                }
            }

            // ä¸šåŠ¡è§„æ¨¡å’Œéœ€æ±‚
            if let Some(business_detail) = self.extract_business_details(content) {
                if !key_info.contains(&business_detail) {
                    key_info.push(business_detail);
                }
            }

            // æŠ€æœ¯è®¨è®ºå†…å®¹
            if let Some(tech_info) = self.extract_technical_discussion(content) {
                if !key_info.contains(&tech_info) {
                    key_info.push(tech_info);
                }
            }

            // è§£å†³æ–¹æ¡ˆå’Œå»ºè®®
            if let Some(solution_info) = self.extract_solution_information(content) {
                if !key_info.contains(&solution_info) {
                    key_info.push(solution_info);
                }
            }
        }

        key_info
    }

    // ğŸ”§ æ–°å¢ï¼šæå–æŠ€æœ¯è®¨è®ºå†…å®¹
    fn extract_technical_discussion(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // æ£€æµ‹æŠ€æœ¯ç›¸å…³çš„è®¨è®º
        if content_lower.contains("architecture") || content_lower.contains("infrastructure") {
            return Some("Discussion: Technical architecture".to_string());
        }

        if content_lower.contains("scalability") || content_lower.contains("scaling") {
            return Some("Discussion: Scalability requirements".to_string());
        }

        if content_lower.contains("security") || content_lower.contains("compliance") {
            return Some("Discussion: Security and compliance".to_string());
        }

        if content_lower.contains("integration") || content_lower.contains("crm") {
            return Some("Discussion: System integration".to_string());
        }

        if content_lower.contains("pricing") || content_lower.contains("budget") {
            return Some("Discussion: Pricing and budget".to_string());
        }

        if content_lower.contains("timeline") || content_lower.contains("implementation") {
            return Some("Discussion: Implementation timeline".to_string());
        }

        None
    }

    // ğŸ”§ æ–°å¢ï¼šæ¸©å’Œå‹ç¼©æ–¹æ³•ï¼ˆä¸“ä¸ºè·¨Agentåœºæ™¯è®¾è®¡ï¼‰
    async fn apply_gentle_compression(&self, messages: &[ChatMessage]) -> Result<Vec<ChatMessage>> {
        debug!("Applying gentle compression to {} messages for cross-agent context", messages.len());

        if messages.len() <= 3 {
            debug!("Too few messages for gentle compression, returning original");
            return Ok(messages.to_vec());
        }

        // ğŸ”§ æ¸©å’Œçš„å‹ç¼©ç­–ç•¥ï¼šä¿ç•™æ›´å¤šæœ€è¿‘çš„æ¶ˆæ¯
        let keep_recent = if messages.len() > 10 {
            4  // å¾ˆé•¿å¯¹è¯ä¿ç•™æœ€è¿‘4æ¡
        } else if messages.len() > 7 {
            3  // ä¸­é•¿å¯¹è¯ä¿ç•™æœ€è¿‘3æ¡
        } else {
            messages.len().saturating_sub(2)  // çŸ­å¯¹è¯ä¿ç•™å‡ ä¹æ‰€æœ‰
        };

        let recent_messages = messages.iter().rev().take(keep_recent).rev().cloned().collect::<Vec<_>>();
        let historical_messages = &messages[..messages.len().saturating_sub(keep_recent)];

        // ğŸ”§ ç”Ÿæˆæ›´è¯¦ç»†çš„å†å²æ‘˜è¦ï¼ˆä¸“ä¸ºè·¨Agentåœºæ™¯ï¼‰
        let compressed_summary = if historical_messages.is_empty() {
            String::new()
        } else {
            self.compress_conversation_history_detailed(historical_messages)
        };

        let mut result = Vec::new();

        // ğŸ”§ ç¡®ä¿æ‘˜è¦åŒ…å«è¶³å¤Ÿçš„ä¿¡æ¯
        if !compressed_summary.is_empty() && compressed_summary.len() > 15 {
            result.push(ChatMessage {
                role: "system".to_string(),
                content: format!("Previous team discussion: {}", compressed_summary),
            });
        }

        result.extend(recent_messages);

        debug!("âœ… Gently compressed {} messages to {} (detailed summary: {} chars)",
               messages.len(), result.len(),
               compressed_summary.len());

        Ok(result)
    }

    // ğŸ”§ æ–°å¢ï¼šè¯¦ç»†çš„å¯¹è¯å†å²å‹ç¼©ï¼ˆä¸“ä¸ºè·¨Agentåœºæ™¯ï¼‰
    fn compress_conversation_history_detailed(&self, messages: &[ChatMessage]) -> String {
        if messages.is_empty() {
            return String::new();
        }

        let mut summary_parts = Vec::new();
        let mut client_info = Vec::new();
        let mut business_info = Vec::new();
        let mut technical_info = Vec::new();

        for message in messages {
            let content = &message.content;

            // æå–å®¢æˆ·ç›¸å…³ä¿¡æ¯
            if let Some(client) = self.extract_client_information(content) {
                if !client_info.contains(&client) {
                    client_info.push(client);
                }
            }

            // æå–ä¸šåŠ¡ä¿¡æ¯
            if let Some(business) = self.extract_business_details(content) {
                if !business_info.contains(&business) {
                    business_info.push(business);
                }
            }

            // æå–æŠ€æœ¯è®¨è®º
            if let Some(tech) = self.extract_technical_discussion(content) {
                if !technical_info.contains(&tech) {
                    technical_info.push(tech);
                }
            }
        }

        // æ„å»ºè¯¦ç»†æ‘˜è¦
        if !client_info.is_empty() {
            summary_parts.push(client_info.join(", "));
        }

        if !business_info.is_empty() {
            summary_parts.push(business_info.join(", "));
        }

        if !technical_info.is_empty() {
            summary_parts.push(technical_info.join(", "));
        }

        if summary_parts.is_empty() {
            format!("Previous discussion: {} exchanges between team members", messages.len() / 2)
        } else {
            summary_parts.join("; ")
        }
    }

    // ğŸ”§ æ–°å¢ï¼šæå–æŒä¹…åŒ–ç”¨æˆ·èº«ä»½ä¿¡æ¯ï¼ˆå…³é”®ä¿®å¤ï¼‰
    fn extract_persistent_user_identity(&self, contexts: &[SimilarContext]) -> String {
        let mut identity_parts: Vec<String> = Vec::new();

        for context in contexts.iter() {
            let content = &context.content;
            let _content_lower = content.to_lowercase();

            // ğŸ”§ ä¼˜å…ˆæå–ç”¨æˆ·å§“å
            if let Some(name) = self.extract_user_name_robust(content) {
                if !identity_parts.iter().any(|part| part.contains(&name)) {
                    identity_parts.push(format!("Name: {}", name));
                }
            }

            // ğŸ”§ æå–å·¥ä½œ/é¡¹ç›®ä¿¡æ¯
            if let Some(project) = self.extract_project_info_robust(content) {
                if !identity_parts.iter().any(|part| part.contains(&project)) {
                    identity_parts.push(format!("Project: {}", project));
                }
            }

            // ğŸ”§ æå–èŒä¸šä¿¡æ¯
            if let Some(role) = self.extract_role_info_robust(content) {
                if !identity_parts.iter().any(|part| part.contains(&role)) {
                    identity_parts.push(format!("Role: {}", role));
                }
            }
        }

        if identity_parts.is_empty() {
            String::new()
        } else {
            identity_parts.join(", ")
        }
    }

    // ğŸ”§ æ–°å¢ï¼šå¼ºåŒ–çš„ç”¨æˆ·å§“åæå–
    fn extract_user_name_robust(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // ç›´æ¥å§“åæ¨¡å¼åŒ¹é…
        let name_patterns = [
            r"my name is ([a-zA-Z]+)",
            r"i'?m ([a-zA-Z]+)(?:\s|,|\.)",
            r"i am ([a-zA-Z]+)(?:\s|,|\.)",
            r"this is ([a-zA-Z]+)(?:\s|,|\.)",
            r"hi,?\s+i'?m ([a-zA-Z]+)",
        ];

        for pattern in name_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(&content_lower) {
                    if let Some(name_match) = captures.get(1) {
                        let name = name_match.as_str();
                        // è¿‡æ»¤æ‰å¸¸è§çš„éå§“åè¯æ±‡
                        if !["working", "doing", "building", "creating", "developing"].contains(&name)
                           && name.len() > 1 && name.len() < 20 {
                            return Some(name.to_string());
                        }
                    }
                }
            }
        }

        // ğŸ”§ å¤‡ç”¨ï¼šç‰¹å®šå§“åæ£€æµ‹
        let common_names = ["alice", "bob", "charlie", "sarah", "david", "emma", "michael", "john"];
        for name in common_names {
            if content_lower.contains(name) {
                return Some(name.to_string());
            }
        }

        None
    }

    // ğŸ”§ æ–°å¢ï¼šå¼ºåŒ–çš„é¡¹ç›®ä¿¡æ¯æå–
    fn extract_project_info_robust(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // é¡¹ç›®æè¿°æ¨¡å¼
        let project_patterns = [
            r"working on (a|an)?\s*([a-zA-Z\s]+?)\s*(project|system)",
            r"project about ([a-zA-Z\s]+)",
            r"building (a|an)?\s*([a-zA-Z\s]+?)\s*(system|application)",
            r"developing (a|an)?\s*([a-zA-Z\s]+?)\s*(solution|tool)",
        ];

        for pattern in project_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(&content_lower) {
                    // æ‰¾åˆ°é¡¹ç›®æè¿°çš„æ•è·ç»„
                    for i in 1..captures.len() {
                        if let Some(project_match) = captures.get(i) {
                            let project = project_match.as_str().trim();
                            if project.len() > 3 && project.len() < 50
                               && !["a", "an", "the", "project", "system"].contains(&project) {
                                return Some(project.to_string());
                            }
                        }
                    }
                }
            }
        }

        // ğŸ”§ ç‰¹å®šæŠ€æœ¯æ ˆæ£€æµ‹
        if content_lower.contains("python") && content_lower.contains("machine learning") {
            return Some("Python machine learning".to_string());
        }

        if content_lower.contains("fraud detection") {
            return Some("fraud detection system".to_string());
        }

        None
    }

    // ğŸ”§ æ–°å¢ï¼šå¼ºåŒ–çš„è§’è‰²ä¿¡æ¯æå–
    fn extract_role_info_robust(&self, content: &str) -> Option<String> {
        let content_lower = content.to_lowercase();

        // è§’è‰²æè¿°æ¨¡å¼
        let role_patterns = [
            r"i'?m (a|an)\s*([a-zA-Z\s]+?)(?:\s|,|\.|$)",
            r"i am (a|an)\s*([a-zA-Z\s]+?)(?:\s|,|\.|$)",
            r"work as (a|an)?\s*([a-zA-Z\s]+?)(?:\s|,|\.|$)",
            r"job as (a|an)?\s*([a-zA-Z\s]+?)(?:\s|,|\.|$)",
        ];

        for pattern in role_patterns {
            if let Ok(re) = regex::Regex::new(pattern) {
                if let Some(captures) = re.captures(&content_lower) {
                    if let Some(role_match) = captures.get(2) {
                        let role = role_match.as_str().trim();
                        if role.len() > 3 && role.len() < 30 {
                            return Some(role.to_string());
                        }
                    }
                }
            }
        }

        // ğŸ”§ ç‰¹å®šè§’è‰²æ£€æµ‹
        let roles = [
            "data scientist", "software engineer", "developer", "engineer",
            "analyst", "researcher", "consultant", "manager"
        ];

        for role in roles {
            if content_lower.contains(role) {
                return Some(role.to_string());
            }
        }

        None
    }

    // ğŸ”§ æ–°å¢ï¼šèº«ä»½ä¿æŠ¤å‹ç¼©æ–¹æ³•ï¼ˆç¡®ä¿ç”¨æˆ·èº«ä»½ä¸ä¸¢å¤±ï¼‰
    async fn apply_identity_preserving_compression(&self, messages: &[ChatMessage], user_identity: &str) -> Result<Vec<ChatMessage>> {
        debug!("Applying identity-preserving compression to {} messages, preserving: {}", messages.len(), user_identity);

        if messages.len() <= 3 {
            return Ok(messages.to_vec());
        }

        // ğŸ”§ æ›´ä¿å®ˆçš„å‹ç¼©ç­–ç•¥ï¼Œç¡®ä¿ç”¨æˆ·èº«ä»½ä¿¡æ¯ä¸ä¸¢å¤±
        let keep_recent = if messages.len() > 10 {
            4  // é•¿å¯¹è¯ä¿ç•™æœ€è¿‘4æ¡
        } else if messages.len() > 7 {
            3  // ä¸­ç­‰å¯¹è¯ä¿ç•™æœ€è¿‘3æ¡
        } else {
            messages.len().saturating_sub(1)  // çŸ­å¯¹è¯ä¿ç•™å¤§éƒ¨åˆ†
        };

        let recent_messages = messages.iter().rev().take(keep_recent).rev().cloned().collect::<Vec<_>>();
        let historical_messages = &messages[..messages.len().saturating_sub(keep_recent)];

        // ğŸ”§ ç”ŸæˆåŒ…å«ç”¨æˆ·èº«ä»½çš„å‹ç¼©æ‘˜è¦
        let compressed_summary = if historical_messages.is_empty() {
            if !user_identity.is_empty() {
                format!("User context: {}", user_identity)
            } else {
                String::new()
            }
        } else {
            let history_summary = self.compress_conversation_history(historical_messages);
            if !user_identity.is_empty() {
                format!("{} | {}", user_identity, history_summary)
            } else {
                history_summary
            }
        };

        let mut result = Vec::new();

        // ğŸ”§ å¼ºåˆ¶æ·»åŠ ç”¨æˆ·èº«ä»½æ‘˜è¦ï¼ˆå³ä½¿å†å²ä¸ºç©ºï¼‰
        if !compressed_summary.is_empty() {
            result.push(ChatMessage {
                role: "system".to_string(),
                content: format!("PRESERVED CONTEXT: {}", compressed_summary),
            });
        }

        result.extend(recent_messages);

        debug!("âœ… Identity-preserving compression: {} -> {} messages, identity preserved: {}",
               messages.len(), result.len(), !user_identity.is_empty());

        Ok(result)
    }
}

#[derive(Debug, Clone)]
pub struct SimilarContext {
    pub content: String,
    pub similarity: f32,
    pub timestamp: i64,
}
