use crate::analyzer::PromptAnalyzer;
use crate::encoder::SimpleTextEncoder;
use prompt_compiler_weights::*;
use serde::{Deserialize, Serialize};

/// é«˜çº§åˆ†æå™¨é…ç½®
#[derive(Debug, Clone)]
pub struct AdvancedAnalyzerConfig {
    /// å­¦ä¹ ç‡
    pub learning_rate: f32,
    /// æ­£åˆ™åŒ–å¼ºåº¦
    pub regularization_strength: f32,
    /// æœ€å¤§è¿­ä»£æ¬¡æ•°
    pub max_iterations: usize,
    /// æ”¶æ•›é˜ˆå€¼
    pub convergence_threshold: f32,
    /// æ˜¯å¦å¯ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡
    pub adaptive_learning_rate: bool,
}

impl Default for AdvancedAnalyzerConfig {
    fn default() -> Self {
        Self {
            learning_rate: 0.1,  // é™ä½å­¦ä¹ ç‡
            regularization_strength: 0.05,  // å¢å¼ºæ­£åˆ™åŒ–
            max_iterations: 50,
            convergence_threshold: 0.01,
            adaptive_learning_rate: true,
        }
    }
}

/// è¯¦ç»†çš„æ”¶æ•›åˆ†æç»“æœ
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetailedConvergenceAnalysis {
    /// æ¯æ­¥çš„æ¢¯åº¦èŒƒæ•°
    pub gradient_norms: Vec<f32>,
    /// æ¯æ­¥çš„æ•ˆæœå¾—åˆ†
    pub effectiveness_scores: Vec<f32>,
    /// æœ€ç»ˆæ”¶æ•›ç‡
    pub final_convergence_rate: f32,
    /// æ˜¯å¦æ”¶æ•›
    pub converged: bool,
    /// æ”¶æ•›æ‰€éœ€æ­¥æ•°
    pub convergence_steps: Option<usize>,
    /// æ”¶æ•›ç±»å‹
    pub convergence_type: ConvergenceType,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ConvergenceType {
    /// å¿«é€Ÿæ”¶æ•›
    Rapid,
    /// å¹³ç¨³æ”¶æ•›
    Steady,
    /// ç¼“æ…¢æ”¶æ•›
    Slow,
    /// éœ‡è¡ä½†æ”¶æ•›
    Oscillating,
    /// å‘æ•£
    Diverging,
    /// å¹³ç¨³ä½†æœªæ”¶æ•›
    Stable,
}

/// å¢å¼ºç‰ˆpromptåˆ†æå™¨
pub struct EnhancedPromptAnalyzer {
    base_analyzer: PromptAnalyzer,
    config: AdvancedAnalyzerConfig,
}

impl EnhancedPromptAnalyzer {
    /// åˆ›å»ºå¢å¼ºç‰ˆåˆ†æå™¨
    pub fn new(config: AdvancedAnalyzerConfig) -> Result<Self, WeightError> {
        // åˆ›å»ºåŸºç¡€åˆ†æå™¨ä½†ä½¿ç”¨æ–°çš„é…ç½®
        let encoder = SimpleTextEncoder::new();

        let dynamics_config = DynamicsConfig {
            learning_rate: config.learning_rate,
            use_skip_connections: true,
            regularization_strength: config.regularization_strength,
        };

        let dynamics = ImplicitDynamics::new(
            encoder.prompt_feature_dim(),
            encoder.task_feature_dim(),
            dynamics_config
        )?;

        let base_analyzer = PromptAnalyzer {
            encoder,
            dynamics,
        };

        Ok(Self {
            base_analyzer,
            config,
        })
    }

    /// æ·±åº¦æ”¶æ•›åˆ†æ
    pub fn deep_convergence_analysis(
        &mut self,
        prompt: &str,
        task: &str,
    ) -> Result<DetailedConvergenceAnalysis, WeightError> {
        let context = self.base_analyzer.encoder.encode_prompt(prompt);
        let query = self.base_analyzer.encoder.encode_task(task);

        let mut gradient_norms = Vec::new();
        let mut effectiveness_scores = Vec::new();
        let mut updates = Vec::new();

        let mut current_learning_rate = self.config.learning_rate;

        println!("ğŸ”¬ å¼€å§‹æ·±åº¦æ”¶æ•›åˆ†æ");
        println!("Prompt: {}", prompt);
        println!("Task: {}", task);
        println!("åˆå§‹å­¦ä¹ ç‡: {:.4}", current_learning_rate);
        println!("{}", "=".repeat(60));

        for step in 0..self.config.max_iterations {
            // æ›´æ–°åŠ¨æ€é…ç½®ï¼ˆå¦‚æœå¯ç”¨è‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰
            if self.config.adaptive_learning_rate && step > 0 {
                let recent_variance = self.calculate_gradient_variance(&gradient_norms, 3);
                if recent_variance > 0.1 {
                    current_learning_rate *= 0.9; // å‡å°‘å­¦ä¹ ç‡
                    self.update_learning_rate(current_learning_rate)?;
                }
            }

            // æ‰§è¡Œæƒé‡æ›´æ–°
            let update = self.base_analyzer.dynamics.update_step(&context, &query)?;
            let gradient_norm = update.delta_w.norm();
            let effectiveness = update.effectiveness_score();

            gradient_norms.push(gradient_norm);
            effectiveness_scores.push(effectiveness);
            updates.push(update);

            println!("æ­¥éª¤ {}: æ¢¯åº¦èŒƒæ•° {:.6}, æ•ˆæœå¾—åˆ† {:.6}, å­¦ä¹ ç‡ {:.4}",
                step + 1, gradient_norm, effectiveness, current_learning_rate);

            // æ£€æŸ¥æ”¶æ•›
            if gradient_norm < self.config.convergence_threshold {
                println!("âœ… åœ¨ç¬¬ {} æ­¥è¾¾åˆ°æ”¶æ•›ï¼", step + 1);

                return Ok(DetailedConvergenceAnalysis {
                    gradient_norms: gradient_norms.clone(),  // æ·»åŠ  clone()
                    effectiveness_scores,
                    final_convergence_rate: self.calculate_convergence_rate(&gradient_norms),
                    converged: true,
                    convergence_steps: Some(step + 1),
                    convergence_type: self.classify_convergence_type(&gradient_norms),
                });
            }

            // æ£€æŸ¥å‘æ•£
            if gradient_norm > 10.0 {
                println!("âŒ æ£€æµ‹åˆ°å‘æ•£ï¼Œåœæ­¢åˆ†æ");
                break;
            }
        }

        println!("â° è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåˆ†æç»“æŸ");

        Ok(DetailedConvergenceAnalysis {
            gradient_norms: gradient_norms.clone(),
            effectiveness_scores,
            final_convergence_rate: self.calculate_convergence_rate(&gradient_norms),
            converged: false,
            convergence_steps: None,
            convergence_type: self.classify_convergence_type(&gradient_norms),
        })
    }

    /// è®¡ç®—æ¢¯åº¦æ–¹å·®
    fn calculate_gradient_variance(&self, gradients: &[f32], window: usize) -> f32 {
        if gradients.len() < window {
            return 0.0;
        }

        let recent: Vec<f32> = gradients.iter().rev().take(window).cloned().collect();
        let mean = recent.iter().sum::<f32>() / recent.len() as f32;
        let variance = recent.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<f32>() / recent.len() as f32;

        variance
    }

    /// æ›´æ–°å­¦ä¹ ç‡
    fn update_learning_rate(&mut self, new_rate: f32) -> Result<(), WeightError> {
        // è¿™é‡Œéœ€è¦é‡æ–°åˆ›å»ºdynamicsä»¥æ›´æ–°å­¦ä¹ ç‡
        // è¿™æ˜¯å½“å‰å®ç°çš„é™åˆ¶ï¼Œåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥å…è®¸åŠ¨æ€æ›´æ–°
        let config = DynamicsConfig {
            learning_rate: new_rate,
            use_skip_connections: true,
            regularization_strength: self.config.regularization_strength,
        };

        self.base_analyzer.dynamics = ImplicitDynamics::new(
            self.base_analyzer.encoder.prompt_feature_dim(),
            self.base_analyzer.encoder.task_feature_dim(),
            config
        )?;

        Ok(())
    }

    /// è®¡ç®—æ”¶æ•›ç‡
    fn calculate_convergence_rate(&self, gradient_norms: &[f32]) -> f32 {
        if gradient_norms.len() < 4 {
            return 0.0;
        }

        let early_avg = gradient_norms.iter().take(3).sum::<f32>() / 3.0;
        let late_avg = gradient_norms.iter().rev().take(3).sum::<f32>() / 3.0;

        if early_avg > 0.0 {
            (early_avg - late_avg) / early_avg
        } else {
            0.0
        }
    }

    /// åˆ†ç±»æ”¶æ•›ç±»å‹
    fn classify_convergence_type(&self, gradient_norms: &[f32]) -> ConvergenceType {
        if gradient_norms.len() < 3 {
            return ConvergenceType::Stable;
        }

        let first = gradient_norms[0];
        let last = *gradient_norms.last().unwrap();
        let variance = self.calculate_gradient_variance(gradient_norms, gradient_norms.len());

        // å‘æ•£
        if last > first * 1.5 {
            return ConvergenceType::Diverging;
        }

        // æ”¶æ•›
        if last < first * 0.1 {
            if variance < 0.01 {
                return ConvergenceType::Rapid;
            } else {
                return ConvergenceType::Oscillating;
            }
        }

        // å¹³ç¨³æ”¶æ•›
        if last < first * 0.5 && variance < 0.05 {
            return ConvergenceType::Steady;
        }

        // ç¼“æ…¢æ”¶æ•›
        if last < first * 0.8 {
            return ConvergenceType::Slow;
        }

        ConvergenceType::Stable
    }

    /// è·å–åŸºç¡€åˆ†æå™¨çš„å¼•ç”¨
    pub fn base_analyzer(&mut self) -> &mut PromptAnalyzer {
        &mut self.base_analyzer
    }
}
