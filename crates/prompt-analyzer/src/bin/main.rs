use clap::{Parser, Subcommand};
use prompt_analyzer::*;

#[derive(Parser)]
#[command(name = "prompt-analyzer")]
#[command(about = "Analyze prompt effectiveness using mathematical models")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// æ¯”è¾ƒä¸¤ä¸ªpromptçš„æ•ˆæœ
    Compare {
        #[arg(long)]
        prompt_a: String,
        #[arg(long)]
        prompt_b: String,
        #[arg(long)]
        task: String,
        /// æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        #[arg(long)]
        save: bool,
    },
    /// åˆ†æå•ä¸ªprompt
    Analyze {
        #[arg(long)]
        prompt: String,
        #[arg(long)]
        task: String,
        /// æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        #[arg(long)]
        save: bool,
    },
    /// è¿è¡Œå†…ç½®æµ‹è¯•ç”¨ä¾‹
    Test,
    /// è¿­ä»£å¼ä¼˜åŒ–åˆ†æ
    Optimize {
        #[arg(long)]
        prompt: String,
        #[arg(long)]
        task: String,
        #[arg(long, default_value = "5")]
        steps: usize,
        /// æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        #[arg(long)]
        save: bool,
    },
    /// æŸ¥è¯¢å†å²è®°å½• (æ–°å¢)
    History {
        #[arg(long)]
        type_filter: Option<String>, // analysis, comparison, optimization
        #[arg(long)]
        task_filter: Option<String>,
        #[arg(long)]
        limit: Option<usize>,
    },
    /// æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ (æ–°å¢)
    Stats,
    /// æ·±åº¦æ”¶æ•›åˆ†æ (æ–°å¢)
    Converge {
        #[arg(long)]
        prompt: String,
        #[arg(long)]
        task: String,
        #[arg(long, default_value = "0.1")]
        learning_rate: f32,
        #[arg(long, default_value = "30")]
        max_iterations: usize,
    },
    /// è¿è¡Œ Prompt è´¨é‡åŸºå‡†æµ‹è¯• (æ–°å¢)
    Benchmark {
        /// æ•°æ®åº“è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        #[arg(long)]
        db_path: Option<String>,
        /// åªè¿è¡Œç‰¹å®šç±»åˆ«çš„æµ‹è¯•
        #[arg(long)]
        category: Option<String>,
        /// ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        #[arg(long)]
        visualize: bool,
        /// å›¾è¡¨è¾“å‡ºç›®å½•
        #[arg(long, default_value = "./charts")]
        chart_dir: String,
    },
    /// å•ç‹¬ç”Ÿæˆæ”¶æ•›å¯è§†åŒ–å›¾è¡¨ (æ–°å¢)
    Visualize {
        #[arg(long)]
        prompt: String,
        #[arg(long)]
        task: String,
        #[arg(long, default_value = "0.1")]
        learning_rate: f32,
        #[arg(long, default_value = "30")]
        max_iterations: usize,
        #[arg(long, default_value = "./convergence_chart.png")]
        output: String,
    },
}

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let cli = Cli::parse();

    match cli.command {
        Commands::Compare { prompt_a, prompt_b, task, save } => {
            let mut analyzer = PromptAnalyzer::new()?;
            let result = analyzer.compare_prompts(&prompt_a, &prompt_b, &task)?;

            println!("=== Prompt Comparison Results ===");
            println!("Task: {}", task);
            println!();
            println!("Prompt A Score: {:.4}", result.prompt_a_score);
            println!("Prompt B Score: {:.4}", result.prompt_b_score);
            println!("Winner: Prompt {}", result.winner);
            println!("Effectiveness Ratio: {:.2}", result.effectiveness_ratio);
            println!("Convergence Diff: {:.4}", result.convergence_diff);
            println!("Confidence: {:.2}", result.confidence);

            if save {
                // ä¿å­˜æ¯”è¾ƒç»“æœåˆ°æ•°æ®åº“çš„é€»ï¿½ï¿½ï¿½
                println!("\nç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚");
            }
        }

        Commands::Analyze { prompt, task, save } => {
            let mut analyzer = PromptAnalyzer::new()?;
            let result = analyzer.analyze_single_prompt(&prompt, &task)?;

            println!("=== Prompt Analysis Results ===");
            println!("Task: {}", task);
            println!("Prompt: {}", prompt);
            println!();
            println!("Effectiveness Score: {:.4}", result.effectiveness_score);
            println!("Convergence Rate: {:.4}", result.convergence_rate);
            println!("Update Magnitude: {:.4}", result.update_magnitude);
            println!("Is Stable: {}", result.is_stable);

            if save {
                // ä¿å­˜åˆ†æç»“æœåˆ°æ•°æ®åº“çš„é€»è¾‘
                println!("\nç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚");
            }
        }

        Commands::Test => {
            println!("=== Running Built-in Test Cases ===");
            let mut analyzer = PromptAnalyzer::new()?;
            let mut correct = 0;
            let total = TEST_CASES.len();

            for (i, test_case) in TEST_CASES.iter().enumerate() {
                println!("\nTest {}: {}", i + 1, test_case.description);
                println!("Task: {}", test_case.task);

                let result = analyzer.compare_prompts(
                    test_case.good_prompt,
                    test_case.bad_prompt,
                    test_case.task
                )?;

                let predicted_winner = match result.winner.as_str() {
                    "A" => "good",
                    "B" => "bad",
                    _ => "unknown",
                };

                let is_correct = predicted_winner == test_case.expected_winner;
                if is_correct {
                    correct += 1;
                }

                println!("Expected: {} | Predicted: {} | {}",
                    test_case.expected_winner,
                    predicted_winner,
                    if is_correct { "âœ“" } else { "âœ—" }
                );
                println!("Scores - Good: {:.3}, Bad: {:.3}, Confidence: {:.2}",
                    result.prompt_a_score,
                    result.prompt_b_score,
                    result.confidence
                );
            }

            println!("\n=== Test Summary ===");
            println!("Accuracy: {}/{} ({:.1}%)", correct, total, (correct as f32 / total as f32) * 100.0);
        }

        Commands::Optimize { prompt, task, steps, save } => {
            let mut sequential_analyzer = SequentialPromptAnalyzer::new()?;
            let history = sequential_analyzer.optimize_iteratively(&prompt, &task, steps)?;

            println!("\nğŸ¯ è¿­ä»£ä¼˜åŒ–å®Œæˆï¼");
            println!("åŸå§‹ Prompt: {}", history.original_prompt);
            println!("æœ€ç»ˆæ”¶æ•›ç‡: {:.4}", history.final_convergence_rate);
            println!("æ€»ä½“æ”¹è¿›: {:.1}%", history.total_improvement);

            println!("\nğŸ“ˆ ä¼˜åŒ–è½¨è¿¹:");
            for step in &history.steps {
                println!("  æ­¥éª¤ {}: å¾—åˆ† {:.3} | å¹…åº¦ {:.3} | ç¨³å®š {}",
                    step.step_number,
                    step.analysis.effectiveness_score,
                    step.analysis.update_magnitude,
                    if step.analysis.is_stable { "âœ…" } else { "âŒ" }
                );
            }

            if save {
                // ä¿å­˜ä¼˜åŒ–å†å²åˆ°æ•°æ®åº“çš„é€»è¾‘
                println!("\nä¼˜åŒ–å†å²å·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚");
            }
        }

        Commands::History { type_filter, task_filter, limit } => {
            // æŸ¥è¯¢å†å²è®°å½•çš„é€»è¾‘
            println!("=== æŸ¥è¯¢å†å²è®°å½• ===");
            println!("ç±»å‹è¿‡æ»¤: {:?}", type_filter);
            println!("ä»»åŠ¡è¿‡æ»¤: {:?}", task_filter);
            println!("é™åˆ¶æ¡æ•°: {:?}", limit);

            // ç¤ºä¾‹è¾“å‡º
            println!("\nå†å²è®°å½•ç¤ºä¾‹ï¼š");
            println!("1. ç±»å‹: analysis | ä»»åŠ¡: ç¤ºä¾‹ä»»åŠ¡ | æ—¶é—´: 2023-10-01");
            println!("2. ç±»å‹: comparison | ä»»åŠ¡: ç¤ºä¾‹ä»»åŠ¡ | æ—¶é—´: 2023-10-02");
        }

        Commands::Stats => {
            // æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯çš„é€»è¾‘
            println!("=== æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ ===");

            // ç¤ºä¾‹ç»Ÿè®¡æ•°æ®
            let total_prompts_analyzed = 120;
            let total_comparisons_made = 80;
            let total_optimizations_run = 30;

            println!("æ€»å…±åˆ†æçš„æç¤ºè¯æ•°é‡: {}", total_prompts_analyzed);
            println!("æ€»å…±è¿›è¡Œçš„æ¯”è¾ƒæ¬¡æ•°: {}", total_comparisons_made);
            println!("æ€»å…±è¿è¡Œçš„ä¼˜åŒ–æ¬¡æ•°: {}", total_optimizations_run);
        }

        Commands::Converge { prompt, task, learning_rate, max_iterations } => {
            let config = AdvancedAnalyzerConfig {
                learning_rate,
                regularization_strength: 0.05,
                max_iterations,
                convergence_threshold: 0.01,
                adaptive_learning_rate: true,
            };

            let mut enhanced_analyzer = EnhancedPromptAnalyzer::new(config)?;
            let analysis = enhanced_analyzer.deep_convergence_analysis(&prompt, &task)?;

            println!("\nğŸ¯ æ·±åº¦æ”¶æ•›åˆ†æå®Œæˆï¼");
            println!("æœ€ç»ˆæ”¶æ•›ç‡: {:.4}", analysis.final_convergence_rate);
            println!("æ”¶æ•›ç±»å‹: {:?}", analysis.convergence_type);
            println!("æ˜¯å¦æ”¶æ•›: {}", if analysis.converged { "âœ…" } else { "âŒ" });

            if let Some(steps) = analysis.convergence_steps {
                println!("æ”¶æ•›æ­¥æ•°: {}", steps);
            }

            println!("\nğŸ“Š æ¢¯åº¦å˜åŒ–è½¨è¿¹:");
            for (i, (grad, score)) in analysis.gradient_norms.iter()
                .zip(analysis.effectiveness_scores.iter()).enumerate() {
                println!("  æ­¥éª¤ {}: æ¢¯åº¦ {:.6} | å¾—åˆ† {:.6}", i + 1, grad, score);
            }

            // åˆ†ææ”¶æ•›è´¨é‡
            match analysis.convergence_type {
                ConvergenceType::Rapid => println!("\nğŸš€ ä¼˜ç§€ï¼å¿«é€Ÿæ”¶æ•›ï¼Œpromptè´¨é‡å¾ˆé«˜"),
                ConvergenceType::Steady => println!("\nğŸ“ˆ è‰¯å¥½ï¼å¹³ç¨³æ”¶æ•›ï¼Œpromptç»“æ„åˆç†"),
                ConvergenceType::Slow => println!("\nğŸŒ ä¸€èˆ¬ï¼šç¼“æ…¢æ”¶æ•›ï¼Œå¯ä»¥ï¿½ï¿½ä¸€æ­¥ä¼˜åŒ–"),
                ConvergenceType::Oscillating => println!("\nğŸŒŠ éœ‡è¡æ”¶æ•›ï¼Œå»ºè®®é™ä½å­¦ä¹ ç‡"),
                ConvergenceType::Diverging => println!("\nâŒ å‘æ•£ï¼promptå¯èƒ½å­˜åœ¨é—®é¢˜"),
                ConvergenceType::Stable => println!("\nâš–ï¸ ç¨³å®šä½†æœªæ”¶æ•›ï¼Œéœ€è¦æ›´å¤šè¿­ä»£"),
            }
        }

        Commands::Benchmark { db_path, category, visualize, chart_dir } => {
            println!("ğŸ§ª === è¿è¡Œ Prompt è´¨é‡åŸºå‡†æµ‹è¯• ===");

            let mut assessor = PromptQualityAssessor::new(db_path.as_deref())?;
            let results = assessor.run_full_benchmark()?;

            // å¦‚æœæŒ‡å®šäº†ç±»åˆ«è¿‡æ»¤ï¼Œåˆ™åªæ˜¾ç¤ºç›¸å…³ç»“æœ
            if let Some(cat) = category {
                println!("\nğŸ” è¿‡æ»¤ç±»åˆ«: {}", cat);
                let filtered: Vec<_> = results.iter()
                    .filter(|r| format!("{:?}", r.benchmark.category).to_lowercase().contains(&cat.to_lowercase()))
                    .collect();

                if filtered.is_empty() {
                    println!("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æµ‹è¯•ç±»åˆ«");
                } else {
                    println!("ğŸ“‹ æ‰¾åˆ° {} ä¸ªåŒ¹é…çš„æµ‹è¯•ç”¨ä¾‹", filtered.len());
                    for result in filtered {
                        println!("\nğŸ¯ {} ({})", result.benchmark.name, result.performance_rating);
                        for rec in &result.recommendations {
                            println!("  ğŸ’¡ {}", rec);
                        }
                    }
                }
            }

            // ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
            if visualize {
                use std::fs;
                fs::create_dir_all(&chart_dir)?;

                println!("\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼Œè¾“å‡ºç›®å½•: {}", chart_dir);

                // 1. åŸºå‡†æµ‹è¯•æ¯”è¾ƒå›¾è¡¨
                let chart_data: Vec<(String, f32, String)> = results.iter()
                    .map(|r| (r.benchmark.name.clone(), r.quality_score, format!("{:?}", r.benchmark.category)))
                    .collect();

                let benchmark_chart_path = format!("{}/benchmark_comparison.png", chart_dir);
                ConvergenceVisualizer::plot_benchmark_comparison(&chart_data, &benchmark_chart_path)?;

                // 2. ä¸ºå±•ç°å¤æ‚æ”¶æ•›è¿‡ç¨‹çš„promptç”Ÿæˆå•ç‹¬å›¾è¡¨
                for result in &results {
                    if result.analysis.gradient_norms.len() > 5 {  // åªä¸ºæœ‰ä¸°å¯Œæ”¶æ•›æ•°æ®çš„promptç”Ÿæˆå›¾è¡¨
                        let chart_path = format!("{}/{}_convergence.png", chart_dir, result.benchmark.name);
                        let title = format!("æ”¶æ•›åˆ†æ: {} (å¾—åˆ†: {:.3})", result.benchmark.name, result.quality_score);
                        ConvergenceVisualizer::plot_convergence_analysis(&result.analysis, &chart_path, &title)?;
                    }
                }

                // 3. æ”¶æ•›ç±»å‹åˆ†å¸ƒå›¾
                let mut convergence_type_counts = std::collections::HashMap::new();
                for result in &results {
                    let type_name = format!("{:?}", result.analysis.convergence_type);
                    *convergence_type_counts.entry(type_name).or_insert(0) += 1;
                }

                let distribution_data: Vec<(&str, usize)> = convergence_type_counts.iter()
                    .map(|(k, v)| (k.as_str(), *v))
                    .collect();

                let distribution_chart_path = format!("{}/convergence_distribution.png", chart_dir);
                ConvergenceVisualizer::plot_convergence_type_distribution(&distribution_data, &distribution_chart_path)?;

                println!("âœ… å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼");
            }

            println!("\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆï¼å…±æµ‹è¯• {} ä¸ª prompt", results.len());
        }

        Commands::Visualize { prompt, task, learning_rate, max_iterations, output } => {
            println!("ğŸ“ˆ === ç”Ÿæˆæ”¶æ•›å¯è§†åŒ–å›¾è¡¨ ===");

            let config = AdvancedAnalyzerConfig {
                learning_rate,
                regularization_strength: 0.05,
                max_iterations,
                convergence_threshold: 0.01,
                adaptive_learning_rate: true,
            };

            let mut enhanced_analyzer = EnhancedPromptAnalyzer::new(config)?;
            let analysis = enhanced_analyzer.deep_convergence_analysis(&prompt, &task)?;

            let title = format!("æ”¶æ•›åˆ†æ: {} | æ”¶æ•›ç‡: {:.3}", task, analysis.final_convergence_rate);
            ConvergenceVisualizer::plot_convergence_analysis(&analysis, &output, &title)?;

            println!("âœ… å›¾è¡¨å·²ä¿å­˜è‡³: {}", output);
            println!("ğŸ“Š åˆ†æç»“æœ:");
            println!("  æ”¶æ•›ç±»å‹: {:?}", analysis.convergence_type);
            println!("  æ˜¯å¦æ”¶æ•›: {}", if analysis.converged { "âœ…" } else { "âŒ" });
            println!("  æ€»æ­¥æ•°: {}", analysis.gradient_norms.len());
        }
    }

    Ok(())
}
