#!/usr/bin/env python3
"""
PC Node æ€§èƒ½æŠ¥å‘Šç”Ÿæˆè„šæœ¬
è‡ªåŠ¨è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆå®Œæ•´çš„æ€§èƒ½åˆ†ææŠ¥å‘Š
"""

import os
import sys
import json
import shutil
from datetime import datetime
from test_runner import TestRunner
from test_data_analyzer import TestDataAnalyzer


def create_docs_structure():
    """åˆ›å»ºdocsç›®å½•ç»“æ„"""
    docs_dir = "../docs"
    images_dir = os.path.join(docs_dir, "images")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(images_dir, exist_ok=True)
    return docs_dir, images_dir


def move_charts_to_docs(test_results_dir, images_dir):
    """å°†å›¾è¡¨æ–‡ä»¶ç§»åŠ¨åˆ°docs/imagesç›®å½•"""
    chart_files = []

    # æŸ¥æ‰¾æ‰€æœ‰å›¾è¡¨æ–‡ä»¶
    for file in os.listdir(test_results_dir):
        if file.endswith('.png'):
            src_path = os.path.join(test_results_dir, file)
            dst_path = os.path.join(images_dir, file)
            shutil.copy2(src_path, dst_path)
            chart_files.append(file)
            print(f"ğŸ“Š å›¾è¡¨å·²ç§»åŠ¨: {file} -> docs/images/")

    return chart_files


def generate_english_report(chinese_report_path, docs_dir):
    """ç”Ÿæˆè‹±æ–‡ç‰ˆæœ¬çš„æŠ¥å‘Š"""
    english_report_path = os.path.join(docs_dir, "pc_node_performance_report.md")

    # è¯»å–ä¸­æ–‡æŠ¥å‘Š
    with open(chinese_report_path, 'r', encoding='utf-8') as f:
        chinese_content = f.read()

    # æ›´å®Œå–„çš„ä¸­è‹±æ–‡å¯¹ç…§ç¿»è¯‘
    english_content = chinese_content.replace(
        "# PC Node æ€§èƒ½åˆ†ææŠ¥å‘Š", "# PC Node Performance Analysis Report"
    ).replace(
        "*ç”Ÿæˆæ—¶é—´:", "*Generated on:"
    ).replace(
        "å¹´", "/"
    ).replace(
        "æœˆ", "/"
    ).replace(
        "æ—¥*", "*"
    ).replace(
        "## ğŸ“Š æµ‹è¯•æ¦‚è§ˆ", "## ğŸ“Š Test Overview"
    ).replace(
        "### å•æ™ºèƒ½ä½“æµ‹è¯•ç»“æœ", "### Single Agent Test Results"
    ).replace(
        "### å¤šæ™ºèƒ½ä½“æµ‹è¯•ç»“æœ", "### Multi-Agent Test Results"
    ).replace(
        "**Tokenæ•ˆç‡æå‡**", "**Token Efficiency Improvement**"
    ).replace(
        "![å•æ™ºèƒ½ä½“æ€§èƒ½å¯¹æ¯”](images/single_agent_comparison.png)",
        "![Single Agent Performance Comparison](images/single_agent_comparison.png)"
    ).replace(
        "![å¤šæ™ºèƒ½ä½“æ€§èƒ½å¯¹æ¯”](images/multi_agent_comparison.png)",
        "![Multi-Agent Performance Comparison](images/multi_agent_comparison.png)"
    ).replace(
        "## ğŸ’¡ æ€§èƒ½æ´å¯Ÿ", "## ğŸ’¡ Performance Insights"
    ).replace(
        "### Context Sharingæ•ˆæœ", "### Context Sharing Effectiveness"
    ).replace(
        "**å•æ™ºèƒ½ä½“æ•ˆç‡**", "**Single Agent Efficiency**"
    ).replace(
        "**å¤šæ™ºèƒ½ä½“æ•ˆç‡**", "**Multi-Agent Efficiency**"
    ).replace(
        "**å¯æ‰©å±•æ€§å› å­**", "**Scalability Factor**"
    ).replace(
        "### å¤æ‚åº¦å½±å“", "### Complexity Impact"
    ).replace(
        "**å•æ™ºèƒ½ä½“å¹³å‡Token**", "**Single Agent Avg Tokens**"
    ).replace(
        "**å¤šæ™ºèƒ½ä½“å¹³å‡Token**", "**Multi-Agent Avg Tokens**"
    ).replace(
        "**å¤æ‚åº¦å¼€é”€**", "**Complexity Overhead**"
    ).replace(
        "## ğŸ’° æˆæœ¬åˆ†æ", "## ğŸ’° Token Savings Analysis"
    ).replace(
        "## ğŸ’° TokenèŠ‚çœåˆ†æ", "## ğŸ’° Token Savings Analysis"
    ).replace(
        "### å•æ™ºèƒ½ä½“åœºæ™¯", "### Single Agent Scenario"
    ).replace(
        "### å¤šæ™ºèƒ½ä½“åœºæ™¯", "### Multi-Agent Scenario"
    ).replace(
        "**ä¸ä½¿ç”¨Context Sharing**", "**Without Context Sharing**"
    ).replace(
        "**ä½¿ç”¨Context Sharing**", "**With Context Sharing**"
    ).replace(
        "**èŠ‚çœ**", "**Savings**"
    ).replace(
        "### æ€»ä½“èŠ‚çœ", "### Total Savings"
    ).replace(
        "**æ€»èŠ‚çœé‡‘é¢**", "**Total Token Savings**"
    ).replace(
        "**æ€»TokenèŠ‚çœ**", "**Total Token Savings**"
    ).replace(
        "**æ€»èŠ‚çœæ¯”ä¾‹**", "**Total Savings Percentage**"
    ).replace(
        "**æ¯è½®èŠ‚çœ**", "**Per Round Savings**"
    ).replace(
        "**å¹³å‡æ¯è½®èŠ‚çœ**", "**Average Per Round Savings**"
    ).replace(
        "## ğŸ¯ ä½¿ç”¨å»ºè®®", "## ğŸ¯ Usage Recommendations"
    ).replace(
        "### ä½•æ—¶ä½¿ç”¨Context Sharing", "### When to Use Context Sharing"
    ).replace(
        "### æ€§èƒ½ä¼˜åŒ–å»ºè®®", "### Performance Optimization"
    ).replace(
        "### æˆæœ¬ä¼˜åŒ–å»ºè®®", "### Cost Optimization"
    ).replace(
        "### æ¶æ„è€ƒè™‘", "### Architecture Considerations"
    ).replace(
        "## ğŸ“‹ æ€»ç»“", "## ğŸ“‹ Summary"
    ).replace(
        "æœ¬æ¬¡æµ‹è¯•éªŒè¯äº†PC Nodeåœ¨Context Sharingæ–¹é¢çš„æ€§èƒ½è¡¨ç°ï¼š",
        "This test validates the performance of PC Node's Context Sharing capabilities:"
    ).replace(
        "**å•æ™ºèƒ½ä½“åœºæ™¯**: Context Sharingå¸¦æ¥äº†", "**Single Agent Scenario**: Context Sharing achieved"
    ).replace(
        "**å¤šæ™ºèƒ½ä½“åœºæ™¯**: Context Sharingå¸¦æ¥äº†", "**Multi-Agent Scenario**: Context Sharing achieved"
    ).replace(
        "çš„Tokenæ•ˆç‡æå‡", " token efficiency improvement"
    ).replace(
        "**TokenèŠ‚çœ**: å¹³å‡æ¯è½®å¯¹è¯èŠ‚çœ", "**Token Savings**: Average per round savings -  "
    ).replace(
        "**è§„æ¨¡æ•ˆåº”**: æ¯1000è½®å¯¹è¯èŠ‚çœ", "**Scale Projection**: Savings per 1,000 rounds - "
    ).replace(
        "*æŠ¥å‘Šç”±PC Nodeè‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ¥æº: ç»¼åˆæ€§èƒ½æµ‹è¯•*",
        "*Report automatically generated by PC Node | Data source: Comprehensive performance testing*"
    ).replace(
        "å•æ™ºèƒ½ä½“åœºæ™¯æ˜¾ç¤º", "Single agent scenario shows"
    ).replace(
        "å¤šæ™ºèƒ½ä½“åœºæ™¯æ˜¾ç¤º", "Multi-agent scenario shows"
    ).replace(
        "Context Sharingåœ¨å¤šæ™ºèƒ½ä½“ç¯å¢ƒä¸­è¡¨ç°æ›´ä¼˜ï¼Œé€‚åˆåä½œå‹åº”ç”¨",
        "Context Sharing performs better in multi-agent environments, suitable for collaborative applications"
    ).replace(
        "Context Sharingæœ‰æ•ˆå‡å°‘Tokenä½¿ç”¨ï¼Œæå‡å“åº”æ•ˆç‡",
        "Context Sharing effectively reduces token usage and improves response efficiency"
    ).replace(
        "é€šè¿‡Context Sharingå¯æ˜¾è‘—é™ä½APIè°ƒç”¨æˆæœ¬",
        "Context Sharing significantly reduces API call costs"
    ).replace(
        "tokens", "tokens"
    ).replace(
        "ä¼˜ï¿½ï¿½ï¿½", "Excellent"
    ).replace(
        "è‰¯å¥½", "Good"
    ).replace(
        "ä¸€èˆ¬", "Average"
    ).replace(
        "éœ€è¦ä¼˜åŒ–", "Needs Optimization"
    )

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å¤„ç†å¤æ‚æƒ…å†µ
    import re

    # æ¸…ç†ä¹±ç å­—ç¬¦
    english_content = re.sub(r'[ï¿½ï¿½]+', '', english_content)

    # å¤„ç†æ¨èè¯­çš„ç¿»è¯‘
    english_content = re.sub(r'ï¼Œæ¨èä½¿ç”¨', ', recommended for use', english_content)
    english_content = re.sub(r'ï¼Œå¼ºçƒˆæ¨èä½¿ç”¨', ', highly recommended', english_content)

    # ä¿®å¤token efficiency improvementåé¢ç›´æ¥è·Ÿæ¨èè¯­çš„æƒ…å†µ
    english_content = re.sub(r'improvementæ¨èä½¿ç”¨', 'improvement, recommended for use', english_content)
    english_content = re.sub(r'improvementå¼ºçƒˆæ¨èä½¿ç”¨', 'improvement, highly recommended', english_content)
    english_content = re.sub(r'improvementrecommended for use', 'improvement, recommended for use', english_content)
    english_content = re.sub(r'improvementhighly recommended', 'improvement, highly recommended', english_content)

    # å¤„ç†ç‹¬ç«‹çš„æ¨èè¯­ç¿»è¯‘
    english_content = re.sub(r'æ¨èä½¿ç”¨', 'recommended for use', english_content)
    english_content = re.sub(r'å¼ºçƒˆæ¨èä½¿ç”¨', 'highly recommended', english_content)

    # å¤„ç†ä¸­æ–‡æ ‡ç‚¹ç¬¦å·
    english_content = english_content.replace('ï¼Œ', ', ')
    english_content = english_content.replace('ã€‚', '. ')
    english_content = english_content.replace('ï¼š', ': ')
    english_content = english_content.replace('ï¼›', '; ')

    # ä¿®å¤æ ¼å¼é—®é¢˜
    english_content = english_content.replace("achieved", "achieved ").replace("achieved  ", "achieved ")

    # å¤„ç†tokensç›¸å…³çš„æ•°å­—æ ¼å¼
    english_content = re.sub(r'savings: (\d+) tokens', r'savings: \1 tokens', english_content)
    english_content = re.sub(r'rounds: (\d+) tokens', r'rounds: \1 tokens', english_content)

    # ä¿®å¤Summaryéƒ¨åˆ†çš„tokensè¡¨è¿°
    # english_content = re.sub(r'3\. \*\*Token Savings\*\*: Average per round savings: (\d+) tokens', r'3. **Token Savings**: Average \1 tokens per conversation turn', english_content)
    # english_content = re.sub(r'4\. \*\*Scale Projection\*\*: Savings per 1,000 rounds: (\d+) tokens', r'4. **Scale Projection**: \1 tokens savings per 1,000 conversation turns', english_content)

    # æœ€åçš„æ ¼å¼æ¸…ç†
    english_content = re.sub(r'[ \t]+', ' ', english_content)
    english_content = re.sub(r' +', ' ', english_content)
    english_content = re.sub(r' +\n', '\n', english_content)

    # ä¿å­˜è‹±æ–‡æŠ¥å‘Š
    with open(english_report_path, 'w', encoding='utf-8') as f:
        f.write(english_content)

    return english_report_path


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç”ŸæˆPC Nodeæ€§èƒ½æŠ¥å‘Š...")
    print("="*60)

    # 1. è¿è¡Œå®Œæ•´æµ‹è¯•
    print("ğŸ“‹ æ­¥éª¤ 1: è¿è¡Œæ€§èƒ½æµ‹è¯•")
    runner = TestRunner()
    test_results = runner.run_all_tests()

    if not test_results.get('tests_completed'):
        print("âŒ æµ‹è¯•å¤±è´¥ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
        return 1

    # 2. åˆ›å»ºdocsç›®å½•ç»“æ„
    print("\nğŸ“ æ­¥éª¤ 2: åˆ›å»ºæ–‡æ¡£ç›®å½•ç»“æ„")
    docs_dir, images_dir = create_docs_structure()

    # 3. ç§»åŠ¨å›¾è¡¨åˆ°docs/images
    print("\nğŸ“Š æ­¥éª¤ 3: ç§»åŠ¨å›¾è¡¨æ–‡ä»¶")
    test_results_dir = runner.results_dir
    chart_files = move_charts_to_docs(test_results_dir, images_dir)

    # 4. ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š
    print("\nğŸ“ˆ æ­¥éª¤ 4: ç”Ÿæˆç»¼åˆåˆ†æï¿½ï¿½ï¿½å‘Š")
    analyzer = TestDataAnalyzer()

    # è·å–æµ‹è¯•ç»“æœ
    single_results = test_results.get('single_agent_results', {})
    multi_results = test_results.get('multi_agent_results', {})

    if not single_results or not multi_results:
        print("âŒ æµ‹è¯•ç»“æœä¸å®Œæ•´ï¼Œæ— æ³•ç”Ÿæˆç»¼åˆåˆ†æ")
        return 1

    # ç”Ÿæˆåˆ†æ
    analysis = analyzer.analyze_comprehensive_results(single_results, multi_results)

    # ç”Ÿæˆä¸­æ–‡æŠ¥å‘Š
    chinese_report_path = os.path.join(docs_dir, "pc_node_performance_report.zh.md")
    analyzer.generate_markdown_report(analysis, chinese_report_path)

    # 5. ç”Ÿæˆè‹±æ–‡æŠ¥å‘Š
    print("\nğŸŒ æ­¥éª¤ 5: ç”Ÿæˆè‹±æ–‡ç‰ˆæŠ¥å‘Š")
    english_report_path = generate_english_report(chinese_report_path, docs_dir)

    # 6. è¾“å‡ºæ€»ç»“
    print("\n" + "="*60)
    print("âœ… PC Nodeæ€§èƒ½æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print("="*60)

    print(f"ï¿½ï¿½ ä¸­æ–‡æŠ¥å‘Š: {chinese_report_path}")
    print(f"ğŸ“„ è‹±æ–‡æŠ¥å‘Š: {english_report_path}")
    print(f"ğŸ“Š å›¾è¡¨ç›®å½•: {images_dir}")
    print(f"ğŸ“ˆ ç”Ÿæˆçš„å›¾è¡¨: {', '.join(chart_files)}")

    # æ˜¾ç¤ºå…³é”®æ€§èƒ½æŒ‡æ ‡
    if 'comprehensive_analysis' in test_results:
        analysis = test_results['comprehensive_analysis']
        single_efficiency = analysis['test_summary']['single_agent'].get('improvements', {}).get('token_efficiency', 0)
        multi_efficiency = analysis['test_summary']['multi_agent'].get('improvements', {}).get('token_efficiency', 0)
        total_token_savings = analysis['cost_analysis']['total_savings']['tokens']

        print(f"\nğŸ¯ å…³é”®æ€§èƒ½æŒ‡æ ‡:")
        print(f"   ğŸ¤– å•æ™ºèƒ½ä½“Tokenæ•ˆç‡æå‡: {single_efficiency:.1f}%")
        print(f"   ğŸ‘¥ å¤šæ™ºèƒ½ä½“Tokenæ•ˆç‡æå‡: {multi_efficiency:.1f}%")
        print(f"   ğŸ’° æ€»ä½“TokenèŠ‚çœ: {total_token_savings:,.0f} tokens")

    print("\nï¿½ï¿½ï¿½ ä½¿ç”¨å»ºè®®:")
    print("   1. å°†æŠ¥å‘Šæ–‡ä»¶æ·»åŠ åˆ°Gitä»“åº“")
    print("   2. åœ¨READMEä¸­å¼•ç”¨æ€§èƒ½æŠ¥å‘Š")
    print("   3. å®šæœŸè¿è¡Œæ­¤è„šæœ¬æ›´æ–°æ€§èƒ½æ•°æ®")

    return 0


if __name__ == "__main__":
    sys.exit(main())
